{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00039056",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-04-01T22:40:05.341419Z",
     "iopub.status.busy": "2023-04-01T22:40:05.340639Z",
     "iopub.status.idle": "2023-04-01T22:40:23.001648Z",
     "shell.execute_reply": "2023-04-01T22:40:22.999704Z"
    },
    "papermill": {
     "duration": 17.670411,
     "end_time": "2023-04-01T22:40:23.004125",
     "exception": false,
     "start_time": "2023-04-01T22:40:05.333714",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchsummary\r\n",
      "  Downloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\r\n",
      "Installing collected packages: torchsummary\r\n",
      "Successfully installed torchsummary-1.5.1\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m1.13.0\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.models as model\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "import tarfile\n",
    "from torch.nn import DataParallel\n",
    "from pathlib import Path\n",
    "!pip install torchsummary\n",
    "from torchsummary import summary\n",
    "import os\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import math\n",
    "import time\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d11318d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T22:40:23.015918Z",
     "iopub.status.busy": "2023-04-01T22:40:23.014744Z",
     "iopub.status.idle": "2023-04-01T22:40:23.113451Z",
     "shell.execute_reply": "2023-04-01T22:40:23.112198Z"
    },
    "papermill": {
     "duration": 0.10786,
     "end_time": "2023-04-01T22:40:23.116644",
     "exception": false,
     "start_time": "2023-04-01T22:40:23.008784",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Setup Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f5d1f6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T22:40:23.128223Z",
     "iopub.status.busy": "2023-04-01T22:40:23.127903Z",
     "iopub.status.idle": "2023-04-01T22:40:23.134563Z",
     "shell.execute_reply": "2023-04-01T22:40:23.133531Z"
    },
    "papermill": {
     "duration": 0.014384,
     "end_time": "2023-04-01T22:40:23.136621",
     "exception": false,
     "start_time": "2023-04-01T22:40:23.122237",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FocalLoss(torch.nn.Module):\n",
    "    def __init__(self, weight=None, gamma=0, eps=1e-7):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.eps = eps\n",
    "        self.ce = torch.nn.CrossEntropyLoss(weight=weight)\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        logp = self.ce(input, target)\n",
    "        p = torch.exp(-logp)\n",
    "        loss = (1 - p) ** self.gamma * logp\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5247eadd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T22:40:23.147046Z",
     "iopub.status.busy": "2023-04-01T22:40:23.146769Z",
     "iopub.status.idle": "2023-04-01T22:40:23.157326Z",
     "shell.execute_reply": "2023-04-01T22:40:23.156268Z"
    },
    "papermill": {
     "duration": 0.018496,
     "end_time": "2023-04-01T22:40:23.159506",
     "exception": false,
     "start_time": "2023-04-01T22:40:23.141010",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ArcFaceLoss(torch.nn.Module):\n",
    "    \"\"\"Implement of large margin arc distance: :\n",
    "        Args:\n",
    "            in_features: size of each input sample\n",
    "            out_features: size of each output sample\n",
    "            s: norm of input feature\n",
    "            m: margin\n",
    "\n",
    "            cos(theta + m)\n",
    "        \"\"\"\n",
    "    def __init__(self, in_features, out_features, s=30.0, m=0.50):\n",
    "        super(ArcFaceLoss, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.weight = torch.nn.Parameter(torch.FloatTensor(out_features, in_features))\n",
    "        torch.nn.init.xavier_uniform_(self.weight)\n",
    "\n",
    "        self.cos_m = math.cos(m)\n",
    "        self.sin_m = math.sin(m)\n",
    "        self.th = math.cos(math.pi - m)\n",
    "        self.mm = math.sin(math.pi - m) * m\n",
    "\n",
    "    def forward(self, feature, label= None):\n",
    "        # Normalize embeddings and weights\n",
    "        feature = F.normalize(feature)\n",
    "        weights = F.normalize(self.weight)\n",
    "\n",
    "        # Compute the logit\n",
    "        cos_theta = F.linear(feature, weights)\n",
    "        \n",
    "        if (label is None):\n",
    "            return cos_theta\n",
    "\n",
    "        # Find the angle between the weight and feature\n",
    "        theta = torch.acos(cos_theta)\n",
    "\n",
    "        # Add angular margin penalty\n",
    "        marginal_target_logit = torch.cos(theta + self.m)\n",
    "        \n",
    "        marginal_target_logit = torch.where(cos_theta > self.th, marginal_target_logit, cos_theta - self.mm)\n",
    "\n",
    "        # One-hot encoding\n",
    "        #one_hot = torch.zeros(cos_theta.size(), device=device)\n",
    "        one_hot = torch.zeros_like(cos_theta)\n",
    "        one_hot.scatter_(1, label.view(-1, 1).long(), 1)\n",
    "\n",
    "        # Compute class wise similarity score through element wise multiplication of one_hot ground truth and the marginal target logit\n",
    "        score = (one_hot * marginal_target_logit) + ((1.0 - one_hot) * cos_theta)\n",
    "        #score = torch.mul(marginal_target_logit, one_hot)\n",
    "\n",
    "        # Rescale to s\n",
    "        score *= self.s\n",
    "\n",
    "        return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6448da98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T22:40:23.170066Z",
     "iopub.status.busy": "2023-04-01T22:40:23.169236Z",
     "iopub.status.idle": "2023-04-01T22:40:23.176321Z",
     "shell.execute_reply": "2023-04-01T22:40:23.175384Z"
    },
    "papermill": {
     "duration": 0.014618,
     "end_time": "2023-04-01T22:40:23.178566",
     "exception": false,
     "start_time": "2023-04-01T22:40:23.163948",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# transform into tensors\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize(112),\n",
    "    transforms.CenterCrop(112),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(112),\n",
    "    transforms.CenterCrop(112),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9e46cea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T22:40:23.188670Z",
     "iopub.status.busy": "2023-04-01T22:40:23.188160Z",
     "iopub.status.idle": "2023-04-01T22:40:53.404860Z",
     "shell.execute_reply": "2023-04-01T22:40:53.403729Z"
    },
    "papermill": {
     "duration": 30.231171,
     "end_time": "2023-04-01T22:40:53.414094",
     "exception": false,
     "start_time": "2023-04-01T22:40:23.182923",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://vis-www.cs.umass.edu/lfw/lfw-funneled.tgz to kaggle/input/lfwpeople/lfw-py/lfw-funneled.tgz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09ddf1c7b05d4bdba652d0035a486945",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/243346528 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting kaggle/input/lfwpeople/lfw-py/lfw-funneled.tgz to kaggle/input/lfwpeople/lfw-py\n",
      "Downloading http://vis-www.cs.umass.edu/lfw/peopleDevTrain.txt to kaggle/input/lfwpeople/lfw-py/peopleDevTrain.txt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6278319381714ddea029bd6dad4a0aef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/66403 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://vis-www.cs.umass.edu/lfw/lfw-names.txt to kaggle/input/lfwpeople/lfw-py/lfw-names.txt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1c42f9a3e3547cc8d061be0dea2ccf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94727 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: kaggle/input/lfwpeople/lfw-py/lfw-funneled.tgz\n",
      "Extracting kaggle/input/lfwpeople/lfw-py/lfw-funneled.tgz to kaggle/input/lfwpeople/lfw-py\n",
      "Downloading http://vis-www.cs.umass.edu/lfw/peopleDevTest.txt to kaggle/input/lfwpeople/lfw-py/peopleDevTest.txt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d67ac4be9454a18a346dd4ab0fff983",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: kaggle/input/lfwpeople/lfw-py/lfw-names.txt\n",
      "Using downloaded and verified file: kaggle/input/lfwpeople/lfw-py/lfw-funneled.tgz\n",
      "Extracting kaggle/input/lfwpeople/lfw-py/lfw-funneled.tgz to kaggle/input/lfwpeople/lfw-py\n",
      "Downloading http://vis-www.cs.umass.edu/lfw/people.txt to kaggle/input/lfwpeople/lfw-py/people.txt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "673cf7ccb8f748b29c7fc9cce50b50de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94770 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: kaggle/input/lfwpeople/lfw-py/lfw-names.txt\n",
      "4038\n",
      "1711\n",
      "5749\n"
     ]
    }
   ],
   "source": [
    "# Make the LFW test and train datasets and put in dataloader for batching\n",
    "lfwdataset_train = torchvision.datasets.LFWPeople(root = \"kaggle/input/lfwpeople\", split= \"train\", transform=transform_train, download=True)\n",
    "lfwdataset_test = torchvision.datasets.LFWPeople(root = \"kaggle/input/lfwpeople\", split= \"test\", transform=transform, download=True)\n",
    "lfwdataset_val = torchvision.datasets.LFWPeople(root = \"kaggle/input/lfwpeople\", split= \"10fold\", transform=transform, download=True)\n",
    "\n",
    "data_loader_valid = DataLoader(lfwdataset_val, batch_size= 32, shuffle= True, num_workers=0, collate_fn= None, pin_memory= False)\n",
    "data_loader_train = DataLoader(lfwdataset_train, batch_size= 32, shuffle= True, num_workers=0, collate_fn= None, pin_memory= False)\n",
    "data_loader_test = DataLoader(lfwdataset_test, batch_size= 32, shuffle= True, num_workers=0, collate_fn= None, pin_memory= False)\n",
    "\n",
    "num_classes_train = len(set(lfwdataset_train.targets))\n",
    "num_classes_validation = len(set(lfwdataset_val.targets))\n",
    "num_classes_test = len(set(lfwdataset_test.targets))\n",
    "#num_classes_LFW = 5749\n",
    "num_classes_LFW = len(set(lfwdataset_val.targets))\n",
    "print(len(set(lfwdataset_train.targets)))\n",
    "print(len(set(lfwdataset_test.targets)))\n",
    "print(len(set(lfwdataset_val.targets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77e4dc0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T22:40:53.428567Z",
     "iopub.status.busy": "2023-04-01T22:40:53.428210Z",
     "iopub.status.idle": "2023-04-01T22:40:53.460991Z",
     "shell.execute_reply": "2023-04-01T22:40:53.460024Z"
    },
    "papermill": {
     "duration": 0.042604,
     "end_time": "2023-04-01T22:40:53.463283",
     "exception": false,
     "start_time": "2023-04-01T22:40:53.420679",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "using_ckpt = False\n",
    "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes,\n",
    "                     out_planes,\n",
    "                     kernel_size=3,\n",
    "                     stride=stride,\n",
    "                     padding=dilation,\n",
    "                     groups=groups,\n",
    "                     bias=False,\n",
    "                     dilation=dilation)\n",
    "\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes,\n",
    "                     out_planes,\n",
    "                     kernel_size=1,\n",
    "                     stride=stride,\n",
    "                     bias=False)\n",
    "\n",
    "\n",
    "class IBasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None,\n",
    "                 groups=1, base_width=64, dilation=1):\n",
    "        super(IBasicBlock, self).__init__()\n",
    "        if groups != 1 or base_width != 64:\n",
    "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
    "        if dilation > 1:\n",
    "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
    "        self.bn1 = nn.BatchNorm2d(inplanes, eps=1e-05,)\n",
    "        self.conv1 = conv3x3(inplanes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes, eps=1e-05,)\n",
    "        self.prelu = nn.PReLU(planes)\n",
    "        self.conv2 = conv3x3(planes, planes, stride)\n",
    "        self.bn3 = nn.BatchNorm2d(planes, eps=1e-05,)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward_impl(self, x):\n",
    "        identity = x\n",
    "        out = self.bn1(x)\n",
    "        out = self.conv1(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.prelu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn3(out)\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "        out += identity\n",
    "        return out        \n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training and using_ckpt:\n",
    "            return checkpoint(self.forward_impl, x)\n",
    "        else:\n",
    "            return self.forward_impl(x)\n",
    "\n",
    "\n",
    "class IResNet(nn.Module):\n",
    "    fc_scale = 7 * 7\n",
    "    def __init__(self,\n",
    "                 block, layers, dropout=0, num_features=512, zero_init_residual=False,\n",
    "                 groups=1, width_per_group=64, replace_stride_with_dilation=None, fp16=False):\n",
    "        super(IResNet, self).__init__()\n",
    "        self.extra_gflops = 0.0\n",
    "        self.fp16 = fp16\n",
    "        self.inplanes = 64\n",
    "        self.dilation = 1\n",
    "        if replace_stride_with_dilation is None:\n",
    "            replace_stride_with_dilation = [False, False, False]\n",
    "        if len(replace_stride_with_dilation) != 3:\n",
    "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
    "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
    "        self.groups = groups\n",
    "        self.base_width = width_per_group\n",
    "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(self.inplanes, eps=1e-05)\n",
    "        self.prelu = nn.PReLU(self.inplanes)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0], stride=2)\n",
    "        self.layer2 = self._make_layer(block,\n",
    "                                       128,\n",
    "                                       layers[1],\n",
    "                                       stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[0])\n",
    "        self.layer3 = self._make_layer(block,\n",
    "                                       256,\n",
    "                                       layers[2],\n",
    "                                       stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[1])\n",
    "        self.layer4 = self._make_layer(block,\n",
    "                                       512,\n",
    "                                       layers[3],\n",
    "                                       stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[2])\n",
    "        self.bn2 = nn.BatchNorm2d(512 * block.expansion, eps=1e-05,)\n",
    "        self.dropout = nn.Dropout(p=dropout, inplace=True)\n",
    "        self.fc = nn.Linear(512 * block.expansion * self.fc_scale, num_features)\n",
    "        self.features = nn.BatchNorm1d(num_features, eps=1e-05)\n",
    "        nn.init.constant_(self.features.weight, 1.0)\n",
    "        self.features.weight.requires_grad = False\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.normal_(m.weight, 0, 0.1)\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, IBasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                nn.BatchNorm2d(planes * block.expansion, eps=1e-05, ),\n",
    "            )\n",
    "        layers = []\n",
    "        layers.append(\n",
    "            block(self.inplanes, planes, stride, downsample, self.groups,\n",
    "                  self.base_width, previous_dilation))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(\n",
    "                block(self.inplanes,\n",
    "                      planes,\n",
    "                      groups=self.groups,\n",
    "                      base_width=self.base_width,\n",
    "                      dilation=self.dilation))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        with torch.cuda.amp.autocast(self.fp16):\n",
    "            x = self.conv1(x)\n",
    "            x = self.bn1(x)\n",
    "            x = self.prelu(x)\n",
    "            x = self.layer1(x)\n",
    "            x = self.layer2(x)\n",
    "            x = self.layer3(x)\n",
    "            x = self.layer4(x)\n",
    "            x = self.bn2(x)\n",
    "            x = torch.flatten(x, 1)\n",
    "            x = self.dropout(x)\n",
    "        x = self.fc(x.float() if self.fp16 else x)\n",
    "        x = self.features(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def _iresnet(arch, block, layers, pretrained, progress, **kwargs):\n",
    "    model = IResNet(block, layers, **kwargs)\n",
    "    if pretrained:\n",
    "        raise ValueError()\n",
    "    return model\n",
    "\n",
    "\n",
    "def iresnet18(pretrained=False, progress=True, **kwargs):\n",
    "    return _iresnet('iresnet18', IBasicBlock, [2, 2, 2, 2], pretrained,\n",
    "                    progress, **kwargs)\n",
    "\n",
    "\n",
    "def iresnet34(pretrained=False, progress=True, **kwargs):\n",
    "    return _iresnet('iresnet34', IBasicBlock, [3, 4, 6, 3], pretrained,\n",
    "                    progress, **kwargs)\n",
    "\n",
    "\n",
    "def iresnet50(pretrained=False, progress=True, **kwargs):\n",
    "    return _iresnet('iresnet50', IBasicBlock, [3, 4, 14, 3], pretrained,\n",
    "                    progress, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bad0b261",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T22:40:53.476818Z",
     "iopub.status.busy": "2023-04-01T22:40:53.476102Z",
     "iopub.status.idle": "2023-04-01T22:40:58.383807Z",
     "shell.execute_reply": "2023-04-01T22:40:58.382774Z"
    },
    "papermill": {
     "duration": 4.917367,
     "end_time": "2023-04-01T22:40:58.386583",
     "exception": false,
     "start_time": "2023-04-01T22:40:53.469216",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): IResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (prelu): PReLU(num_parameters=64)\n",
       "    (layer1): Sequential(\n",
       "      (0): IBasicBlock(\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=64)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): IBasicBlock(\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=64)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): IBasicBlock(\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=64)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): IBasicBlock(\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=128)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): IBasicBlock(\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=128)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): IBasicBlock(\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=128)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): IBasicBlock(\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=128)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): IBasicBlock(\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=256)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): IBasicBlock(\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=256)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): IBasicBlock(\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=256)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): IBasicBlock(\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=256)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): IBasicBlock(\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=256)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (5): IBasicBlock(\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=256)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (6): IBasicBlock(\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=256)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (7): IBasicBlock(\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=256)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (8): IBasicBlock(\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=256)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (9): IBasicBlock(\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=256)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (10): IBasicBlock(\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=256)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (11): IBasicBlock(\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=256)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (12): IBasicBlock(\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=256)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (13): IBasicBlock(\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=256)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): IBasicBlock(\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=512)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): IBasicBlock(\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=512)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): IBasicBlock(\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=512)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dropout): Dropout(p=0, inplace=True)\n",
       "    (fc): Linear(in_features=25088, out_features=512, bias=True)\n",
       "    (features): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Implemenet CNN Baacosh_ckbone\n",
    "Path_resnet = Path('/kaggle/working/resnet50_weights.pth') \n",
    "# if (Path_resnet.is_file()):\n",
    "#     models = model.resnet50()\n",
    "#     # Freeze All CNN Layers (Stop all learning in all layers)\n",
    "#     for param in models.parameters():\n",
    "#         param.requires_grad = False\n",
    "\n",
    "#     # Change the final layer (unfreeze fc layer)\n",
    "#     models.avgpool = torch.nn.Identity()\n",
    "#     models.fc = torch.nn.Sequential(\n",
    "#     torch.nn.BatchNorm1d(num_features= 100352),\n",
    "#     torch.nn.Dropout(p=0.5),\n",
    "#     torch.nn.Linear(in_features= 100352, out_features=512, bias=True),\n",
    "#     torch.nn.BatchNorm1d(num_features=512)\n",
    "#     )\n",
    "#     models.fc.requires_grad = True\n",
    "#     models = DataParallel(models)\n",
    "#     models.load_state_dict(torch.load('/kaggle/working/resnet50_weights.pth'))\n",
    "#     print(models.state_dict())\n",
    "# else:\n",
    "# weights = model.ResNet50_Weights.DEFAULT\n",
    "# models = model.resnet50(weights = weights)\n",
    "\n",
    "\n",
    "# #Freeze All CNN Layers (Stop all learning in all layers)\n",
    "# for param in models.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# # Change the final layer (unfreeze fc layer)\n",
    "# models.avgpool = torch.nn.Identity()\n",
    "# models.fc = torch.nn.Sequential(\n",
    "# torch.nn.BatchNorm1d(num_features= 32768, track_running_stats= True),\n",
    "# torch.nn.Dropout(p=0.5),\n",
    "# torch.nn.Linear(in_features= 32768, out_features=512, bias=True),\n",
    "# torch.nn.BatchNorm1d(num_features=512, track_running_stats= True)\n",
    "# )\n",
    "models = iresnet50()\n",
    "models.fc.requires_grad = True\n",
    "models = DataParallel(models)\n",
    "\n",
    "models.to(device)\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1d1a992",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T22:40:58.400236Z",
     "iopub.status.busy": "2023-04-01T22:40:58.399917Z",
     "iopub.status.idle": "2023-04-01T22:40:58.549458Z",
     "shell.execute_reply": "2023-04-01T22:40:58.548209Z"
    },
    "papermill": {
     "duration": 0.160507,
     "end_time": "2023-04-01T22:40:58.553135",
     "exception": false,
     "start_time": "2023-04-01T22:40:58.392628",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('module.weight', tensor([[ 0.0158, -0.0126,  0.0181,  ..., -0.0188,  0.0108, -0.0092],\n",
      "        [ 0.0120,  0.0122, -0.0126,  ...,  0.0003, -0.0177,  0.0285],\n",
      "        [ 0.0035, -0.0057,  0.0102,  ...,  0.0246,  0.0157, -0.0154],\n",
      "        ...,\n",
      "        [ 0.0309, -0.0301,  0.0229,  ..., -0.0152,  0.0183, -0.0191],\n",
      "        [-0.0268, -0.0236, -0.0123,  ...,  0.0149, -0.0033, -0.0174],\n",
      "        [-0.0086, -0.0043,  0.0175,  ...,  0.0235, -0.0211,  0.0167]],\n",
      "       device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "Path_arcface = Path('/kaggle/working/arcface_weights.pth')\n",
    "# if (Path_arcface.is_file()):\n",
    "#     metric_fc = ArcFaceLoss(512, num_classes_LFW, 30.0, 0.5)\n",
    "#     metric_fc = DataParallel(metric_fc)\n",
    "#     metric_fc.load_state_dict(torch.load('/kaggle/working/arcface_weights.pth'))\n",
    "# else:\n",
    "metric_fc = ArcFaceLoss(512, num_classes_LFW, 64.0, 0.5)\n",
    "metric_fc = DataParallel(metric_fc)\n",
    "metric_fc.requires_grad = True\n",
    "metric_fc.to(device)\n",
    "print(metric_fc.state_dict())\n",
    "# Analyze model parameters and layers\n",
    "#summary(models, (3, 112, 112))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab36e05c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T22:40:58.568868Z",
     "iopub.status.busy": "2023-04-01T22:40:58.568527Z",
     "iopub.status.idle": "2023-04-01T22:40:58.573976Z",
     "shell.execute_reply": "2023-04-01T22:40:58.572654Z"
    },
    "papermill": {
     "duration": 0.01666,
     "end_time": "2023-04-01T22:40:58.576749",
     "exception": false,
     "start_time": "2023-04-01T22:40:58.560089",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Focal loss is an improved method of Cross Entropy that can focus on scaling the harder cases then the easier cases\n",
    "#Loss = torch.nn.CrossEntropyLoss().to(device)\n",
    "Loss = FocalLoss(gamma= 2).to(device)\n",
    "Loss.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7439cff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T22:40:58.591263Z",
     "iopub.status.busy": "2023-04-01T22:40:58.590308Z",
     "iopub.status.idle": "2023-04-01T22:40:58.598202Z",
     "shell.execute_reply": "2023-04-01T22:40:58.597233Z"
    },
    "papermill": {
     "duration": 0.017409,
     "end_time": "2023-04-01T22:40:58.600385",
     "exception": false,
     "start_time": "2023-04-01T22:40:58.582976",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup Optimizer and Scheduler\n",
    "optimizer = torch.optim.SGD([{'params': models.parameters()},\n",
    "                              {'params': metric_fc.parameters()}],\n",
    "                              lr = 1e-1, weight_decay= 5e-4, momentum= 0.9)  # Can use Adam or SGD\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones= [30, 80, 120, 170], gamma= 0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f1cc7ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T22:40:58.613809Z",
     "iopub.status.busy": "2023-04-01T22:40:58.613264Z",
     "iopub.status.idle": "2023-04-02T06:21:01.765322Z",
     "shell.execute_reply": "2023-04-02T06:21:01.764265Z"
    },
    "papermill": {
     "duration": 27603.161609,
     "end_time": "2023-04-02T06:21:01.767900",
     "exception": false,
     "start_time": "2023-04-01T22:40:58.606291",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #: [001/298], Train Loss: 43.212425231933594, Train Accuracy: 0.0\n",
      "Batch #: [101/298], Train Loss: 64.17802319668307, Train Accuracy: 0.0\n",
      "Batch #: [201/298], Train Loss: 62.67752642655254, Train Accuracy: 0.0\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.58104419708252, Validation Accuracy: 0.03125\n",
      "Validation Batch #: 101, Validation Loss: 8.606690642857316, Validation Accuracy: 0.004641089108910891\n",
      "Validation Batch #: 201, Validation Loss: 8.607645680062213, Validation Accuracy: 0.004508706467661692\n",
      "Validation Batch #: 301, Validation Loss: 8.60727795572376, Validation Accuracy: 0.003841362126245847\n",
      "Validation Batch #: 401, Validation Loss: 8.607068620715058, Validation Accuracy: 0.003740648379052369\n",
      "Epoch: 2/10\n",
      "Batch #: [001/298], Train Loss: 52.00578308105469, Train Accuracy: 0.0\n",
      "Batch #: [101/298], Train Loss: 44.12839130363842, Train Accuracy: 0.0\n",
      "Batch #: [201/298], Train Loss: 41.94116512697134, Train Accuracy: 0.0\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.61429500579834, Validation Accuracy: 0.03125\n",
      "Validation Batch #: 101, Validation Loss: 8.61057964173874, Validation Accuracy: 0.038675742574257425\n",
      "Validation Batch #: 201, Validation Loss: 8.611212474196705, Validation Accuracy: 0.03980099502487562\n",
      "Validation Batch #: 301, Validation Loss: 8.610720048315105, Validation Accuracy: 0.03997093023255814\n",
      "Validation Batch #: 401, Validation Loss: 8.610010596582123, Validation Accuracy: 0.0399002493765586\n",
      "Epoch: 3/10\n",
      "Batch #: [001/298], Train Loss: 39.33647918701172, Train Accuracy: 0.0\n",
      "Batch #: [101/298], Train Loss: 38.6778360121321, Train Accuracy: 0.0\n",
      "Batch #: [201/298], Train Loss: 38.686407022808325, Train Accuracy: 0.0\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.598183631896973, Validation Accuracy: 0.09375\n",
      "Validation Batch #: 101, Validation Loss: 8.585108077172006, Validation Accuracy: 0.08013613861386139\n",
      "Validation Batch #: 201, Validation Loss: 8.585106417907411, Validation Accuracy: 0.0830223880597015\n",
      "Validation Batch #: 301, Validation Loss: 8.585678797623643, Validation Accuracy: 0.08108388704318936\n",
      "Validation Batch #: 401, Validation Loss: 8.58598644180488, Validation Accuracy: 0.08104738154613467\n",
      "Epoch: 4/10\n",
      "Batch #: [001/298], Train Loss: 37.65272903442383, Train Accuracy: 0.0\n",
      "Batch #: [101/298], Train Loss: 37.97962347351679, Train Accuracy: 0.0\n",
      "Batch #: [201/298], Train Loss: 38.09847432226684, Train Accuracy: 0.0\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.580924987792969, Validation Accuracy: 0.03125\n",
      "Validation Batch #: 101, Validation Loss: 8.559194177684217, Validation Accuracy: 0.11076732673267327\n",
      "Validation Batch #: 201, Validation Loss: 8.560694367138307, Validation Accuracy: 0.1052549751243781\n",
      "Validation Batch #: 301, Validation Loss: 8.559946142557848, Validation Accuracy: 0.10568936877076412\n",
      "Validation Batch #: 401, Validation Loss: 8.559871928055685, Validation Accuracy: 0.10419264339152119\n",
      "Epoch: 5/10\n",
      "Batch #: [001/298], Train Loss: 36.449825286865234, Train Accuracy: 0.0\n",
      "Batch #: [101/298], Train Loss: 37.39547280037757, Train Accuracy: 0.0\n",
      "Batch #: [201/298], Train Loss: 37.67635874961739, Train Accuracy: 0.0\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.522278785705566, Validation Accuracy: 0.1875\n",
      "Validation Batch #: 101, Validation Loss: 8.516363927633455, Validation Accuracy: 0.17698019801980197\n",
      "Validation Batch #: 201, Validation Loss: 8.514469863170415, Validation Accuracy: 0.17863805970149255\n",
      "Validation Batch #: 301, Validation Loss: 8.5142200571358, Validation Accuracy: 0.18085548172757476\n",
      "Validation Batch #: 401, Validation Loss: 8.514930323175063, Validation Accuracy: 0.1813435162094763\n",
      "Epoch: 6/10\n",
      "Batch #: [001/298], Train Loss: 36.427337646484375, Train Accuracy: 0.0\n",
      "Batch #: [101/298], Train Loss: 36.59723644445438, Train Accuracy: 0.0\n",
      "Batch #: [201/298], Train Loss: 37.07448221083304, Train Accuracy: 0.0\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.509309768676758, Validation Accuracy: 0.1875\n",
      "Validation Batch #: 101, Validation Loss: 8.44961939707841, Validation Accuracy: 0.29176980198019803\n",
      "Validation Batch #: 201, Validation Loss: 8.447663316679238, Validation Accuracy: 0.29259950248756217\n",
      "Validation Batch #: 301, Validation Loss: 8.448226149296048, Validation Accuracy: 0.28934800664451826\n",
      "Validation Batch #: 401, Validation Loss: 8.448992986036952, Validation Accuracy: 0.28592581047381543\n",
      "Epoch: 7/10\n",
      "Batch #: [001/298], Train Loss: 37.25753402709961, Train Accuracy: 0.0\n",
      "Batch #: [101/298], Train Loss: 34.62640520605711, Train Accuracy: 0.0018564356435643563\n",
      "Batch #: [201/298], Train Loss: 35.02298698615079, Train Accuracy: 0.002021144278606965\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.457151412963867, Validation Accuracy: 0.3125\n",
      "Validation Batch #: 101, Validation Loss: 8.373850482525212, Validation Accuracy: 0.4158415841584158\n",
      "Validation Batch #: 201, Validation Loss: 8.372150112740435, Validation Accuracy: 0.41962064676616917\n",
      "Validation Batch #: 301, Validation Loss: 8.370523034536165, Validation Accuracy: 0.4260797342192691\n",
      "Validation Batch #: 401, Validation Loss: 8.370206364372425, Validation Accuracy: 0.42573254364089774\n",
      "Epoch: 8/10\n",
      "Batch #: [001/298], Train Loss: 32.392127990722656, Train Accuracy: 0.0\n",
      "Batch #: [101/298], Train Loss: 30.621187096775166, Train Accuracy: 0.0037128712871287127\n",
      "Batch #: [201/298], Train Loss: 31.177626699950565, Train Accuracy: 0.00388681592039801\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.343549728393555, Validation Accuracy: 0.46875\n",
      "Validation Batch #: 101, Validation Loss: 8.303152632005144, Validation Accuracy: 0.5411509900990099\n",
      "Validation Batch #: 201, Validation Loss: 8.302394501605438, Validation Accuracy: 0.5388681592039801\n",
      "Validation Batch #: 301, Validation Loss: 8.304084499016948, Validation Accuracy: 0.5365448504983389\n",
      "Validation Batch #: 401, Validation Loss: 8.304789614499061, Validation Accuracy: 0.5349906483790524\n",
      "Epoch: 9/10\n",
      "Batch #: [001/298], Train Loss: 24.642375946044922, Train Accuracy: 0.0\n",
      "Batch #: [101/298], Train Loss: 26.16293470930345, Train Accuracy: 0.011757425742574257\n",
      "Batch #: [201/298], Train Loss: 27.02261079247318, Train Accuracy: 0.01197139303482587\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.346250534057617, Validation Accuracy: 0.375\n",
      "Validation Batch #: 101, Validation Loss: 8.263922266440817, Validation Accuracy: 0.5683787128712872\n",
      "Validation Batch #: 201, Validation Loss: 8.258861940298507, Validation Accuracy: 0.576181592039801\n",
      "Validation Batch #: 301, Validation Loss: 8.260345234031297, Validation Accuracy: 0.5769310631229236\n",
      "Validation Batch #: 401, Validation Loss: 8.259152557487202, Validation Accuracy: 0.5801122194513716\n",
      "Epoch: 10/10\n",
      "Batch #: [001/298], Train Loss: 24.585811614990234, Train Accuracy: 0.0\n",
      "Batch #: [101/298], Train Loss: 22.54722827495915, Train Accuracy: 0.03063118811881188\n",
      "Batch #: [201/298], Train Loss: 23.306058542052313, Train Accuracy: 0.029228855721393034\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.199357986450195, Validation Accuracy: 0.625\n",
      "Validation Batch #: 101, Validation Loss: 8.233787527178773, Validation Accuracy: 0.6092202970297029\n",
      "Validation Batch #: 201, Validation Loss: 8.232689112573121, Validation Accuracy: 0.6122512437810945\n",
      "Validation Batch #: 301, Validation Loss: 8.231909384363117, Validation Accuracy: 0.6097383720930233\n",
      "Validation Batch #: 401, Validation Loss: 8.233019562433485, Validation Accuracy: 0.6065305486284289\n",
      "Epoch: 11/10\n",
      "Batch #: [001/298], Train Loss: 16.567298889160156, Train Accuracy: 0.0625\n",
      "Batch #: [101/298], Train Loss: 19.760290023123865, Train Accuracy: 0.06992574257425743\n",
      "Batch #: [201/298], Train Loss: 20.61475850100541, Train Accuracy: 0.05970149253731343\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.247274398803711, Validation Accuracy: 0.625\n",
      "Validation Batch #: 101, Validation Loss: 8.214896287068282, Validation Accuracy: 0.6324257425742574\n",
      "Validation Batch #: 201, Validation Loss: 8.212117029066702, Validation Accuracy: 0.6291977611940298\n",
      "Validation Batch #: 301, Validation Loss: 8.21152366435409, Validation Accuracy: 0.6289451827242525\n",
      "Validation Batch #: 401, Validation Loss: 8.211980869645192, Validation Accuracy: 0.6285068578553616\n",
      "Epoch: 12/10\n",
      "Batch #: [001/298], Train Loss: 18.371078491210938, Train Accuracy: 0.0625\n",
      "Batch #: [101/298], Train Loss: 18.024900511939926, Train Accuracy: 0.11726485148514851\n",
      "Batch #: [201/298], Train Loss: 19.131304873755916, Train Accuracy: 0.09903606965174129\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.221203804016113, Validation Accuracy: 0.59375\n",
      "Validation Batch #: 101, Validation Loss: 8.206461283239987, Validation Accuracy: 0.6268564356435643\n",
      "Validation Batch #: 201, Validation Loss: 8.200239518388587, Validation Accuracy: 0.6363495024875622\n",
      "Validation Batch #: 301, Validation Loss: 8.204793442127317, Validation Accuracy: 0.6297757475083057\n",
      "Validation Batch #: 401, Validation Loss: 8.202989183459199, Validation Accuracy: 0.6312344139650873\n",
      "Epoch: 13/10\n",
      "Batch #: [001/298], Train Loss: 18.714876174926758, Train Accuracy: 0.125\n",
      "Batch #: [101/298], Train Loss: 17.144057160556905, Train Accuracy: 0.13675742574257427\n",
      "Batch #: [201/298], Train Loss: 17.940658986864992, Train Accuracy: 0.12328980099502487\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.15439224243164, Validation Accuracy: 0.6875\n",
      "Validation Batch #: 101, Validation Loss: 8.197920752043771, Validation Accuracy: 0.6599628712871287\n",
      "Validation Batch #: 201, Validation Loss: 8.200349333274424, Validation Accuracy: 0.6559390547263682\n",
      "Validation Batch #: 301, Validation Loss: 8.203525001424492, Validation Accuracy: 0.6499169435215947\n",
      "Validation Batch #: 401, Validation Loss: 8.202106570959685, Validation Accuracy: 0.6500155860349127\n",
      "Epoch: 14/10\n",
      "Batch #: [001/298], Train Loss: 14.59734058380127, Train Accuracy: 0.15625\n",
      "Batch #: [101/298], Train Loss: 16.08014762047494, Train Accuracy: 0.15748762376237624\n",
      "Batch #: [201/298], Train Loss: 17.065012077787028, Train Accuracy: 0.1388370646766169\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.155359268188477, Validation Accuracy: 0.6875\n",
      "Validation Batch #: 101, Validation Loss: 8.18909511943855, Validation Accuracy: 0.6680074257425742\n",
      "Validation Batch #: 201, Validation Loss: 8.188138549007586, Validation Accuracy: 0.6671330845771144\n",
      "Validation Batch #: 301, Validation Loss: 8.18868439696556, Validation Accuracy: 0.6661129568106312\n",
      "Validation Batch #: 401, Validation Loss: 8.188466607186562, Validation Accuracy: 0.6653678304239401\n",
      "Epoch: 15/10\n",
      "Batch #: [001/298], Train Loss: 19.458271026611328, Train Accuracy: 0.0625\n",
      "Batch #: [101/298], Train Loss: 15.400049492864326, Train Accuracy: 0.1639851485148515\n",
      "Batch #: [201/298], Train Loss: 16.342719082808614, Train Accuracy: 0.15236318407960198\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.174659729003906, Validation Accuracy: 0.6875\n",
      "Validation Batch #: 101, Validation Loss: 8.192098617553711, Validation Accuracy: 0.6624381188118812\n",
      "Validation Batch #: 201, Validation Loss: 8.18572437229441, Validation Accuracy: 0.667910447761194\n",
      "Validation Batch #: 301, Validation Loss: 8.187866755894252, Validation Accuracy: 0.6653862126245847\n",
      "Validation Batch #: 401, Validation Loss: 8.188263082147536, Validation Accuracy: 0.6649002493765586\n",
      "Epoch: 16/10\n",
      "Batch #: [001/298], Train Loss: 10.131209373474121, Train Accuracy: 0.34375\n",
      "Batch #: [101/298], Train Loss: 15.021900233655874, Train Accuracy: 0.1760519801980198\n",
      "Batch #: [201/298], Train Loss: 15.997768155377896, Train Accuracy: 0.15205223880597016\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.183677673339844, Validation Accuracy: 0.71875\n",
      "Validation Batch #: 101, Validation Loss: 8.196258601575796, Validation Accuracy: 0.6775990099009901\n",
      "Validation Batch #: 201, Validation Loss: 8.196912656376018, Validation Accuracy: 0.6763059701492538\n",
      "Validation Batch #: 301, Validation Loss: 8.200681499468528, Validation Accuracy: 0.6686046511627907\n",
      "Validation Batch #: 401, Validation Loss: 8.200195153157907, Validation Accuracy: 0.6701215710723192\n",
      "Epoch: 17/10\n",
      "Batch #: [001/298], Train Loss: 14.852659225463867, Train Accuracy: 0.1875\n",
      "Batch #: [101/298], Train Loss: 14.443171595582868, Train Accuracy: 0.1806930693069307\n",
      "Batch #: [201/298], Train Loss: 15.349350673049244, Train Accuracy: 0.16930970149253732\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.254213333129883, Validation Accuracy: 0.59375\n",
      "Validation Batch #: 101, Validation Loss: 8.185831343773568, Validation Accuracy: 0.6875\n",
      "Validation Batch #: 201, Validation Loss: 8.188516806607222, Validation Accuracy: 0.6820584577114428\n",
      "Validation Batch #: 301, Validation Loss: 8.190595668019647, Validation Accuracy: 0.6789867109634552\n",
      "Validation Batch #: 401, Validation Loss: 8.192825376838817, Validation Accuracy: 0.6763559850374065\n",
      "Epoch: 18/10\n",
      "Batch #: [001/298], Train Loss: 14.61075210571289, Train Accuracy: 0.1875\n",
      "Batch #: [101/298], Train Loss: 13.699635977792267, Train Accuracy: 0.20266089108910892\n",
      "Batch #: [201/298], Train Loss: 14.58105199728439, Train Accuracy: 0.18516791044776118\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.150131225585938, Validation Accuracy: 0.6875\n",
      "Validation Batch #: 101, Validation Loss: 8.177221269890813, Validation Accuracy: 0.6782178217821783\n",
      "Validation Batch #: 201, Validation Loss: 8.180108791560082, Validation Accuracy: 0.6742848258706468\n",
      "Validation Batch #: 301, Validation Loss: 8.17609117197436, Validation Accuracy: 0.6790905315614618\n",
      "Validation Batch #: 401, Validation Loss: 8.177859011433666, Validation Accuracy: 0.6777587281795511\n",
      "Epoch: 19/10\n",
      "Batch #: [001/298], Train Loss: 9.741695404052734, Train Accuracy: 0.25\n",
      "Batch #: [101/298], Train Loss: 12.732503277240413, Train Accuracy: 0.20606435643564355\n",
      "Batch #: [201/298], Train Loss: 13.941565475653654, Train Accuracy: 0.1881218905472637\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.104098320007324, Validation Accuracy: 0.84375\n",
      "Validation Batch #: 101, Validation Loss: 8.194766431751818, Validation Accuracy: 0.6757425742574258\n",
      "Validation Batch #: 201, Validation Loss: 8.186123112540933, Validation Accuracy: 0.6861007462686567\n",
      "Validation Batch #: 301, Validation Loss: 8.18614872903919, Validation Accuracy: 0.6850083056478405\n",
      "Validation Batch #: 401, Validation Loss: 8.184639788030687, Validation Accuracy: 0.6859413965087282\n",
      "Epoch: 20/10\n",
      "Batch #: [001/298], Train Loss: 9.511117935180664, Train Accuracy: 0.4375\n",
      "Batch #: [101/298], Train Loss: 12.424786973707747, Train Accuracy: 0.2264851485148515\n",
      "Batch #: [201/298], Train Loss: 13.45265598202226, Train Accuracy: 0.20304726368159204\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.145734786987305, Validation Accuracy: 0.71875\n",
      "Validation Batch #: 101, Validation Loss: 8.174979455400221, Validation Accuracy: 0.6964727722772277\n",
      "Validation Batch #: 201, Validation Loss: 8.169393937979171, Validation Accuracy: 0.7013370646766169\n",
      "Validation Batch #: 301, Validation Loss: 8.169971184081017, Validation Accuracy: 0.6989202657807309\n",
      "Validation Batch #: 401, Validation Loss: 8.170142073881001, Validation Accuracy: 0.69856608478803\n",
      "Epoch: 21/10\n",
      "Batch #: [001/298], Train Loss: 15.093165397644043, Train Accuracy: 0.1875\n",
      "Batch #: [101/298], Train Loss: 11.892624340435066, Train Accuracy: 0.21998762376237624\n",
      "Batch #: [201/298], Train Loss: 13.009644202331998, Train Accuracy: 0.20366915422885573\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.084978103637695, Validation Accuracy: 0.84375\n",
      "Validation Batch #: 101, Validation Loss: 8.169281204148094, Validation Accuracy: 0.7048267326732673\n",
      "Validation Batch #: 201, Validation Loss: 8.172778727403328, Validation Accuracy: 0.7008706467661692\n",
      "Validation Batch #: 301, Validation Loss: 8.176702090672084, Validation Accuracy: 0.6963247508305648\n",
      "Validation Batch #: 401, Validation Loss: 8.17887655814687, Validation Accuracy: 0.694357855361596\n",
      "Epoch: 22/10\n",
      "Batch #: [001/298], Train Loss: 7.719462871551514, Train Accuracy: 0.375\n",
      "Batch #: [101/298], Train Loss: 11.441805650692174, Train Accuracy: 0.22462871287128713\n",
      "Batch #: [201/298], Train Loss: 12.505746608942895, Train Accuracy: 0.20833333333333334\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.170063972473145, Validation Accuracy: 0.6875\n",
      "Validation Batch #: 101, Validation Loss: 8.18572989548787, Validation Accuracy: 0.6921410891089109\n",
      "Validation Batch #: 201, Validation Loss: 8.18896135643347, Validation Accuracy: 0.6890547263681592\n",
      "Validation Batch #: 301, Validation Loss: 8.1897695991288, Validation Accuracy: 0.68781146179402\n",
      "Validation Batch #: 401, Validation Loss: 8.186617242427836, Validation Accuracy: 0.6913965087281796\n",
      "Epoch: 23/10\n",
      "Batch #: [001/298], Train Loss: 9.164969444274902, Train Accuracy: 0.53125\n",
      "Batch #: [101/298], Train Loss: 11.071298382069806, Train Accuracy: 0.23824257425742573\n",
      "Batch #: [201/298], Train Loss: 11.908810041437102, Train Accuracy: 0.22201492537313433\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.156625747680664, Validation Accuracy: 0.71875\n",
      "Validation Batch #: 101, Validation Loss: 8.156947041502093, Validation Accuracy: 0.7175123762376238\n",
      "Validation Batch #: 201, Validation Loss: 8.15985290565301, Validation Accuracy: 0.7137748756218906\n",
      "Validation Batch #: 301, Validation Loss: 8.16416032290538, Validation Accuracy: 0.7085755813953488\n",
      "Validation Batch #: 401, Validation Loss: 8.164640440905183, Validation Accuracy: 0.706748753117207\n",
      "Epoch: 24/10\n",
      "Batch #: [001/298], Train Loss: 10.58305835723877, Train Accuracy: 0.3125\n",
      "Batch #: [101/298], Train Loss: 10.392855408168074, Train Accuracy: 0.24597772277227722\n",
      "Batch #: [201/298], Train Loss: 11.362863758903238, Train Accuracy: 0.22745646766169153\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.196335792541504, Validation Accuracy: 0.71875\n",
      "Validation Batch #: 101, Validation Loss: 8.176167516425105, Validation Accuracy: 0.7060643564356436\n",
      "Validation Batch #: 201, Validation Loss: 8.1744699240917, Validation Accuracy: 0.7052238805970149\n",
      "Validation Batch #: 301, Validation Loss: 8.174769712048908, Validation Accuracy: 0.7056686046511628\n",
      "Validation Batch #: 401, Validation Loss: 8.173095555674108, Validation Accuracy: 0.7075280548628429\n",
      "Epoch: 25/10\n",
      "Batch #: [001/298], Train Loss: 10.0246000289917, Train Accuracy: 0.25\n",
      "Batch #: [101/298], Train Loss: 9.697323024863064, Train Accuracy: 0.27413366336633666\n",
      "Batch #: [201/298], Train Loss: 10.748384916960303, Train Accuracy: 0.24486940298507462\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.180899620056152, Validation Accuracy: 0.75\n",
      "Validation Batch #: 101, Validation Loss: 8.165112146056524, Validation Accuracy: 0.7094678217821783\n",
      "Validation Batch #: 201, Validation Loss: 8.167845839884743, Validation Accuracy: 0.7060012437810945\n",
      "Validation Batch #: 301, Validation Loss: 8.167860186377236, Validation Accuracy: 0.7066029900332226\n",
      "Validation Batch #: 401, Validation Loss: 8.167804920167994, Validation Accuracy: 0.7069825436408977\n",
      "Epoch: 26/10\n",
      "Batch #: [001/298], Train Loss: 7.128101348876953, Train Accuracy: 0.40625\n",
      "Batch #: [101/298], Train Loss: 9.476494368940298, Train Accuracy: 0.2698019801980198\n",
      "Batch #: [201/298], Train Loss: 10.440480637906203, Train Accuracy: 0.24564676616915423\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.216899871826172, Validation Accuracy: 0.6875\n",
      "Validation Batch #: 101, Validation Loss: 8.19178044914019, Validation Accuracy: 0.7020420792079208\n",
      "Validation Batch #: 201, Validation Loss: 8.188330916029896, Validation Accuracy: 0.705068407960199\n",
      "Validation Batch #: 301, Validation Loss: 8.185364089534925, Validation Accuracy: 0.709406146179402\n",
      "Validation Batch #: 401, Validation Loss: 8.185091477677114, Validation Accuracy: 0.7103335411471322\n",
      "Epoch: 27/10\n",
      "Batch #: [001/298], Train Loss: 7.9019269943237305, Train Accuracy: 0.3125\n",
      "Batch #: [101/298], Train Loss: 8.914320738008707, Train Accuracy: 0.28217821782178215\n",
      "Batch #: [201/298], Train Loss: 9.764606667988335, Train Accuracy: 0.2610385572139303\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.117005348205566, Validation Accuracy: 0.75\n",
      "Validation Batch #: 101, Validation Loss: 8.182003276182874, Validation Accuracy: 0.6912128712871287\n",
      "Validation Batch #: 201, Validation Loss: 8.171240944174391, Validation Accuracy: 0.7064676616915423\n",
      "Validation Batch #: 301, Validation Loss: 8.168420759942444, Validation Accuracy: 0.7089908637873754\n",
      "Validation Batch #: 401, Validation Loss: 8.166018343328538, Validation Accuracy: 0.7125935162094763\n",
      "Epoch: 28/10\n",
      "Batch #: [001/298], Train Loss: 5.91997766494751, Train Accuracy: 0.46875\n",
      "Batch #: [101/298], Train Loss: 8.576904768990998, Train Accuracy: 0.27722772277227725\n",
      "Batch #: [201/298], Train Loss: 9.30952279959152, Train Accuracy: 0.2605721393034826\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.259355545043945, Validation Accuracy: 0.625\n",
      "Validation Batch #: 101, Validation Loss: 8.156482772071763, Validation Accuracy: 0.7150371287128713\n",
      "Validation Batch #: 201, Validation Loss: 8.157434387586603, Validation Accuracy: 0.7140858208955224\n",
      "Validation Batch #: 301, Validation Loss: 8.15883701109015, Validation Accuracy: 0.7109634551495017\n",
      "Validation Batch #: 401, Validation Loss: 8.156785660551076, Validation Accuracy: 0.714931421446384\n",
      "Epoch: 29/10\n",
      "Batch #: [001/298], Train Loss: 6.9942755699157715, Train Accuracy: 0.34375\n",
      "Batch #: [101/298], Train Loss: 7.9679521003572065, Train Accuracy: 0.297029702970297\n",
      "Batch #: [201/298], Train Loss: 8.955834187085356, Train Accuracy: 0.26710199004975127\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.215911865234375, Validation Accuracy: 0.65625\n",
      "Validation Batch #: 101, Validation Loss: 8.168866563551497, Validation Accuracy: 0.713799504950495\n",
      "Validation Batch #: 201, Validation Loss: 8.170089541383051, Validation Accuracy: 0.7106654228855721\n",
      "Validation Batch #: 301, Validation Loss: 8.169941271658356, Validation Accuracy: 0.7109634551495017\n",
      "Validation Batch #: 401, Validation Loss: 8.16795825720428, Validation Accuracy: 0.7139183291770573\n",
      "Epoch: 30/10\n",
      "Batch #: [001/298], Train Loss: 7.445703506469727, Train Accuracy: 0.28125\n",
      "Batch #: [101/298], Train Loss: 5.861309004302072, Train Accuracy: 0.43254950495049505\n",
      "Batch #: [201/298], Train Loss: 5.425686123952343, Train Accuracy: 0.44636194029850745\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 7.99257755279541, Validation Accuracy: 0.84375\n",
      "Validation Batch #: 101, Validation Loss: 8.103965513777025, Validation Accuracy: 0.7122524752475248\n",
      "Validation Batch #: 201, Validation Loss: 8.104522999246322, Validation Accuracy: 0.7137748756218906\n",
      "Validation Batch #: 301, Validation Loss: 8.10317881004359, Validation Accuracy: 0.7153239202657807\n",
      "Validation Batch #: 401, Validation Loss: 8.100305059009656, Validation Accuracy: 0.7194513715710723\n",
      "Epoch: 31/10\n",
      "Batch #: [001/298], Train Loss: 2.662515878677368, Train Accuracy: 0.65625\n",
      "Batch #: [101/298], Train Loss: 3.147239663813374, Train Accuracy: 0.5829207920792079\n",
      "Batch #: [201/298], Train Loss: 3.176981832554091, Train Accuracy: 0.5887748756218906\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.162736892700195, Validation Accuracy: 0.625\n",
      "Validation Batch #: 101, Validation Loss: 8.09061299692286, Validation Accuracy: 0.7193688118811881\n",
      "Validation Batch #: 201, Validation Loss: 8.085877088765006, Validation Accuracy: 0.7243470149253731\n",
      "Validation Batch #: 301, Validation Loss: 8.087658909072115, Validation Accuracy: 0.7231104651162791\n",
      "Validation Batch #: 401, Validation Loss: 8.089509606064109, Validation Accuracy: 0.7199189526184538\n",
      "Epoch: 32/10\n",
      "Batch #: [001/298], Train Loss: 1.2303712368011475, Train Accuracy: 0.65625\n",
      "Batch #: [101/298], Train Loss: 2.1426833367141165, Train Accuracy: 0.6652227722772277\n",
      "Batch #: [201/298], Train Loss: 2.0665037131020383, Train Accuracy: 0.6705534825870647\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.192770004272461, Validation Accuracy: 0.5625\n",
      "Validation Batch #: 101, Validation Loss: 8.085961658175629, Validation Accuracy: 0.713799504950495\n",
      "Validation Batch #: 201, Validation Loss: 8.078549434889608, Validation Accuracy: 0.7237251243781094\n",
      "Validation Batch #: 301, Validation Loss: 8.081864529669879, Validation Accuracy: 0.7196843853820598\n",
      "Validation Batch #: 401, Validation Loss: 8.081642123529145, Validation Accuracy: 0.7199968827930174\n",
      "Epoch: 33/10\n",
      "Batch #: [001/298], Train Loss: 0.33518531918525696, Train Accuracy: 0.875\n",
      "Batch #: [101/298], Train Loss: 1.108052335315301, Train Accuracy: 0.744740099009901\n",
      "Batch #: [201/298], Train Loss: 1.1815556945459944, Train Accuracy: 0.7456467661691543\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.123638153076172, Validation Accuracy: 0.6875\n",
      "Validation Batch #: 101, Validation Loss: 8.07873784433497, Validation Accuracy: 0.7162747524752475\n",
      "Validation Batch #: 201, Validation Loss: 8.076945395018925, Validation Accuracy: 0.7192164179104478\n",
      "Validation Batch #: 301, Validation Loss: 8.07508488113302, Validation Accuracy: 0.7208264119601329\n",
      "Validation Batch #: 401, Validation Loss: 8.075563305928522, Validation Accuracy: 0.720074812967581\n",
      "Epoch: 34/10\n",
      "Batch #: [001/298], Train Loss: 0.4933985471725464, Train Accuracy: 0.8125\n",
      "Batch #: [101/298], Train Loss: 0.6629718860857982, Train Accuracy: 0.7985767326732673\n",
      "Batch #: [201/298], Train Loss: 0.6651339568423608, Train Accuracy: 0.7977300995024875\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.039260864257812, Validation Accuracy: 0.75\n",
      "Validation Batch #: 101, Validation Loss: 8.066998779183567, Validation Accuracy: 0.7233910891089109\n",
      "Validation Batch #: 201, Validation Loss: 8.06879853965038, Validation Accuracy: 0.7213930348258707\n",
      "Validation Batch #: 301, Validation Loss: 8.069608959248692, Validation Accuracy: 0.7203073089700996\n",
      "Validation Batch #: 401, Validation Loss: 8.07024996536331, Validation Accuracy: 0.7196851620947631\n",
      "Epoch: 35/10\n",
      "Batch #: [001/298], Train Loss: 0.2416239231824875, Train Accuracy: 0.875\n",
      "Batch #: [101/298], Train Loss: 0.2757097471915739, Train Accuracy: 0.864480198019802\n",
      "Batch #: [201/298], Train Loss: 0.2930131352689599, Train Accuracy: 0.8606965174129353\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.102696418762207, Validation Accuracy: 0.6875\n",
      "Validation Batch #: 101, Validation Loss: 8.062703363966234, Validation Accuracy: 0.7261757425742574\n",
      "Validation Batch #: 201, Validation Loss: 8.06461983533641, Validation Accuracy: 0.7238805970149254\n",
      "Validation Batch #: 301, Validation Loss: 8.0689931628712, Validation Accuracy: 0.7186461794019934\n",
      "Validation Batch #: 401, Validation Loss: 8.068131692986238, Validation Accuracy: 0.7195293017456359\n",
      "Epoch: 36/10\n",
      "Batch #: [001/298], Train Loss: 0.12827128171920776, Train Accuracy: 0.8125\n",
      "Batch #: [101/298], Train Loss: 0.1265799999660651, Train Accuracy: 0.9016089108910891\n",
      "Batch #: [201/298], Train Loss: 0.12686126643519, Train Accuracy: 0.9000310945273632\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.175800323486328, Validation Accuracy: 0.59375\n",
      "Validation Batch #: 101, Validation Loss: 8.06837762228333, Validation Accuracy: 0.7144183168316832\n",
      "Validation Batch #: 201, Validation Loss: 8.072837703856663, Validation Accuracy: 0.7094216417910447\n",
      "Validation Batch #: 301, Validation Loss: 8.065992914561022, Validation Accuracy: 0.7180232558139535\n",
      "Validation Batch #: 401, Validation Loss: 8.064791662734644, Validation Accuracy: 0.7194513715710723\n",
      "Epoch: 37/10\n",
      "Batch #: [001/298], Train Loss: 0.0027337055653333664, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.08543476846912965, Train Accuracy: 0.9170792079207921\n",
      "Batch #: [201/298], Train Loss: 0.08390874518261454, Train Accuracy: 0.9168221393034826\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.115675926208496, Validation Accuracy: 0.65625\n",
      "Validation Batch #: 101, Validation Loss: 8.066283750061942, Validation Accuracy: 0.7168935643564357\n",
      "Validation Batch #: 201, Validation Loss: 8.062201677863278, Validation Accuracy: 0.7221703980099502\n",
      "Validation Batch #: 301, Validation Loss: 8.0629971859067, Validation Accuracy: 0.7212416943521595\n",
      "Validation Batch #: 401, Validation Loss: 8.064602501077248, Validation Accuracy: 0.7196851620947631\n",
      "Epoch: 38/10\n",
      "Batch #: [001/298], Train Loss: 0.0004007189127150923, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.03843034495431572, Train Accuracy: 0.9334777227722773\n",
      "Batch #: [201/298], Train Loss: 0.045061339270692835, Train Accuracy: 0.9323694029850746\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.07517147064209, Validation Accuracy: 0.6875\n",
      "Validation Batch #: 101, Validation Loss: 8.069681559458818, Validation Accuracy: 0.7100866336633663\n",
      "Validation Batch #: 201, Validation Loss: 8.063220436893292, Validation Accuracy: 0.71875\n",
      "Validation Batch #: 301, Validation Loss: 8.064245277861028, Validation Accuracy: 0.7179194352159468\n",
      "Validation Batch #: 401, Validation Loss: 8.062376515823706, Validation Accuracy: 0.7203865336658354\n",
      "Epoch: 39/10\n",
      "Batch #: [001/298], Train Loss: 0.03181840479373932, Train Accuracy: 0.9375\n",
      "Batch #: [101/298], Train Loss: 0.03752408639177315, Train Accuracy: 0.9350247524752475\n",
      "Batch #: [201/298], Train Loss: 0.03182952160728402, Train Accuracy: 0.9399875621890548\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 7.934402942657471, Validation Accuracy: 0.875\n",
      "Validation Batch #: 101, Validation Loss: 8.05515993231594, Validation Accuracy: 0.7277227722772277\n",
      "Validation Batch #: 201, Validation Loss: 8.06213061489276, Validation Accuracy: 0.7190609452736318\n",
      "Validation Batch #: 301, Validation Loss: 8.062268247636053, Validation Accuracy: 0.71906146179402\n",
      "Validation Batch #: 401, Validation Loss: 8.062166634937771, Validation Accuracy: 0.7192175810473815\n",
      "Epoch: 40/10\n",
      "Batch #: [001/298], Train Loss: 0.006868917495012283, Train Accuracy: 0.9375\n",
      "Batch #: [101/298], Train Loss: 0.018008384665885353, Train Accuracy: 0.9523514851485149\n",
      "Batch #: [201/298], Train Loss: 0.01977747754967845, Train Accuracy: 0.9482276119402985\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.086174964904785, Validation Accuracy: 0.6875\n",
      "Validation Batch #: 101, Validation Loss: 8.067108607528233, Validation Accuracy: 0.7119430693069307\n",
      "Validation Batch #: 201, Validation Loss: 8.062889912828284, Validation Accuracy: 0.7164179104477612\n",
      "Validation Batch #: 301, Validation Loss: 8.060936284619709, Validation Accuracy: 0.71906146179402\n",
      "Validation Batch #: 401, Validation Loss: 8.061303597733266, Validation Accuracy: 0.7189837905236908\n",
      "Epoch: 41/10\n",
      "Batch #: [001/298], Train Loss: 0.0002180021838285029, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.01960773637386923, Train Accuracy: 0.9504950495049505\n",
      "Batch #: [201/298], Train Loss: 0.015035880339011818, Train Accuracy: 0.9552238805970149\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 7.982273101806641, Validation Accuracy: 0.8125\n",
      "Validation Batch #: 101, Validation Loss: 8.063578388478497, Validation Accuracy: 0.7159653465346535\n",
      "Validation Batch #: 201, Validation Loss: 8.066098452800542, Validation Accuracy: 0.7137748756218906\n",
      "Validation Batch #: 301, Validation Loss: 8.063878442757945, Validation Accuracy: 0.7167774086378738\n",
      "Validation Batch #: 401, Validation Loss: 8.06155740233728, Validation Accuracy: 0.7196072319201995\n",
      "Epoch: 42/10\n",
      "Batch #: [001/298], Train Loss: 4.6106997615424916e-05, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.007956386584066765, Train Accuracy: 0.963180693069307\n",
      "Batch #: [201/298], Train Loss: 0.008642029236340538, Train Accuracy: 0.9606654228855721\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.188041687011719, Validation Accuracy: 0.5625\n",
      "Validation Batch #: 101, Validation Loss: 8.059393075433109, Validation Accuracy: 0.7218440594059405\n",
      "Validation Batch #: 201, Validation Loss: 8.062380465702038, Validation Accuracy: 0.7184390547263682\n",
      "Validation Batch #: 301, Validation Loss: 8.061012927083874, Validation Accuracy: 0.7195805647840532\n",
      "Validation Batch #: 401, Validation Loss: 8.060409090465441, Validation Accuracy: 0.7203086034912718\n",
      "Epoch: 43/10\n",
      "Batch #: [001/298], Train Loss: 0.00020683760521933436, Train Accuracy: 0.96875\n",
      "Batch #: [101/298], Train Loss: 0.008876136006917234, Train Accuracy: 0.96875\n",
      "Batch #: [201/298], Train Loss: 0.009755877720151749, Train Accuracy: 0.9662624378109452\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.090655326843262, Validation Accuracy: 0.6875\n",
      "Validation Batch #: 101, Validation Loss: 8.062364054198312, Validation Accuracy: 0.7165841584158416\n",
      "Validation Batch #: 201, Validation Loss: 8.060220751596328, Validation Accuracy: 0.7185945273631841\n",
      "Validation Batch #: 301, Validation Loss: 8.059627528206455, Validation Accuracy: 0.7197882059800664\n",
      "Validation Batch #: 401, Validation Loss: 8.060173832567553, Validation Accuracy: 0.7194513715710723\n",
      "Epoch: 44/10\n",
      "Batch #: [001/298], Train Loss: 0.0024611593689769506, Train Accuracy: 0.96875\n",
      "Batch #: [101/298], Train Loss: 0.008633016911944921, Train Accuracy: 0.9650371287128713\n",
      "Batch #: [201/298], Train Loss: 0.007784835996827877, Train Accuracy: 0.9645522388059702\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.089759826660156, Validation Accuracy: 0.6875\n",
      "Validation Batch #: 101, Validation Loss: 8.052702436352721, Validation Accuracy: 0.7289603960396039\n",
      "Validation Batch #: 201, Validation Loss: 8.057159414338829, Validation Accuracy: 0.7235696517412935\n",
      "Validation Batch #: 301, Validation Loss: 8.059174919445253, Validation Accuracy: 0.7212416943521595\n",
      "Validation Batch #: 401, Validation Loss: 8.059949009198501, Validation Accuracy: 0.7201527431421446\n",
      "Epoch: 45/10\n",
      "Batch #: [001/298], Train Loss: 0.000655030773486942, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.005110470488093012, Train Accuracy: 0.9681311881188119\n",
      "Batch #: [201/298], Train Loss: 0.004639110721131264, Train Accuracy: 0.9715485074626866\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.113642692565918, Validation Accuracy: 0.65625\n",
      "Validation Batch #: 101, Validation Loss: 8.050996752068547, Validation Accuracy: 0.7308168316831684\n",
      "Validation Batch #: 201, Validation Loss: 8.06025329276697, Validation Accuracy: 0.7198383084577115\n",
      "Validation Batch #: 301, Validation Loss: 8.060281587201496, Validation Accuracy: 0.7193729235880398\n",
      "Validation Batch #: 401, Validation Loss: 8.059739671740449, Validation Accuracy: 0.720074812967581\n",
      "Epoch: 46/10\n",
      "Batch #: [001/298], Train Loss: 1.3526718248613179e-05, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.004418266391142667, Train Accuracy: 0.9706064356435643\n",
      "Batch #: [201/298], Train Loss: 0.004462387054336975, Train Accuracy: 0.9712375621890548\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 7.984888553619385, Validation Accuracy: 0.8125\n",
      "Validation Batch #: 101, Validation Loss: 8.059209450636759, Validation Accuracy: 0.7206064356435643\n",
      "Validation Batch #: 201, Validation Loss: 8.058981537225828, Validation Accuracy: 0.7212375621890548\n",
      "Validation Batch #: 301, Validation Loss: 8.060483064366338, Validation Accuracy: 0.7193729235880398\n",
      "Validation Batch #: 401, Validation Loss: 8.06022821816423, Validation Accuracy: 0.7196851620947631\n",
      "Epoch: 47/10\n",
      "Batch #: [001/298], Train Loss: 0.0007836502627469599, Train Accuracy: 0.96875\n",
      "Batch #: [101/298], Train Loss: 0.006548972886201965, Train Accuracy: 0.9727722772277227\n",
      "Batch #: [201/298], Train Loss: 0.005865169010904262, Train Accuracy: 0.9723258706467661\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.134092330932617, Validation Accuracy: 0.625\n",
      "Validation Batch #: 101, Validation Loss: 8.063831055518424, Validation Accuracy: 0.7165841584158416\n",
      "Validation Batch #: 201, Validation Loss: 8.062192665403755, Validation Accuracy: 0.7179726368159204\n",
      "Validation Batch #: 301, Validation Loss: 8.05798663174195, Validation Accuracy: 0.7233181063122923\n",
      "Validation Batch #: 401, Validation Loss: 8.060536470199166, Validation Accuracy: 0.720074812967581\n",
      "Epoch: 48/10\n",
      "Batch #: [001/298], Train Loss: 0.0029863344971090555, Train Accuracy: 0.96875\n",
      "Batch #: [101/298], Train Loss: 0.002653426378072812, Train Accuracy: 0.9820544554455446\n",
      "Batch #: [201/298], Train Loss: 0.002638535291546972, Train Accuracy: 0.9797885572139303\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 7.935767650604248, Validation Accuracy: 0.875\n",
      "Validation Batch #: 101, Validation Loss: 8.055426956403373, Validation Accuracy: 0.7252475247524752\n",
      "Validation Batch #: 201, Validation Loss: 8.062803852024363, Validation Accuracy: 0.7164179104477612\n",
      "Validation Batch #: 301, Validation Loss: 8.058935319070404, Validation Accuracy: 0.7207225913621262\n",
      "Validation Batch #: 401, Validation Loss: 8.059091500213318, Validation Accuracy: 0.720464463840399\n",
      "Epoch: 49/10\n",
      "Batch #: [001/298], Train Loss: 0.0005923165590502322, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.003172907564602259, Train Accuracy: 0.9746287128712872\n",
      "Batch #: [201/298], Train Loss: 0.003982139821420869, Train Accuracy: 0.9729477611940298\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 7.957577228546143, Validation Accuracy: 0.84375\n",
      "Validation Batch #: 101, Validation Loss: 8.080562926755093, Validation Accuracy: 0.6949257425742574\n",
      "Validation Batch #: 201, Validation Loss: 8.069101777242784, Validation Accuracy: 0.7081778606965174\n",
      "Validation Batch #: 301, Validation Loss: 8.06119229231166, Validation Accuracy: 0.7177117940199336\n",
      "Validation Batch #: 401, Validation Loss: 8.059826773598306, Validation Accuracy: 0.7193734413965087\n",
      "Epoch: 50/10\n",
      "Batch #: [001/298], Train Loss: 0.0025610255543142557, Train Accuracy: 0.9375\n",
      "Batch #: [101/298], Train Loss: 0.0029250677423488464, Train Accuracy: 0.9764851485148515\n",
      "Batch #: [201/298], Train Loss: 0.003675408604308291, Train Accuracy: 0.9759017412935324\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.01481819152832, Validation Accuracy: 0.78125\n",
      "Validation Batch #: 101, Validation Loss: 8.062343238603951, Validation Accuracy: 0.7178217821782178\n",
      "Validation Batch #: 201, Validation Loss: 8.062395110059141, Validation Accuracy: 0.7176616915422885\n",
      "Validation Batch #: 301, Validation Loss: 8.059083520376008, Validation Accuracy: 0.7213455149501661\n",
      "Validation Batch #: 401, Validation Loss: 8.06022485176524, Validation Accuracy: 0.7198410224438903\n",
      "Epoch: 51/10\n",
      "Batch #: [001/298], Train Loss: 0.0001853788853622973, Train Accuracy: 0.96875\n",
      "Batch #: [101/298], Train Loss: 0.0017778619246497994, Train Accuracy: 0.9832920792079208\n",
      "Batch #: [201/298], Train Loss: 0.0023749438699957152, Train Accuracy: 0.9797885572139303\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.059173583984375, Validation Accuracy: 0.71875\n",
      "Validation Batch #: 101, Validation Loss: 8.055806131646184, Validation Accuracy: 0.7230816831683168\n",
      "Validation Batch #: 201, Validation Loss: 8.060406599471818, Validation Accuracy: 0.7175062189054726\n",
      "Validation Batch #: 301, Validation Loss: 8.058045247860525, Validation Accuracy: 0.720514950166113\n",
      "Validation Batch #: 401, Validation Loss: 8.058612552366947, Validation Accuracy: 0.7198410224438903\n",
      "Epoch: 52/10\n",
      "Batch #: [001/298], Train Loss: 0.000741702679079026, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.00478411573490661, Train Accuracy: 0.9693688118811881\n",
      "Batch #: [201/298], Train Loss: 0.003815742785391692, Train Accuracy: 0.9717039800995025\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.003764152526855, Validation Accuracy: 0.78125\n",
      "Validation Batch #: 101, Validation Loss: 8.058523862668784, Validation Accuracy: 0.7193688118811881\n",
      "Validation Batch #: 201, Validation Loss: 8.053789383143334, Validation Accuracy: 0.724657960199005\n",
      "Validation Batch #: 301, Validation Loss: 8.060280349959566, Validation Accuracy: 0.7171926910299004\n",
      "Validation Batch #: 401, Validation Loss: 8.058164911674442, Validation Accuracy: 0.7199968827930174\n",
      "Epoch: 53/10\n",
      "Batch #: [001/298], Train Loss: 0.008893179707229137, Train Accuracy: 0.9375\n",
      "Batch #: [101/298], Train Loss: 0.004312164462855507, Train Accuracy: 0.9761757425742574\n",
      "Batch #: [201/298], Train Loss: 0.003480074493809433, Train Accuracy: 0.9780783582089553\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.106450080871582, Validation Accuracy: 0.65625\n",
      "Validation Batch #: 101, Validation Loss: 8.07065473688711, Validation Accuracy: 0.7054455445544554\n",
      "Validation Batch #: 201, Validation Loss: 8.061376538442735, Validation Accuracy: 0.7168843283582089\n",
      "Validation Batch #: 301, Validation Loss: 8.055283853778015, Validation Accuracy: 0.7243563122923588\n",
      "Validation Batch #: 401, Validation Loss: 8.057634674700122, Validation Accuracy: 0.721399625935162\n",
      "Epoch: 54/10\n",
      "Batch #: [001/298], Train Loss: 0.0018026662291958928, Train Accuracy: 0.96875\n",
      "Batch #: [101/298], Train Loss: 0.0023957996115160935, Train Accuracy: 0.9777227722772277\n",
      "Batch #: [201/298], Train Loss: 0.002717311678580288, Train Accuracy: 0.9794776119402985\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.086800575256348, Validation Accuracy: 0.6875\n",
      "Validation Batch #: 101, Validation Loss: 8.059688671980753, Validation Accuracy: 0.71875\n",
      "Validation Batch #: 201, Validation Loss: 8.054756133710567, Validation Accuracy: 0.7243470149253731\n",
      "Validation Batch #: 301, Validation Loss: 8.05929502221041, Validation Accuracy: 0.71843853820598\n",
      "Validation Batch #: 401, Validation Loss: 8.058842064436535, Validation Accuracy: 0.719139650872818\n",
      "Epoch: 55/10\n",
      "Batch #: [001/298], Train Loss: 0.0003790787886828184, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0022083597810652095, Train Accuracy: 0.9789603960396039\n",
      "Batch #: [201/298], Train Loss: 0.0019235730095052662, Train Accuracy: 0.9807213930348259\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 7.980574131011963, Validation Accuracy: 0.8125\n",
      "Validation Batch #: 101, Validation Loss: 8.057663317954185, Validation Accuracy: 0.7209158415841584\n",
      "Validation Batch #: 201, Validation Loss: 8.057177939818272, Validation Accuracy: 0.7215485074626866\n",
      "Validation Batch #: 301, Validation Loss: 8.05800396421819, Validation Accuracy: 0.7200996677740864\n",
      "Validation Batch #: 401, Validation Loss: 8.058038303679659, Validation Accuracy: 0.7202306733167082\n",
      "Epoch: 56/10\n",
      "Batch #: [001/298], Train Loss: 4.789095328305848e-05, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0030611105214845367, Train Accuracy: 0.9814356435643564\n",
      "Batch #: [201/298], Train Loss: 0.002560095654541161, Train Accuracy: 0.9822761194029851\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.037283897399902, Validation Accuracy: 0.75\n",
      "Validation Batch #: 101, Validation Loss: 8.064199617593596, Validation Accuracy: 0.7119430693069307\n",
      "Validation Batch #: 201, Validation Loss: 8.059262996882348, Validation Accuracy: 0.7182835820895522\n",
      "Validation Batch #: 301, Validation Loss: 8.054065176814893, Validation Accuracy: 0.7246677740863787\n",
      "Validation Batch #: 401, Validation Loss: 8.056891038233502, Validation Accuracy: 0.7210099750623441\n",
      "Epoch: 57/10\n",
      "Batch #: [001/298], Train Loss: 0.00014444682165049016, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0014240822474225706, Train Accuracy: 0.9845297029702971\n",
      "Batch #: [201/298], Train Loss: 0.0020921133354886703, Train Accuracy: 0.9799440298507462\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.006508827209473, Validation Accuracy: 0.78125\n",
      "Validation Batch #: 101, Validation Loss: 8.063002761047665, Validation Accuracy: 0.7144183168316832\n",
      "Validation Batch #: 201, Validation Loss: 8.060585532022353, Validation Accuracy: 0.7171952736318408\n",
      "Validation Batch #: 301, Validation Loss: 8.060239845732122, Validation Accuracy: 0.7175041528239202\n",
      "Validation Batch #: 401, Validation Loss: 8.057926921178575, Validation Accuracy: 0.7201527431421446\n",
      "Epoch: 58/10\n",
      "Batch #: [001/298], Train Loss: 0.00019686615269165486, Train Accuracy: 0.96875\n",
      "Batch #: [101/298], Train Loss: 0.0018721658177211415, Train Accuracy: 0.9863861386138614\n",
      "Batch #: [201/298], Train Loss: 0.002047604804899031, Train Accuracy: 0.9838308457711443\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 7.979716777801514, Validation Accuracy: 0.8125\n",
      "Validation Batch #: 101, Validation Loss: 8.057284685644772, Validation Accuracy: 0.7209158415841584\n",
      "Validation Batch #: 201, Validation Loss: 8.061587262509475, Validation Accuracy: 0.7154850746268657\n",
      "Validation Batch #: 301, Validation Loss: 8.058752256374422, Validation Accuracy: 0.7188538205980066\n",
      "Validation Batch #: 401, Validation Loss: 8.057178424778128, Validation Accuracy: 0.7207761845386533\n",
      "Epoch: 59/10\n",
      "Batch #: [001/298], Train Loss: 1.7327161913271993e-05, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0016236167012644584, Train Accuracy: 0.9823638613861386\n",
      "Batch #: [201/298], Train Loss: 0.001961305931128287, Train Accuracy: 0.9830534825870647\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.061108589172363, Validation Accuracy: 0.71875\n",
      "Validation Batch #: 101, Validation Loss: 8.061882982159606, Validation Accuracy: 0.7156559405940595\n",
      "Validation Batch #: 201, Validation Loss: 8.062700209926017, Validation Accuracy: 0.7145522388059702\n",
      "Validation Batch #: 301, Validation Loss: 8.062570104567316, Validation Accuracy: 0.7147009966777409\n",
      "Validation Batch #: 401, Validation Loss: 8.059156488004765, Validation Accuracy: 0.7188279301745636\n",
      "Epoch: 60/10\n",
      "Batch #: [001/298], Train Loss: 0.004550494719296694, Train Accuracy: 0.9375\n",
      "Batch #: [101/298], Train Loss: 0.0018589223037984725, Train Accuracy: 0.9854579207920792\n",
      "Batch #: [201/298], Train Loss: 0.0021022031667845952, Train Accuracy: 0.9836753731343284\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 7.98283576965332, Validation Accuracy: 0.8125\n",
      "Validation Batch #: 101, Validation Loss: 8.050085440720663, Validation Accuracy: 0.7301980198019802\n",
      "Validation Batch #: 201, Validation Loss: 8.054011703130618, Validation Accuracy: 0.7252798507462687\n",
      "Validation Batch #: 301, Validation Loss: 8.059246918687789, Validation Accuracy: 0.7191652823920266\n",
      "Validation Batch #: 401, Validation Loss: 8.057930152017875, Validation Accuracy: 0.7208541147132169\n",
      "Epoch: 61/10\n",
      "Batch #: [001/298], Train Loss: 0.0011502814013510942, Train Accuracy: 0.9375\n",
      "Batch #: [101/298], Train Loss: 0.0014668647063354901, Train Accuracy: 0.9860767326732673\n",
      "Batch #: [201/298], Train Loss: 0.0017583172868717834, Train Accuracy: 0.9856965174129353\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.050514221191406, Validation Accuracy: 0.71875\n",
      "Validation Batch #: 101, Validation Loss: 8.05926531612283, Validation Accuracy: 0.7178217821782178\n",
      "Validation Batch #: 201, Validation Loss: 8.055155324698681, Validation Accuracy: 0.722481343283582\n",
      "Validation Batch #: 301, Validation Loss: 8.055749810811292, Validation Accuracy: 0.721968438538206\n",
      "Validation Batch #: 401, Validation Loss: 8.057758202873858, Validation Accuracy: 0.7196851620947631\n",
      "Epoch: 62/10\n",
      "Batch #: [001/298], Train Loss: 6.162983481772244e-05, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.00338382646014121, Train Accuracy: 0.9842202970297029\n",
      "Batch #: [201/298], Train Loss: 0.0029483565746999153, Train Accuracy: 0.9828980099502488\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.00224494934082, Validation Accuracy: 0.78125\n",
      "Validation Batch #: 101, Validation Loss: 8.065998082113738, Validation Accuracy: 0.7103960396039604\n",
      "Validation Batch #: 201, Validation Loss: 8.063635190327963, Validation Accuracy: 0.7133084577114428\n",
      "Validation Batch #: 301, Validation Loss: 8.060274619992786, Validation Accuracy: 0.7174003322259136\n",
      "Validation Batch #: 401, Validation Loss: 8.058274780425645, Validation Accuracy: 0.7195293017456359\n",
      "Epoch: 63/10\n",
      "Batch #: [001/298], Train Loss: 0.00020161340944468975, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0022402617826477724, Train Accuracy: 0.9801980198019802\n",
      "Batch #: [201/298], Train Loss: 0.0017701807994217078, Train Accuracy: 0.9839863184079602\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.034541130065918, Validation Accuracy: 0.75\n",
      "Validation Batch #: 101, Validation Loss: 8.054439931812853, Validation Accuracy: 0.7233910891089109\n",
      "Validation Batch #: 201, Validation Loss: 8.061733084531566, Validation Accuracy: 0.7143967661691543\n",
      "Validation Batch #: 301, Validation Loss: 8.058397958444994, Validation Accuracy: 0.7185423588039868\n",
      "Validation Batch #: 401, Validation Loss: 8.058196134400784, Validation Accuracy: 0.7186720698254364\n",
      "Epoch: 64/10\n",
      "Batch #: [001/298], Train Loss: 4.2558393033687025e-05, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0021124728798800826, Train Accuracy: 0.9826732673267327\n",
      "Batch #: [201/298], Train Loss: 0.0019876942319366317, Train Accuracy: 0.9841417910447762\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.010218620300293, Validation Accuracy: 0.78125\n",
      "Validation Batch #: 101, Validation Loss: 8.057440181769946, Validation Accuracy: 0.7212252475247525\n",
      "Validation Batch #: 201, Validation Loss: 8.05790638330564, Validation Accuracy: 0.7206156716417911\n",
      "Validation Batch #: 301, Validation Loss: 8.056726246577165, Validation Accuracy: 0.721656976744186\n",
      "Validation Batch #: 401, Validation Loss: 8.058608202565638, Validation Accuracy: 0.7194513715710723\n",
      "Epoch: 65/10\n",
      "Batch #: [001/298], Train Loss: 4.539112342172302e-05, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0012722802635769966, Train Accuracy: 0.9885519801980198\n",
      "Batch #: [201/298], Train Loss: 0.001384635483541908, Train Accuracy: 0.9874067164179104\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.113409996032715, Validation Accuracy: 0.65625\n",
      "Validation Batch #: 101, Validation Loss: 8.051203982664807, Validation Accuracy: 0.7274133663366337\n",
      "Validation Batch #: 201, Validation Loss: 8.053971418693884, Validation Accuracy: 0.7240360696517413\n",
      "Validation Batch #: 301, Validation Loss: 8.05775389243598, Validation Accuracy: 0.7195805647840532\n",
      "Validation Batch #: 401, Validation Loss: 8.057772560309887, Validation Accuracy: 0.7195293017456359\n",
      "Epoch: 66/10\n",
      "Batch #: [001/298], Train Loss: 4.763137621921487e-05, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0020136273017226244, Train Accuracy: 0.9836014851485149\n",
      "Batch #: [201/298], Train Loss: 0.0019322253746702415, Train Accuracy: 0.9836753731343284\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.036190032958984, Validation Accuracy: 0.75\n",
      "Validation Batch #: 101, Validation Loss: 8.057717172226104, Validation Accuracy: 0.7193688118811881\n",
      "Validation Batch #: 201, Validation Loss: 8.05853271484375, Validation Accuracy: 0.7175062189054726\n",
      "Validation Batch #: 301, Validation Loss: 8.058543211597938, Validation Accuracy: 0.7180232558139535\n",
      "Validation Batch #: 401, Validation Loss: 8.057020173108489, Validation Accuracy: 0.7198410224438903\n",
      "Epoch: 67/10\n",
      "Batch #: [001/298], Train Loss: 1.6396546925534494e-05, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0014103771754062425, Train Accuracy: 0.9882425742574258\n",
      "Batch #: [201/298], Train Loss: 0.0012207082292120934, Train Accuracy: 0.9877176616915423\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.006975173950195, Validation Accuracy: 0.78125\n",
      "Validation Batch #: 101, Validation Loss: 8.056716352406115, Validation Accuracy: 0.7212252475247525\n",
      "Validation Batch #: 201, Validation Loss: 8.056151565627673, Validation Accuracy: 0.7221703980099502\n",
      "Validation Batch #: 301, Validation Loss: 8.058025602486442, Validation Accuracy: 0.7203073089700996\n",
      "Validation Batch #: 401, Validation Loss: 8.059006119012238, Validation Accuracy: 0.7192175810473815\n",
      "Epoch: 68/10\n",
      "Batch #: [001/298], Train Loss: 3.4843544653995195e-06, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.00242471763846591, Train Accuracy: 0.9820544554455446\n",
      "Batch #: [201/298], Train Loss: 0.0023888817720060036, Train Accuracy: 0.9816542288557214\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.137507438659668, Validation Accuracy: 0.625\n",
      "Validation Batch #: 101, Validation Loss: 8.067286802990601, Validation Accuracy: 0.7100866336633663\n",
      "Validation Batch #: 201, Validation Loss: 8.061532383534447, Validation Accuracy: 0.7165733830845771\n",
      "Validation Batch #: 301, Validation Loss: 8.06140695774674, Validation Accuracy: 0.7161544850498339\n",
      "Validation Batch #: 401, Validation Loss: 8.058171529127772, Validation Accuracy: 0.7199968827930174\n",
      "Epoch: 69/10\n",
      "Batch #: [001/298], Train Loss: 6.690990994684398e-05, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0018646173610245614, Train Accuracy: 0.9823638613861386\n",
      "Batch #: [201/298], Train Loss: 0.001745821740795899, Train Accuracy: 0.9827425373134329\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 7.9753336906433105, Validation Accuracy: 0.8125\n",
      "Validation Batch #: 101, Validation Loss: 8.060126857002183, Validation Accuracy: 0.7172029702970297\n",
      "Validation Batch #: 201, Validation Loss: 8.05592682824206, Validation Accuracy: 0.7217039800995025\n",
      "Validation Batch #: 301, Validation Loss: 8.05680404707443, Validation Accuracy: 0.7209302325581395\n",
      "Validation Batch #: 401, Validation Loss: 8.05847018972002, Validation Accuracy: 0.7192175810473815\n",
      "Epoch: 70/10\n",
      "Batch #: [001/298], Train Loss: 3.54956864612177e-05, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0012527980600202907, Train Accuracy: 0.9866955445544554\n",
      "Batch #: [201/298], Train Loss: 0.0011951929173384353, Train Accuracy: 0.9860074626865671\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.113643646240234, Validation Accuracy: 0.65625\n",
      "Validation Batch #: 101, Validation Loss: 8.05101192587673, Validation Accuracy: 0.7289603960396039\n",
      "Validation Batch #: 201, Validation Loss: 8.05613122769256, Validation Accuracy: 0.7227922885572139\n",
      "Validation Batch #: 301, Validation Loss: 8.057545989850826, Validation Accuracy: 0.7212416943521595\n",
      "Validation Batch #: 401, Validation Loss: 8.05838755895372, Validation Accuracy: 0.7205423940149626\n",
      "Epoch: 71/10\n",
      "Batch #: [001/298], Train Loss: 3.3738466299837455e-05, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0010865150306150135, Train Accuracy: 0.989480198019802\n",
      "Batch #: [201/298], Train Loss: 0.0010264423879044983, Train Accuracy: 0.9889614427860697\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.115952491760254, Validation Accuracy: 0.65625\n",
      "Validation Batch #: 101, Validation Loss: 8.06003746183792, Validation Accuracy: 0.7178217821782178\n",
      "Validation Batch #: 201, Validation Loss: 8.056902887809336, Validation Accuracy: 0.7213930348258707\n",
      "Validation Batch #: 301, Validation Loss: 8.057138949929678, Validation Accuracy: 0.7206187707641196\n",
      "Validation Batch #: 401, Validation Loss: 8.057476547888092, Validation Accuracy: 0.7202306733167082\n",
      "Epoch: 72/10\n",
      "Batch #: [001/298], Train Loss: 0.00020431850862223655, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.001487477157908053, Train Accuracy: 0.9863861386138614\n",
      "Batch #: [201/298], Train Loss: 0.0015685245083914344, Train Accuracy: 0.9852300995024875\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.0566987991333, Validation Accuracy: 0.71875\n",
      "Validation Batch #: 101, Validation Loss: 8.057257458715156, Validation Accuracy: 0.719059405940594\n",
      "Validation Batch #: 201, Validation Loss: 8.055298596472289, Validation Accuracy: 0.7218594527363185\n",
      "Validation Batch #: 301, Validation Loss: 8.055227392139624, Validation Accuracy: 0.7221760797342193\n",
      "Validation Batch #: 401, Validation Loss: 8.05658994945802, Validation Accuracy: 0.7206203241895262\n",
      "Epoch: 73/10\n",
      "Batch #: [001/298], Train Loss: 4.728920885099797e-06, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0009814483824341254, Train Accuracy: 0.9876237623762376\n",
      "Batch #: [201/298], Train Loss: 0.0008744630679797551, Train Accuracy: 0.9892723880597015\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.107160568237305, Validation Accuracy: 0.65625\n",
      "Validation Batch #: 101, Validation Loss: 8.048832902813903, Validation Accuracy: 0.7320544554455446\n",
      "Validation Batch #: 201, Validation Loss: 8.059430762903014, Validation Accuracy: 0.7193718905472637\n",
      "Validation Batch #: 301, Validation Loss: 8.059478555406843, Validation Accuracy: 0.7191652823920266\n",
      "Validation Batch #: 401, Validation Loss: 8.058626432965818, Validation Accuracy: 0.7202306733167082\n",
      "Epoch: 74/10\n",
      "Batch #: [001/298], Train Loss: 0.0002830372250173241, Train Accuracy: 0.96875\n",
      "Batch #: [101/298], Train Loss: 0.003547989287108967, Train Accuracy: 0.9771039603960396\n",
      "Batch #: [201/298], Train Loss: 0.0036700913308492606, Train Accuracy: 0.9782338308457711\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.023825645446777, Validation Accuracy: 0.75\n",
      "Validation Batch #: 101, Validation Loss: 8.046902717930255, Validation Accuracy: 0.7311262376237624\n",
      "Validation Batch #: 201, Validation Loss: 8.051862102242845, Validation Accuracy: 0.7255907960199005\n",
      "Validation Batch #: 301, Validation Loss: 8.056793195464682, Validation Accuracy: 0.7194767441860465\n",
      "Validation Batch #: 401, Validation Loss: 8.057571799975083, Validation Accuracy: 0.7185941396508728\n",
      "Epoch: 75/10\n",
      "Batch #: [001/298], Train Loss: 0.0009124395437538624, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0010756876929609363, Train Accuracy: 0.9860767326732673\n",
      "Batch #: [201/298], Train Loss: 0.0012299952957413218, Train Accuracy: 0.9875621890547264\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.034531593322754, Validation Accuracy: 0.75\n",
      "Validation Batch #: 101, Validation Loss: 8.053413948210158, Validation Accuracy: 0.724009900990099\n",
      "Validation Batch #: 201, Validation Loss: 8.057467126134616, Validation Accuracy: 0.7189054726368159\n",
      "Validation Batch #: 301, Validation Loss: 8.054089851949698, Validation Accuracy: 0.7232142857142857\n",
      "Validation Batch #: 401, Validation Loss: 8.056331657114766, Validation Accuracy: 0.7206982543640897\n",
      "Epoch: 76/10\n",
      "Batch #: [001/298], Train Loss: 7.779714906064328e-06, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0015573563702948358, Train Accuracy: 0.9839108910891089\n",
      "Batch #: [201/298], Train Loss: 0.0014748992390621117, Train Accuracy: 0.9844527363184079\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.030933380126953, Validation Accuracy: 0.75\n",
      "Validation Batch #: 101, Validation Loss: 8.061943101410819, Validation Accuracy: 0.713180693069307\n",
      "Validation Batch #: 201, Validation Loss: 8.061585333809925, Validation Accuracy: 0.7140858208955224\n",
      "Validation Batch #: 301, Validation Loss: 8.058953202840101, Validation Accuracy: 0.7171926910299004\n",
      "Validation Batch #: 401, Validation Loss: 8.058166669193943, Validation Accuracy: 0.7185162094763092\n",
      "Epoch: 77/10\n",
      "Batch #: [001/298], Train Loss: 4.409376924741082e-05, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.001554263848416495, Train Accuracy: 0.9866955445544554\n",
      "Batch #: [201/298], Train Loss: 0.0012694628857949973, Train Accuracy: 0.9872512437810945\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.115697860717773, Validation Accuracy: 0.65625\n",
      "Validation Batch #: 101, Validation Loss: 8.067755902167594, Validation Accuracy: 0.7088490099009901\n",
      "Validation Batch #: 201, Validation Loss: 8.05983533669467, Validation Accuracy: 0.7182835820895522\n",
      "Validation Batch #: 301, Validation Loss: 8.056391429267453, Validation Accuracy: 0.7221760797342193\n",
      "Validation Batch #: 401, Validation Loss: 8.058542615457663, Validation Accuracy: 0.7194513715710723\n",
      "Epoch: 78/10\n",
      "Batch #: [001/298], Train Loss: 1.9063669242314063e-05, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0015310409934801723, Train Accuracy: 0.9876237623762376\n",
      "Batch #: [201/298], Train Loss: 0.0013161427454183444, Train Accuracy: 0.9870957711442786\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 7.954265117645264, Validation Accuracy: 0.84375\n",
      "Validation Batch #: 101, Validation Loss: 8.060346730864874, Validation Accuracy: 0.7162747524752475\n",
      "Validation Batch #: 201, Validation Loss: 8.05881880527705, Validation Accuracy: 0.7179726368159204\n",
      "Validation Batch #: 301, Validation Loss: 8.059627081468651, Validation Accuracy: 0.7171926910299004\n",
      "Validation Batch #: 401, Validation Loss: 8.057702278555777, Validation Accuracy: 0.7193734413965087\n",
      "Epoch: 79/10\n",
      "Batch #: [001/298], Train Loss: 6.785953155485913e-05, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.001377503570568992, Train Accuracy: 0.9879331683168316\n",
      "Batch #: [201/298], Train Loss: 0.00144531686743306, Train Accuracy: 0.9875621890547264\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.036545753479004, Validation Accuracy: 0.75\n",
      "Validation Batch #: 101, Validation Loss: 8.050602842085432, Validation Accuracy: 0.7286509900990099\n",
      "Validation Batch #: 201, Validation Loss: 8.052458886483416, Validation Accuracy: 0.7263681592039801\n",
      "Validation Batch #: 301, Validation Loss: 8.052873895017807, Validation Accuracy: 0.7259136212624585\n",
      "Validation Batch #: 401, Validation Loss: 8.058341540006033, Validation Accuracy: 0.7193734413965087\n",
      "Epoch: 80/10\n",
      "Batch #: [001/298], Train Loss: 0.00125429208856076, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0014959307168567193, Train Accuracy: 0.9885519801980198\n",
      "Batch #: [201/298], Train Loss: 0.0010526892215506308, Train Accuracy: 0.9891169154228856\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.008563041687012, Validation Accuracy: 0.78125\n",
      "Validation Batch #: 101, Validation Loss: 8.054837505416115, Validation Accuracy: 0.7230816831683168\n",
      "Validation Batch #: 201, Validation Loss: 8.052939614253258, Validation Accuracy: 0.7248134328358209\n",
      "Validation Batch #: 301, Validation Loss: 8.057722273855115, Validation Accuracy: 0.7195805647840532\n",
      "Validation Batch #: 401, Validation Loss: 8.058064237199817, Validation Accuracy: 0.7190617206982544\n",
      "Epoch: 81/10\n",
      "Batch #: [001/298], Train Loss: 0.0008659545565024018, Train Accuracy: 0.96875\n",
      "Batch #: [101/298], Train Loss: 0.000863180827383697, Train Accuracy: 0.9866955445544554\n",
      "Batch #: [201/298], Train Loss: 0.000925816369063022, Train Accuracy: 0.9891169154228856\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 7.981582164764404, Validation Accuracy: 0.8125\n",
      "Validation Batch #: 101, Validation Loss: 8.046257198447048, Validation Accuracy: 0.7320544554455446\n",
      "Validation Batch #: 201, Validation Loss: 8.050724129178631, Validation Accuracy: 0.7263681592039801\n",
      "Validation Batch #: 301, Validation Loss: 8.05367118258809, Validation Accuracy: 0.7230066445182725\n",
      "Validation Batch #: 401, Validation Loss: 8.055453777313232, Validation Accuracy: 0.7211658354114713\n",
      "Epoch: 82/10\n",
      "Batch #: [001/298], Train Loss: 5.86906389798969e-06, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0009720459340533215, Train Accuracy: 0.9897896039603961\n",
      "Batch #: [201/298], Train Loss: 0.0008690339386468545, Train Accuracy: 0.9898942786069652\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.080551147460938, Validation Accuracy: 0.6875\n",
      "Validation Batch #: 101, Validation Loss: 8.05520503355725, Validation Accuracy: 0.7224628712871287\n",
      "Validation Batch #: 201, Validation Loss: 8.057406954504364, Validation Accuracy: 0.7195273631840796\n",
      "Validation Batch #: 301, Validation Loss: 8.060044483488976, Validation Accuracy: 0.7164659468438538\n",
      "Validation Batch #: 401, Validation Loss: 8.057436753984105, Validation Accuracy: 0.7194513715710723\n",
      "Epoch: 83/10\n",
      "Batch #: [001/298], Train Loss: 7.607766019646078e-05, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0007660972470803515, Train Accuracy: 0.9922648514851485\n",
      "Batch #: [201/298], Train Loss: 0.0007075098311570915, Train Accuracy: 0.9928482587064676\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.006884574890137, Validation Accuracy: 0.78125\n",
      "Validation Batch #: 101, Validation Loss: 8.063608896614301, Validation Accuracy: 0.7125618811881188\n",
      "Validation Batch #: 201, Validation Loss: 8.062430206222913, Validation Accuracy: 0.7140858208955224\n",
      "Validation Batch #: 301, Validation Loss: 8.060302525263689, Validation Accuracy: 0.7165697674418605\n",
      "Validation Batch #: 401, Validation Loss: 8.058308635863877, Validation Accuracy: 0.7189058603491272\n",
      "Epoch: 84/10\n",
      "Batch #: [001/298], Train Loss: 0.0008131827344186604, Train Accuracy: 0.96875\n",
      "Batch #: [101/298], Train Loss: 0.0009914880974029434, Train Accuracy: 0.9888613861386139\n",
      "Batch #: [201/298], Train Loss: 0.0009165227703652451, Train Accuracy: 0.9892723880597015\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.010177612304688, Validation Accuracy: 0.78125\n",
      "Validation Batch #: 101, Validation Loss: 8.056497932660697, Validation Accuracy: 0.7212252475247525\n",
      "Validation Batch #: 201, Validation Loss: 8.05759754940052, Validation Accuracy: 0.7195273631840796\n",
      "Validation Batch #: 301, Validation Loss: 8.055053473311009, Validation Accuracy: 0.7225913621262459\n",
      "Validation Batch #: 401, Validation Loss: 8.057108877900236, Validation Accuracy: 0.7198410224438903\n",
      "Epoch: 85/10\n",
      "Batch #: [001/298], Train Loss: 3.3368476579198614e-05, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0007598879085446584, Train Accuracy: 0.9888613861386139\n",
      "Batch #: [201/298], Train Loss: 0.0010889955760022255, Train Accuracy: 0.9898942786069652\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.163677215576172, Validation Accuracy: 0.59375\n",
      "Validation Batch #: 101, Validation Loss: 8.060952342382752, Validation Accuracy: 0.7159653465346535\n",
      "Validation Batch #: 201, Validation Loss: 8.061914835403215, Validation Accuracy: 0.7147077114427861\n",
      "Validation Batch #: 301, Validation Loss: 8.057693201046053, Validation Accuracy: 0.7197882059800664\n",
      "Validation Batch #: 401, Validation Loss: 8.057031184360572, Validation Accuracy: 0.7205423940149626\n",
      "Epoch: 86/10\n",
      "Batch #: [001/298], Train Loss: 0.0002737802278716117, Train Accuracy: 0.96875\n",
      "Batch #: [101/298], Train Loss: 0.000810048937316113, Train Accuracy: 0.9907178217821783\n",
      "Batch #: [201/298], Train Loss: 0.001104275736469219, Train Accuracy: 0.9897388059701493\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 7.958850383758545, Validation Accuracy: 0.84375\n",
      "Validation Batch #: 101, Validation Loss: 8.055160904874896, Validation Accuracy: 0.7218440594059405\n",
      "Validation Batch #: 201, Validation Loss: 8.056880898736603, Validation Accuracy: 0.7199937810945274\n",
      "Validation Batch #: 301, Validation Loss: 8.058525619316734, Validation Accuracy: 0.7181270764119602\n",
      "Validation Batch #: 401, Validation Loss: 8.05738815940229, Validation Accuracy: 0.7196072319201995\n",
      "Epoch: 87/10\n",
      "Batch #: [001/298], Train Loss: 0.0009431421640329063, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.00048027134482033423, Train Accuracy: 0.989480198019802\n",
      "Batch #: [201/298], Train Loss: 0.0006682130183949921, Train Accuracy: 0.9894278606965174\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 7.9544267654418945, Validation Accuracy: 0.84375\n",
      "Validation Batch #: 101, Validation Loss: 8.051578951354074, Validation Accuracy: 0.7258663366336634\n",
      "Validation Batch #: 201, Validation Loss: 8.052637593663153, Validation Accuracy: 0.724502487562189\n",
      "Validation Batch #: 301, Validation Loss: 8.055631111626608, Validation Accuracy: 0.7210340531561462\n",
      "Validation Batch #: 401, Validation Loss: 8.057060190567055, Validation Accuracy: 0.7192175810473815\n",
      "Epoch: 88/10\n",
      "Batch #: [001/298], Train Loss: 7.088134225341491e-06, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0011887045509416736, Train Accuracy: 0.9913366336633663\n",
      "Batch #: [201/298], Train Loss: 0.0012546180585284175, Train Accuracy: 0.9888059701492538\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.0668363571167, Validation Accuracy: 0.71875\n",
      "Validation Batch #: 101, Validation Loss: 8.05549684373459, Validation Accuracy: 0.7209158415841584\n",
      "Validation Batch #: 201, Validation Loss: 8.054419548357304, Validation Accuracy: 0.7218594527363185\n",
      "Validation Batch #: 301, Validation Loss: 8.056368248011186, Validation Accuracy: 0.7196843853820598\n",
      "Validation Batch #: 401, Validation Loss: 8.056237745166122, Validation Accuracy: 0.7201527431421446\n",
      "Epoch: 89/10\n",
      "Batch #: [001/298], Train Loss: 0.00022116067702881992, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.001028436938513393, Train Accuracy: 0.9910272277227723\n",
      "Batch #: [201/298], Train Loss: 0.001871654185117564, Train Accuracy: 0.9897388059701493\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.088756561279297, Validation Accuracy: 0.6875\n",
      "Validation Batch #: 101, Validation Loss: 8.054922769565394, Validation Accuracy: 0.7233910891089109\n",
      "Validation Batch #: 201, Validation Loss: 8.0589706103007, Validation Accuracy: 0.71875\n",
      "Validation Batch #: 301, Validation Loss: 8.061936707987737, Validation Accuracy: 0.7151162790697675\n",
      "Validation Batch #: 401, Validation Loss: 8.058322586620834, Validation Accuracy: 0.7195293017456359\n",
      "Epoch: 90/10\n",
      "Batch #: [001/298], Train Loss: 6.256857159314677e-05, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0007642398196448184, Train Accuracy: 0.9916460396039604\n",
      "Batch #: [201/298], Train Loss: 0.0009524894442765074, Train Accuracy: 0.9906716417910447\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.055867195129395, Validation Accuracy: 0.71875\n",
      "Validation Batch #: 101, Validation Loss: 8.062588252643547, Validation Accuracy: 0.7128712871287128\n",
      "Validation Batch #: 201, Validation Loss: 8.060294687451416, Validation Accuracy: 0.7159514925373134\n",
      "Validation Batch #: 301, Validation Loss: 8.059848196086694, Validation Accuracy: 0.7161544850498339\n",
      "Validation Batch #: 401, Validation Loss: 8.057391714871375, Validation Accuracy: 0.7192175810473815\n",
      "Epoch: 91/10\n",
      "Batch #: [001/298], Train Loss: 0.0010214229114353657, Train Accuracy: 0.96875\n",
      "Batch #: [101/298], Train Loss: 0.0007450007692771371, Train Accuracy: 0.9907178217821783\n",
      "Batch #: [201/298], Train Loss: 0.0006711665096518751, Train Accuracy: 0.9909825870646766\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.030420303344727, Validation Accuracy: 0.75\n",
      "Validation Batch #: 101, Validation Loss: 8.043889763331649, Validation Accuracy: 0.7370049504950495\n",
      "Validation Batch #: 201, Validation Loss: 8.052433977079628, Validation Accuracy: 0.726523631840796\n",
      "Validation Batch #: 301, Validation Loss: 8.05949549183893, Validation Accuracy: 0.7182308970099668\n",
      "Validation Batch #: 401, Validation Loss: 8.057666550253394, Validation Accuracy: 0.7202306733167082\n",
      "Epoch: 92/10\n",
      "Batch #: [001/298], Train Loss: 0.0009038443677127361, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0007814890162290064, Train Accuracy: 0.9904084158415841\n",
      "Batch #: [201/298], Train Loss: 0.0007365452509851984, Train Accuracy: 0.9898942786069652\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.03775405883789, Validation Accuracy: 0.75\n",
      "Validation Batch #: 101, Validation Loss: 8.05983038231878, Validation Accuracy: 0.7162747524752475\n",
      "Validation Batch #: 201, Validation Loss: 8.056376172535455, Validation Accuracy: 0.7204601990049752\n",
      "Validation Batch #: 301, Validation Loss: 8.059240696042083, Validation Accuracy: 0.7171926910299004\n",
      "Validation Batch #: 401, Validation Loss: 8.056851366808884, Validation Accuracy: 0.7201527431421446\n",
      "Epoch: 93/10\n",
      "Batch #: [001/298], Train Loss: 9.032824164023623e-05, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0010648665351747767, Train Accuracy: 0.9891707920792079\n",
      "Batch #: [201/298], Train Loss: 0.0010718742043239113, Train Accuracy: 0.9889614427860697\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.011297225952148, Validation Accuracy: 0.78125\n",
      "Validation Batch #: 101, Validation Loss: 8.053269933946062, Validation Accuracy: 0.723700495049505\n",
      "Validation Batch #: 201, Validation Loss: 8.057972499980263, Validation Accuracy: 0.7178171641791045\n",
      "Validation Batch #: 301, Validation Loss: 8.058982857041977, Validation Accuracy: 0.7165697674418605\n",
      "Validation Batch #: 401, Validation Loss: 8.056041719907537, Validation Accuracy: 0.7199968827930174\n",
      "Epoch: 94/10\n",
      "Batch #: [001/298], Train Loss: 0.00020585385209415108, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0005268986615317486, Train Accuracy: 0.9935024752475248\n",
      "Batch #: [201/298], Train Loss: 0.0008230120851704127, Train Accuracy: 0.9905161691542289\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.075798988342285, Validation Accuracy: 0.6875\n",
      "Validation Batch #: 101, Validation Loss: 8.051226219328322, Validation Accuracy: 0.7264851485148515\n",
      "Validation Batch #: 201, Validation Loss: 8.050675702925345, Validation Accuracy: 0.7274564676616916\n",
      "Validation Batch #: 301, Validation Loss: 8.056205594262412, Validation Accuracy: 0.720514950166113\n",
      "Validation Batch #: 401, Validation Loss: 8.056876092183025, Validation Accuracy: 0.7197630922693267\n",
      "Epoch: 95/10\n",
      "Batch #: [001/298], Train Loss: 4.052487201988697e-05, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0006625961543839835, Train Accuracy: 0.9931930693069307\n",
      "Batch #: [201/298], Train Loss: 0.0006178965237526612, Train Accuracy: 0.9917599502487562\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.137590408325195, Validation Accuracy: 0.625\n",
      "Validation Batch #: 101, Validation Loss: 8.054590513210485, Validation Accuracy: 0.7218440594059405\n",
      "Validation Batch #: 201, Validation Loss: 8.056841046062868, Validation Accuracy: 0.7192164179104478\n",
      "Validation Batch #: 301, Validation Loss: 8.053899734915293, Validation Accuracy: 0.7229028239202658\n",
      "Validation Batch #: 401, Validation Loss: 8.055753850580153, Validation Accuracy: 0.7205423940149626\n",
      "Epoch: 96/10\n",
      "Batch #: [001/298], Train Loss: 5.938342656008899e-05, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0014624657687489157, Train Accuracy: 0.9885519801980198\n",
      "Batch #: [201/298], Train Loss: 0.0011167025746742503, Train Accuracy: 0.9897388059701493\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 7.998776435852051, Validation Accuracy: 0.78125\n",
      "Validation Batch #: 101, Validation Loss: 8.054989871412221, Validation Accuracy: 0.723700495049505\n",
      "Validation Batch #: 201, Validation Loss: 8.060140986940754, Validation Accuracy: 0.7173507462686567\n",
      "Validation Batch #: 301, Validation Loss: 8.05572573291107, Validation Accuracy: 0.7221760797342193\n",
      "Validation Batch #: 401, Validation Loss: 8.058479060555932, Validation Accuracy: 0.719139650872818\n",
      "Epoch: 97/10\n",
      "Batch #: [001/298], Train Loss: 1.2316414540691767e-05, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0006100283562458085, Train Accuracy: 0.9916460396039604\n",
      "Batch #: [201/298], Train Loss: 0.0006787322652557104, Train Accuracy: 0.992226368159204\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.10680103302002, Validation Accuracy: 0.65625\n",
      "Validation Batch #: 101, Validation Loss: 8.054304911358521, Validation Accuracy: 0.7230816831683168\n",
      "Validation Batch #: 201, Validation Loss: 8.052860826995243, Validation Accuracy: 0.7252798507462687\n",
      "Validation Batch #: 301, Validation Loss: 8.056142108384954, Validation Accuracy: 0.7211378737541528\n",
      "Validation Batch #: 401, Validation Loss: 8.057661331205297, Validation Accuracy: 0.7192175810473815\n",
      "Epoch: 98/10\n",
      "Batch #: [001/298], Train Loss: 0.0020817832555621862, Train Accuracy: 0.96875\n",
      "Batch #: [101/298], Train Loss: 0.0009683899466770725, Train Accuracy: 0.9882425742574258\n",
      "Batch #: [201/298], Train Loss: 0.000726041819595805, Train Accuracy: 0.9909825870646766\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.031723022460938, Validation Accuracy: 0.75\n",
      "Validation Batch #: 101, Validation Loss: 8.05119821812847, Validation Accuracy: 0.7280321782178217\n",
      "Validation Batch #: 201, Validation Loss: 8.053873555577216, Validation Accuracy: 0.7248134328358209\n",
      "Validation Batch #: 301, Validation Loss: 8.057606858668533, Validation Accuracy: 0.720514950166113\n",
      "Validation Batch #: 401, Validation Loss: 8.058291360327134, Validation Accuracy: 0.7196851620947631\n",
      "Epoch: 99/10\n",
      "Batch #: [001/298], Train Loss: 5.4872685723239556e-05, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.00036549146527406294, Train Accuracy: 0.9919554455445545\n",
      "Batch #: [201/298], Train Loss: 0.0009429053082784826, Train Accuracy: 0.992070895522388\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.219470977783203, Validation Accuracy: 0.53125\n",
      "Validation Batch #: 101, Validation Loss: 8.05807632975059, Validation Accuracy: 0.7206064356435643\n",
      "Validation Batch #: 201, Validation Loss: 8.063026485158437, Validation Accuracy: 0.714863184079602\n",
      "Validation Batch #: 301, Validation Loss: 8.05913082547362, Validation Accuracy: 0.7194767441860465\n",
      "Validation Batch #: 401, Validation Loss: 8.05837320032857, Validation Accuracy: 0.7203086034912718\n",
      "Epoch: 100/10\n",
      "Batch #: [001/298], Train Loss: 1.5604999134666286e-05, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0006118394409176997, Train Accuracy: 0.9913366336633663\n",
      "Batch #: [201/298], Train Loss: 0.001146034582844992, Train Accuracy: 0.9911380597014925\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 7.9618940353393555, Validation Accuracy: 0.84375\n",
      "Validation Batch #: 101, Validation Loss: 8.05597688183926, Validation Accuracy: 0.7202970297029703\n",
      "Validation Batch #: 201, Validation Loss: 8.056693954847345, Validation Accuracy: 0.7195273631840796\n",
      "Validation Batch #: 301, Validation Loss: 8.055329040831506, Validation Accuracy: 0.7212416943521595\n",
      "Validation Batch #: 401, Validation Loss: 8.05533592837707, Validation Accuracy: 0.7210879052369077\n",
      "Epoch: 101/10\n",
      "Batch #: [001/298], Train Loss: 0.00022533893934451044, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0008807752728617373, Train Accuracy: 0.9904084158415841\n",
      "Batch #: [201/298], Train Loss: 0.0007804589626027395, Train Accuracy: 0.9905161691542289\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 7.924437522888184, Validation Accuracy: 0.875\n",
      "Validation Batch #: 101, Validation Loss: 8.051507402174543, Validation Accuracy: 0.7255569306930693\n",
      "Validation Batch #: 201, Validation Loss: 8.059719804507584, Validation Accuracy: 0.7153296019900498\n",
      "Validation Batch #: 301, Validation Loss: 8.057279569366049, Validation Accuracy: 0.7183347176079734\n",
      "Validation Batch #: 401, Validation Loss: 8.056102070130612, Validation Accuracy: 0.7197630922693267\n",
      "Epoch: 102/10\n",
      "Batch #: [001/298], Train Loss: 0.00013001183106098324, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0005932088491848876, Train Accuracy: 0.9913366336633663\n",
      "Batch #: [201/298], Train Loss: 0.0006100103797235699, Train Accuracy: 0.992226368159204\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.06204891204834, Validation Accuracy: 0.71875\n",
      "Validation Batch #: 101, Validation Loss: 8.057972431182861, Validation Accuracy: 0.7206064356435643\n",
      "Validation Batch #: 201, Validation Loss: 8.056759305261261, Validation Accuracy: 0.7213930348258707\n",
      "Validation Batch #: 301, Validation Loss: 8.05808563010637, Validation Accuracy: 0.7196843853820598\n",
      "Validation Batch #: 401, Validation Loss: 8.058254976819578, Validation Accuracy: 0.7193734413965087\n",
      "Epoch: 103/10\n",
      "Batch #: [001/298], Train Loss: 2.8071937776985578e-05, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.000436496744138753, Train Accuracy: 0.989480198019802\n",
      "Batch #: [201/298], Train Loss: 0.0012387734197818843, Train Accuracy: 0.9880286069651741\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 7.994712829589844, Validation Accuracy: 0.78125\n",
      "Validation Batch #: 101, Validation Loss: 8.05490540041782, Validation Accuracy: 0.7212252475247525\n",
      "Validation Batch #: 201, Validation Loss: 8.0562266046135, Validation Accuracy: 0.7199937810945274\n",
      "Validation Batch #: 301, Validation Loss: 8.054149535803305, Validation Accuracy: 0.7224875415282392\n",
      "Validation Batch #: 401, Validation Loss: 8.056389409110434, Validation Accuracy: 0.7197630922693267\n",
      "Epoch: 104/10\n",
      "Batch #: [001/298], Train Loss: 7.246839686558815e-06, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0007642104341691506, Train Accuracy: 0.9922648514851485\n",
      "Batch #: [201/298], Train Loss: 0.0008501489199357426, Train Accuracy: 0.9916044776119403\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.089730262756348, Validation Accuracy: 0.6875\n",
      "Validation Batch #: 101, Validation Loss: 8.058903340065834, Validation Accuracy: 0.7162747524752475\n",
      "Validation Batch #: 201, Validation Loss: 8.055954795571703, Validation Accuracy: 0.7198383084577115\n",
      "Validation Batch #: 301, Validation Loss: 8.053754317007984, Validation Accuracy: 0.7229028239202658\n",
      "Validation Batch #: 401, Validation Loss: 8.05593853638951, Validation Accuracy: 0.7203086034912718\n",
      "Epoch: 105/10\n",
      "Batch #: [001/298], Train Loss: 3.289474648227042e-07, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0003471555935124509, Train Accuracy: 0.9941212871287128\n",
      "Batch #: [201/298], Train Loss: 0.0005086348959885604, Train Accuracy: 0.9928482587064676\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.034305572509766, Validation Accuracy: 0.75\n",
      "Validation Batch #: 101, Validation Loss: 8.059960837411408, Validation Accuracy: 0.7150371287128713\n",
      "Validation Batch #: 201, Validation Loss: 8.059121518585812, Validation Accuracy: 0.716728855721393\n",
      "Validation Batch #: 301, Validation Loss: 8.05466080187167, Validation Accuracy: 0.7217607973421927\n",
      "Validation Batch #: 401, Validation Loss: 8.057270394893656, Validation Accuracy: 0.71875\n",
      "Epoch: 106/10\n",
      "Batch #: [001/298], Train Loss: 8.194597285182681e-06, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0022066806419177125, Train Accuracy: 0.9891707920792079\n",
      "Batch #: [201/298], Train Loss: 0.0013747101912802416, Train Accuracy: 0.9902052238805971\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.029619216918945, Validation Accuracy: 0.75\n",
      "Validation Batch #: 101, Validation Loss: 8.061519570869974, Validation Accuracy: 0.7147277227722773\n",
      "Validation Batch #: 201, Validation Loss: 8.06108384108662, Validation Accuracy: 0.7145522388059702\n",
      "Validation Batch #: 301, Validation Loss: 8.055461281557811, Validation Accuracy: 0.7211378737541528\n",
      "Validation Batch #: 401, Validation Loss: 8.056605994255465, Validation Accuracy: 0.7198410224438903\n",
      "Epoch: 107/10\n",
      "Batch #: [001/298], Train Loss: 4.009143594885245e-06, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0005162967311668968, Train Accuracy: 0.9916460396039604\n",
      "Batch #: [201/298], Train Loss: 0.0007459445281834243, Train Accuracy: 0.9916044776119403\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.10721492767334, Validation Accuracy: 0.65625\n",
      "Validation Batch #: 101, Validation Loss: 8.048224307522915, Validation Accuracy: 0.7295792079207921\n",
      "Validation Batch #: 201, Validation Loss: 8.050083767715378, Validation Accuracy: 0.7274564676616916\n",
      "Validation Batch #: 301, Validation Loss: 8.05209561756679, Validation Accuracy: 0.7251868770764119\n",
      "Validation Batch #: 401, Validation Loss: 8.0563897384967, Validation Accuracy: 0.7198410224438903\n",
      "Epoch: 108/10\n",
      "Batch #: [001/298], Train Loss: 0.0006629087147302926, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0012000637091373978, Train Accuracy: 0.9910272277227723\n",
      "Batch #: [201/298], Train Loss: 0.0009288443502982343, Train Accuracy: 0.9905161691542289\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 7.998509883880615, Validation Accuracy: 0.78125\n",
      "Validation Batch #: 101, Validation Loss: 8.055940840503958, Validation Accuracy: 0.7199876237623762\n",
      "Validation Batch #: 201, Validation Loss: 8.053962847486657, Validation Accuracy: 0.7218594527363185\n",
      "Validation Batch #: 301, Validation Loss: 8.055963883764324, Validation Accuracy: 0.7193729235880398\n",
      "Validation Batch #: 401, Validation Loss: 8.055530680088033, Validation Accuracy: 0.7201527431421446\n",
      "Epoch: 109/10\n",
      "Batch #: [001/298], Train Loss: 5.071224950370379e-05, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0008269495253425882, Train Accuracy: 0.9907178217821783\n",
      "Batch #: [201/298], Train Loss: 0.0008022195319583713, Train Accuracy: 0.9916044776119403\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.133237838745117, Validation Accuracy: 0.625\n",
      "Validation Batch #: 101, Validation Loss: 8.05010755463402, Validation Accuracy: 0.7274133663366337\n",
      "Validation Batch #: 201, Validation Loss: 8.050230567135028, Validation Accuracy: 0.7276119402985075\n",
      "Validation Batch #: 301, Validation Loss: 8.05774595887954, Validation Accuracy: 0.71843853820598\n",
      "Validation Batch #: 401, Validation Loss: 8.057592541796906, Validation Accuracy: 0.71875\n",
      "Epoch: 110/10\n",
      "Batch #: [001/298], Train Loss: 0.0006558118620887399, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0007235859459167994, Train Accuracy: 0.9919554455445545\n",
      "Batch #: [201/298], Train Loss: 0.0010708429941936363, Train Accuracy: 0.9917599502487562\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.084794998168945, Validation Accuracy: 0.6875\n",
      "Validation Batch #: 101, Validation Loss: 8.065091175608115, Validation Accuracy: 0.7091584158415841\n",
      "Validation Batch #: 201, Validation Loss: 8.060311751579171, Validation Accuracy: 0.7143967661691543\n",
      "Validation Batch #: 301, Validation Loss: 8.06026624128272, Validation Accuracy: 0.7149086378737541\n",
      "Validation Batch #: 401, Validation Loss: 8.056614578513432, Validation Accuracy: 0.7193734413965087\n",
      "Epoch: 111/10\n",
      "Batch #: [001/298], Train Loss: 0.00038455455796793103, Train Accuracy: 0.96875\n",
      "Batch #: [101/298], Train Loss: 0.0003812494627650852, Train Accuracy: 0.9916460396039604\n",
      "Batch #: [201/298], Train Loss: 0.0004377942164347277, Train Accuracy: 0.9925373134328358\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.005803108215332, Validation Accuracy: 0.78125\n",
      "Validation Batch #: 101, Validation Loss: 8.059129384484622, Validation Accuracy: 0.7168935643564357\n",
      "Validation Batch #: 201, Validation Loss: 8.052352105800193, Validation Accuracy: 0.7249689054726368\n",
      "Validation Batch #: 301, Validation Loss: 8.05552537892744, Validation Accuracy: 0.7209302325581395\n",
      "Validation Batch #: 401, Validation Loss: 8.056412017850805, Validation Accuracy: 0.7199189526184538\n",
      "Epoch: 112/10\n",
      "Batch #: [001/298], Train Loss: 1.7548083633300848e-05, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.001328000641305803, Train Accuracy: 0.9891707920792079\n",
      "Batch #: [201/298], Train Loss: 0.0008927984123345712, Train Accuracy: 0.9911380597014925\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.113736152648926, Validation Accuracy: 0.65625\n",
      "Validation Batch #: 101, Validation Loss: 8.05840300097324, Validation Accuracy: 0.718440594059406\n",
      "Validation Batch #: 201, Validation Loss: 8.058318052718889, Validation Accuracy: 0.7189054726368159\n",
      "Validation Batch #: 301, Validation Loss: 8.056463015039894, Validation Accuracy: 0.7212416943521595\n",
      "Validation Batch #: 401, Validation Loss: 8.05766872991053, Validation Accuracy: 0.7197630922693267\n",
      "Epoch: 113/10\n",
      "Batch #: [001/298], Train Loss: 5.145089380675927e-05, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.00067120855983857, Train Accuracy: 0.9925742574257426\n",
      "Batch #: [201/298], Train Loss: 0.0009683460649601989, Train Accuracy: 0.9914490049751243\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.160690307617188, Validation Accuracy: 0.59375\n",
      "Validation Batch #: 101, Validation Loss: 8.070300116397366, Validation Accuracy: 0.7045173267326733\n",
      "Validation Batch #: 201, Validation Loss: 8.058825106170048, Validation Accuracy: 0.7179726368159204\n",
      "Validation Batch #: 301, Validation Loss: 8.056453837904819, Validation Accuracy: 0.720514950166113\n",
      "Validation Batch #: 401, Validation Loss: 8.057529297255519, Validation Accuracy: 0.7192175810473815\n",
      "Epoch: 114/10\n",
      "Batch #: [001/298], Train Loss: 0.00012299629452172667, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0020495220352066295, Train Accuracy: 0.9888613861386139\n",
      "Batch #: [201/298], Train Loss: 0.0013597525829403985, Train Accuracy: 0.9900497512437811\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.029979705810547, Validation Accuracy: 0.75\n",
      "Validation Batch #: 101, Validation Loss: 8.05764127957939, Validation Accuracy: 0.7181311881188119\n",
      "Validation Batch #: 201, Validation Loss: 8.06335529403307, Validation Accuracy: 0.7115982587064676\n",
      "Validation Batch #: 301, Validation Loss: 8.059660054520515, Validation Accuracy: 0.7161544850498339\n",
      "Validation Batch #: 401, Validation Loss: 8.056906583600508, Validation Accuracy: 0.7192175810473815\n",
      "Epoch: 115/10\n",
      "Batch #: [001/298], Train Loss: 0.000866744143422693, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0010690173231312043, Train Accuracy: 0.9919554455445545\n",
      "Batch #: [201/298], Train Loss: 0.0008172081239261453, Train Accuracy: 0.992070895522388\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.077542304992676, Validation Accuracy: 0.6875\n",
      "Validation Batch #: 101, Validation Loss: 8.0601168387007, Validation Accuracy: 0.7150371287128713\n",
      "Validation Batch #: 201, Validation Loss: 8.057365123312271, Validation Accuracy: 0.7179726368159204\n",
      "Validation Batch #: 301, Validation Loss: 8.056171258818667, Validation Accuracy: 0.7196843853820598\n",
      "Validation Batch #: 401, Validation Loss: 8.056511475855572, Validation Accuracy: 0.7195293017456359\n",
      "Epoch: 116/10\n",
      "Batch #: [001/298], Train Loss: 2.583853301985073e-06, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0009243363976981239, Train Accuracy: 0.9941212871287128\n",
      "Batch #: [201/298], Train Loss: 0.0006807367016082948, Train Accuracy: 0.9937810945273632\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.134615898132324, Validation Accuracy: 0.625\n",
      "Validation Batch #: 101, Validation Loss: 8.060815475954868, Validation Accuracy: 0.713799504950495\n",
      "Validation Batch #: 201, Validation Loss: 8.062138189723836, Validation Accuracy: 0.7125310945273632\n",
      "Validation Batch #: 301, Validation Loss: 8.060553210122245, Validation Accuracy: 0.7141818936877077\n",
      "Validation Batch #: 401, Validation Loss: 8.056013401012468, Validation Accuracy: 0.7196851620947631\n",
      "Epoch: 117/10\n",
      "Batch #: [001/298], Train Loss: 0.00031639417284168303, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0017865113989046222, Train Accuracy: 0.9857673267326733\n",
      "Batch #: [201/298], Train Loss: 0.0014305604759144118, Train Accuracy: 0.9872512437810945\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.13352108001709, Validation Accuracy: 0.625\n",
      "Validation Batch #: 101, Validation Loss: 8.05420966195588, Validation Accuracy: 0.7218440594059405\n",
      "Validation Batch #: 201, Validation Loss: 8.05429142861817, Validation Accuracy: 0.7212375621890548\n",
      "Validation Batch #: 301, Validation Loss: 8.05460178337224, Validation Accuracy: 0.7211378737541528\n",
      "Validation Batch #: 401, Validation Loss: 8.056430360028275, Validation Accuracy: 0.7190617206982544\n",
      "Epoch: 118/10\n",
      "Batch #: [001/298], Train Loss: 9.278055586037226e-07, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0003900073308721297, Train Accuracy: 0.9925742574257426\n",
      "Batch #: [201/298], Train Loss: 0.000550700394521356, Train Accuracy: 0.9933146766169154\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.112098693847656, Validation Accuracy: 0.65625\n",
      "Validation Batch #: 101, Validation Loss: 8.056456584741573, Validation Accuracy: 0.71875\n",
      "Validation Batch #: 201, Validation Loss: 8.058596694054295, Validation Accuracy: 0.7165733830845771\n",
      "Validation Batch #: 301, Validation Loss: 8.057999286144675, Validation Accuracy: 0.7171926910299004\n",
      "Validation Batch #: 401, Validation Loss: 8.055289773869692, Validation Accuracy: 0.720464463840399\n",
      "Epoch: 119/10\n",
      "Batch #: [001/298], Train Loss: 3.2065800041891634e-05, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.00039878820380935586, Train Accuracy: 0.9925742574257426\n",
      "Batch #: [201/298], Train Loss: 0.00046729326806086254, Train Accuracy: 0.9916044776119403\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.036238670349121, Validation Accuracy: 0.75\n",
      "Validation Batch #: 101, Validation Loss: 8.063520039662276, Validation Accuracy: 0.7110148514851485\n",
      "Validation Batch #: 201, Validation Loss: 8.056116685345398, Validation Accuracy: 0.7201492537313433\n",
      "Validation Batch #: 301, Validation Loss: 8.056770399163332, Validation Accuracy: 0.7197882059800664\n",
      "Validation Batch #: 401, Validation Loss: 8.056839531496577, Validation Accuracy: 0.7196851620947631\n",
      "Epoch: 120/10\n",
      "Batch #: [001/298], Train Loss: 0.0002837981446646154, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0005974873959816012, Train Accuracy: 0.9873143564356436\n",
      "Batch #: [201/298], Train Loss: 0.0007099379133121964, Train Accuracy: 0.9884950248756219\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 7.978334426879883, Validation Accuracy: 0.8125\n",
      "Validation Batch #: 101, Validation Loss: 8.059762713932756, Validation Accuracy: 0.7162747524752475\n",
      "Validation Batch #: 201, Validation Loss: 8.05967648824056, Validation Accuracy: 0.7164179104477612\n",
      "Validation Batch #: 301, Validation Loss: 8.057780224619513, Validation Accuracy: 0.7185423588039868\n",
      "Validation Batch #: 401, Validation Loss: 8.057056985888398, Validation Accuracy: 0.7195293017456359\n",
      "Epoch: 121/10\n",
      "Batch #: [001/298], Train Loss: 0.00017578870756551623, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.001432432278011051, Train Accuracy: 0.9916460396039604\n",
      "Batch #: [201/298], Train Loss: 0.0009680937939785069, Train Accuracy: 0.9923818407960199\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.083037376403809, Validation Accuracy: 0.6875\n",
      "Validation Batch #: 101, Validation Loss: 8.050229681600438, Validation Accuracy: 0.7258663366336634\n",
      "Validation Batch #: 201, Validation Loss: 8.05493190869763, Validation Accuracy: 0.7209266169154229\n",
      "Validation Batch #: 301, Validation Loss: 8.058180823278585, Validation Accuracy: 0.717296511627907\n",
      "Validation Batch #: 401, Validation Loss: 8.055714093538889, Validation Accuracy: 0.720074812967581\n",
      "Epoch: 122/10\n",
      "Batch #: [001/298], Train Loss: 8.736211020732298e-05, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0016224345210372518, Train Accuracy: 0.9907178217821783\n",
      "Batch #: [201/298], Train Loss: 0.0011636533300714345, Train Accuracy: 0.9917599502487562\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.218310356140137, Validation Accuracy: 0.53125\n",
      "Validation Batch #: 101, Validation Loss: 8.054492586910134, Validation Accuracy: 0.7230816831683168\n",
      "Validation Batch #: 201, Validation Loss: 8.050957594344865, Validation Accuracy: 0.7276119402985075\n",
      "Validation Batch #: 301, Validation Loss: 8.055132145105405, Validation Accuracy: 0.7225913621262459\n",
      "Validation Batch #: 401, Validation Loss: 8.058692241250132, Validation Accuracy: 0.7182824189526185\n",
      "Epoch: 123/10\n",
      "Batch #: [001/298], Train Loss: 0.00023093556228559464, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0005641521877463458, Train Accuracy: 0.9913366336633663\n",
      "Batch #: [201/298], Train Loss: 0.00048151820991744167, Train Accuracy: 0.9919154228855721\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.03568172454834, Validation Accuracy: 0.75\n",
      "Validation Batch #: 101, Validation Loss: 8.057176896841218, Validation Accuracy: 0.719059405940594\n",
      "Validation Batch #: 201, Validation Loss: 8.056468586423504, Validation Accuracy: 0.7198383084577115\n",
      "Validation Batch #: 301, Validation Loss: 8.054274213670496, Validation Accuracy: 0.7226951827242525\n",
      "Validation Batch #: 401, Validation Loss: 8.058018155228766, Validation Accuracy: 0.7181265586034913\n",
      "Epoch: 124/10\n",
      "Batch #: [001/298], Train Loss: 8.449536107946187e-05, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0012474703964023847, Train Accuracy: 0.9910272277227723\n",
      "Batch #: [201/298], Train Loss: 0.0009286565790737282, Train Accuracy: 0.9909825870646766\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.007399559020996, Validation Accuracy: 0.78125\n",
      "Validation Batch #: 101, Validation Loss: 8.051708325301066, Validation Accuracy: 0.7258663366336634\n",
      "Validation Batch #: 201, Validation Loss: 8.05703322092692, Validation Accuracy: 0.7193718905472637\n",
      "Validation Batch #: 301, Validation Loss: 8.058598195199554, Validation Accuracy: 0.7174003322259136\n",
      "Validation Batch #: 401, Validation Loss: 8.056131380751841, Validation Accuracy: 0.7202306733167082\n",
      "Epoch: 125/10\n",
      "Batch #: [001/298], Train Loss: 9.211593351210468e-06, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0006093285797025448, Train Accuracy: 0.9913366336633663\n",
      "Batch #: [201/298], Train Loss: 0.00047344130866572434, Train Accuracy: 0.9912935323383084\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.031392097473145, Validation Accuracy: 0.75\n",
      "Validation Batch #: 101, Validation Loss: 8.060296223895385, Validation Accuracy: 0.7141089108910891\n",
      "Validation Batch #: 201, Validation Loss: 8.056282529783486, Validation Accuracy: 0.7195273631840796\n",
      "Validation Batch #: 301, Validation Loss: 8.054071690949094, Validation Accuracy: 0.7220722591362126\n",
      "Validation Batch #: 401, Validation Loss: 8.056402630936773, Validation Accuracy: 0.7192955112219451\n",
      "Epoch: 126/10\n",
      "Batch #: [001/298], Train Loss: 3.4627882996574044e-06, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.000768854271530974, Train Accuracy: 0.9904084158415841\n",
      "Batch #: [201/298], Train Loss: 0.000705679442416677, Train Accuracy: 0.9905161691542289\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.157949447631836, Validation Accuracy: 0.59375\n",
      "Validation Batch #: 101, Validation Loss: 8.058412669908883, Validation Accuracy: 0.7172029702970297\n",
      "Validation Batch #: 201, Validation Loss: 8.052689571285722, Validation Accuracy: 0.7238805970149254\n",
      "Validation Batch #: 301, Validation Loss: 8.053116936224244, Validation Accuracy: 0.7233181063122923\n",
      "Validation Batch #: 401, Validation Loss: 8.056429179232019, Validation Accuracy: 0.7195293017456359\n",
      "Epoch: 127/10\n",
      "Batch #: [001/298], Train Loss: 0.00019531440921127796, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0006062861736070588, Train Accuracy: 0.9922648514851485\n",
      "Batch #: [201/298], Train Loss: 0.0005492015819620338, Train Accuracy: 0.9923818407960199\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 7.999259948730469, Validation Accuracy: 0.78125\n",
      "Validation Batch #: 101, Validation Loss: 8.06372834668301, Validation Accuracy: 0.7113242574257426\n",
      "Validation Batch #: 201, Validation Loss: 8.056206456464322, Validation Accuracy: 0.7198383084577115\n",
      "Validation Batch #: 301, Validation Loss: 8.059204109483384, Validation Accuracy: 0.7161544850498339\n",
      "Validation Batch #: 401, Validation Loss: 8.055813892821124, Validation Accuracy: 0.7201527431421446\n",
      "Epoch: 128/10\n",
      "Batch #: [001/298], Train Loss: 0.001602933625690639, Train Accuracy: 0.9375\n",
      "Batch #: [101/298], Train Loss: 0.000538967996291295, Train Accuracy: 0.9907178217821783\n",
      "Batch #: [201/298], Train Loss: 0.0006789640825457975, Train Accuracy: 0.9916044776119403\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.054720878601074, Validation Accuracy: 0.71875\n",
      "Validation Batch #: 101, Validation Loss: 8.045996151348152, Validation Accuracy: 0.7311262376237624\n",
      "Validation Batch #: 201, Validation Loss: 8.053076760685858, Validation Accuracy: 0.7229477611940298\n",
      "Validation Batch #: 301, Validation Loss: 8.054397942615902, Validation Accuracy: 0.7213455149501661\n",
      "Validation Batch #: 401, Validation Loss: 8.055746237833304, Validation Accuracy: 0.7201527431421446\n",
      "Epoch: 129/10\n",
      "Batch #: [001/298], Train Loss: 1.0177907824981958e-05, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0010031039808388801, Train Accuracy: 0.9913366336633663\n",
      "Batch #: [201/298], Train Loss: 0.0006414041890743713, Train Accuracy: 0.9934701492537313\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 7.955728054046631, Validation Accuracy: 0.84375\n",
      "Validation Batch #: 101, Validation Loss: 8.057087081493718, Validation Accuracy: 0.7196782178217822\n",
      "Validation Batch #: 201, Validation Loss: 8.062995526328015, Validation Accuracy: 0.7126865671641791\n",
      "Validation Batch #: 301, Validation Loss: 8.059452104410063, Validation Accuracy: 0.7168812292358804\n",
      "Validation Batch #: 401, Validation Loss: 8.056862491027376, Validation Accuracy: 0.7198410224438903\n",
      "Epoch: 130/10\n",
      "Batch #: [001/298], Train Loss: 9.55127616180107e-05, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0014377559491735345, Train Accuracy: 0.9888613861386139\n",
      "Batch #: [201/298], Train Loss: 0.001013723039723593, Train Accuracy: 0.9891169154228856\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.132183074951172, Validation Accuracy: 0.625\n",
      "Validation Batch #: 101, Validation Loss: 8.054412473546396, Validation Accuracy: 0.7209158415841584\n",
      "Validation Batch #: 201, Validation Loss: 8.057691441246526, Validation Accuracy: 0.7175062189054726\n",
      "Validation Batch #: 301, Validation Loss: 8.056655655667631, Validation Accuracy: 0.71906146179402\n",
      "Validation Batch #: 401, Validation Loss: 8.055434876249318, Validation Accuracy: 0.7205423940149626\n",
      "Epoch: 131/10\n",
      "Batch #: [001/298], Train Loss: 0.00046480001765303314, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0004199397918412588, Train Accuracy: 0.9925742574257426\n",
      "Batch #: [201/298], Train Loss: 0.0004692876828539399, Train Accuracy: 0.9925373134328358\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.08535385131836, Validation Accuracy: 0.6875\n",
      "Validation Batch #: 101, Validation Loss: 8.049764009985592, Validation Accuracy: 0.7274133663366337\n",
      "Validation Batch #: 201, Validation Loss: 8.052054806135187, Validation Accuracy: 0.7241915422885572\n",
      "Validation Batch #: 301, Validation Loss: 8.053380131325452, Validation Accuracy: 0.7225913621262459\n",
      "Validation Batch #: 401, Validation Loss: 8.055594582212834, Validation Accuracy: 0.7201527431421446\n",
      "Epoch: 132/10\n",
      "Batch #: [001/298], Train Loss: 0.00038380647310987115, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0003993767086308028, Train Accuracy: 0.9919554455445545\n",
      "Batch #: [201/298], Train Loss: 0.000506164741244063, Train Accuracy: 0.992226368159204\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 7.983661651611328, Validation Accuracy: 0.8125\n",
      "Validation Batch #: 101, Validation Loss: 8.05076803547321, Validation Accuracy: 0.7264851485148515\n",
      "Validation Batch #: 201, Validation Loss: 8.051044945693135, Validation Accuracy: 0.7262126865671642\n",
      "Validation Batch #: 301, Validation Loss: 8.05548420934582, Validation Accuracy: 0.7209302325581395\n",
      "Validation Batch #: 401, Validation Loss: 8.057383884515549, Validation Accuracy: 0.71875\n",
      "Epoch: 133/10\n",
      "Batch #: [001/298], Train Loss: 6.854648381704465e-05, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.00021837791733855062, Train Accuracy: 0.9938118811881188\n",
      "Batch #: [201/298], Train Loss: 0.00030275973542703393, Train Accuracy: 0.9930037313432836\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.06452751159668, Validation Accuracy: 0.71875\n",
      "Validation Batch #: 101, Validation Loss: 8.045019546357713, Validation Accuracy: 0.7320544554455446\n",
      "Validation Batch #: 201, Validation Loss: 8.051717679892013, Validation Accuracy: 0.7248134328358209\n",
      "Validation Batch #: 301, Validation Loss: 8.057701302525214, Validation Accuracy: 0.7175041528239202\n",
      "Validation Batch #: 401, Validation Loss: 8.056185088550064, Validation Accuracy: 0.7192175810473815\n",
      "Epoch: 134/10\n",
      "Batch #: [001/298], Train Loss: 8.32805599202402e-05, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.009104704122386587, Train Accuracy: 0.9919554455445545\n",
      "Batch #: [201/298], Train Loss: 0.004815680803281778, Train Accuracy: 0.9926927860696517\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.059957504272461, Validation Accuracy: 0.71875\n",
      "Validation Batch #: 101, Validation Loss: 8.038550527969209, Validation Accuracy: 0.7410272277227723\n",
      "Validation Batch #: 201, Validation Loss: 8.053757565531564, Validation Accuracy: 0.7235696517412935\n",
      "Validation Batch #: 301, Validation Loss: 8.056393403151503, Validation Accuracy: 0.7204111295681063\n",
      "Validation Batch #: 401, Validation Loss: 8.05588873009432, Validation Accuracy: 0.7210879052369077\n",
      "Epoch: 135/10\n",
      "Batch #: [001/298], Train Loss: 0.0008963715517893434, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.000657492552416033, Train Accuracy: 0.9904084158415841\n",
      "Batch #: [201/298], Train Loss: 0.0006218510038445642, Train Accuracy: 0.9912935323383084\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.110450744628906, Validation Accuracy: 0.65625\n",
      "Validation Batch #: 101, Validation Loss: 8.057377201495784, Validation Accuracy: 0.7175123762376238\n",
      "Validation Batch #: 201, Validation Loss: 8.052538570479967, Validation Accuracy: 0.7231032338308457\n",
      "Validation Batch #: 301, Validation Loss: 8.054666343321436, Validation Accuracy: 0.7207225913621262\n",
      "Validation Batch #: 401, Validation Loss: 8.055232394068616, Validation Accuracy: 0.7201527431421446\n",
      "Epoch: 136/10\n",
      "Batch #: [001/298], Train Loss: 7.962223025970161e-05, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0005823930633761784, Train Accuracy: 0.9922648514851485\n",
      "Batch #: [201/298], Train Loss: 0.0007390341190973029, Train Accuracy: 0.9914490049751243\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.074920654296875, Validation Accuracy: 0.6875\n",
      "Validation Batch #: 101, Validation Loss: 8.048464789248928, Validation Accuracy: 0.7295792079207921\n",
      "Validation Batch #: 201, Validation Loss: 8.04954735438029, Validation Accuracy: 0.7282338308457711\n",
      "Validation Batch #: 301, Validation Loss: 8.054279197490096, Validation Accuracy: 0.7226951827242525\n",
      "Validation Batch #: 401, Validation Loss: 8.056204441479615, Validation Accuracy: 0.7203086034912718\n",
      "Epoch: 137/10\n",
      "Batch #: [001/298], Train Loss: 4.376311437681579e-07, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0008198276620880666, Train Accuracy: 0.9910272277227723\n",
      "Batch #: [201/298], Train Loss: 0.0006380419448052082, Train Accuracy: 0.9919154228855721\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.080779075622559, Validation Accuracy: 0.6875\n",
      "Validation Batch #: 101, Validation Loss: 8.05032201332621, Validation Accuracy: 0.7267945544554455\n",
      "Validation Batch #: 201, Validation Loss: 8.052179661556263, Validation Accuracy: 0.724657960199005\n",
      "Validation Batch #: 301, Validation Loss: 8.056911525536217, Validation Accuracy: 0.71875\n",
      "Validation Batch #: 401, Validation Loss: 8.055761735635505, Validation Accuracy: 0.720074812967581\n",
      "Epoch: 138/10\n",
      "Batch #: [001/298], Train Loss: 2.7060355023422744e-07, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0003579877882405319, Train Accuracy: 0.9925742574257426\n",
      "Batch #: [201/298], Train Loss: 0.0003475487428058151, Train Accuracy: 0.9933146766169154\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.062411308288574, Validation Accuracy: 0.71875\n",
      "Validation Batch #: 101, Validation Loss: 8.053273828903047, Validation Accuracy: 0.724009900990099\n",
      "Validation Batch #: 201, Validation Loss: 8.05518863213003, Validation Accuracy: 0.7217039800995025\n",
      "Validation Batch #: 301, Validation Loss: 8.057512048867057, Validation Accuracy: 0.7186461794019934\n",
      "Validation Batch #: 401, Validation Loss: 8.057997740414969, Validation Accuracy: 0.7180486284289277\n",
      "Epoch: 139/10\n",
      "Batch #: [001/298], Train Loss: 6.012412541167578e-06, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0008510017677737085, Train Accuracy: 0.9928836633663366\n",
      "Batch #: [201/298], Train Loss: 0.0007685835369151769, Train Accuracy: 0.9923818407960199\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.052170753479004, Validation Accuracy: 0.71875\n",
      "Validation Batch #: 101, Validation Loss: 8.055794999150947, Validation Accuracy: 0.7196782178217822\n",
      "Validation Batch #: 201, Validation Loss: 8.057650684717283, Validation Accuracy: 0.7179726368159204\n",
      "Validation Batch #: 301, Validation Loss: 8.059356931832145, Validation Accuracy: 0.7159468438538206\n",
      "Validation Batch #: 401, Validation Loss: 8.056095091184773, Validation Accuracy: 0.7199968827930174\n",
      "Epoch: 140/10\n",
      "Batch #: [001/298], Train Loss: 0.0005163596360944211, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.00038128230567571617, Train Accuracy: 0.9938118811881188\n",
      "Batch #: [201/298], Train Loss: 0.000470265425795206, Train Accuracy: 0.9937810945273632\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.088906288146973, Validation Accuracy: 0.6875\n",
      "Validation Batch #: 101, Validation Loss: 8.064146098524038, Validation Accuracy: 0.7097772277227723\n",
      "Validation Batch #: 201, Validation Loss: 8.05916819406386, Validation Accuracy: 0.7162624378109452\n",
      "Validation Batch #: 301, Validation Loss: 8.058582709873237, Validation Accuracy: 0.717296511627907\n",
      "Validation Batch #: 401, Validation Loss: 8.056666911688826, Validation Accuracy: 0.7194513715710723\n",
      "Epoch: 141/10\n",
      "Batch #: [001/298], Train Loss: 5.4303876822814345e-05, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0003757197537174986, Train Accuracy: 0.9919554455445545\n",
      "Batch #: [201/298], Train Loss: 0.0005263290405893523, Train Accuracy: 0.9926927860696517\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.062347412109375, Validation Accuracy: 0.71875\n",
      "Validation Batch #: 101, Validation Loss: 8.049213990126505, Validation Accuracy: 0.7295792079207921\n",
      "Validation Batch #: 201, Validation Loss: 8.051147342321292, Validation Accuracy: 0.7271455223880597\n",
      "Validation Batch #: 301, Validation Loss: 8.057091852359202, Validation Accuracy: 0.7197882059800664\n",
      "Validation Batch #: 401, Validation Loss: 8.056906549116025, Validation Accuracy: 0.7199189526184538\n",
      "Epoch: 142/10\n",
      "Batch #: [001/298], Train Loss: 2.0687217329395935e-05, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0036780545668643797, Train Accuracy: 0.9882425742574258\n",
      "Batch #: [201/298], Train Loss: 0.001999874025519451, Train Accuracy: 0.9906716417910447\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.025270462036133, Validation Accuracy: 0.75\n",
      "Validation Batch #: 101, Validation Loss: 8.052106654289926, Validation Accuracy: 0.7249381188118812\n",
      "Validation Batch #: 201, Validation Loss: 8.054675998972423, Validation Accuracy: 0.7220149253731343\n",
      "Validation Batch #: 301, Validation Loss: 8.055397188940713, Validation Accuracy: 0.7213455149501661\n",
      "Validation Batch #: 401, Validation Loss: 8.056408885708473, Validation Accuracy: 0.7202306733167082\n",
      "Epoch: 143/10\n",
      "Batch #: [001/298], Train Loss: 0.00017090306209865957, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0005413586924643175, Train Accuracy: 0.9922648514851485\n",
      "Batch #: [201/298], Train Loss: 0.000661806487927656, Train Accuracy: 0.992070895522388\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.138670921325684, Validation Accuracy: 0.625\n",
      "Validation Batch #: 101, Validation Loss: 8.0556057467319, Validation Accuracy: 0.7212252475247525\n",
      "Validation Batch #: 201, Validation Loss: 8.056474927646011, Validation Accuracy: 0.7198383084577115\n",
      "Validation Batch #: 301, Validation Loss: 8.058047255012283, Validation Accuracy: 0.7179194352159468\n",
      "Validation Batch #: 401, Validation Loss: 8.055552589625789, Validation Accuracy: 0.7206982543640897\n",
      "Epoch: 144/10\n",
      "Batch #: [001/298], Train Loss: 8.002895629033446e-05, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0005378079178460903, Train Accuracy: 0.9910272277227723\n",
      "Batch #: [201/298], Train Loss: 0.0008559793997840081, Train Accuracy: 0.9902052238805971\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.085588455200195, Validation Accuracy: 0.6875\n",
      "Validation Batch #: 101, Validation Loss: 8.054210724216876, Validation Accuracy: 0.724009900990099\n",
      "Validation Batch #: 201, Validation Loss: 8.058019253745007, Validation Accuracy: 0.7192164179104478\n",
      "Validation Batch #: 301, Validation Loss: 8.057116199569448, Validation Accuracy: 0.720203488372093\n",
      "Validation Batch #: 401, Validation Loss: 8.057690050833838, Validation Accuracy: 0.7195293017456359\n",
      "Epoch: 145/10\n",
      "Batch #: [001/298], Train Loss: 0.000279042316833511, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.000531331217753222, Train Accuracy: 0.9904084158415841\n",
      "Batch #: [201/298], Train Loss: 0.0008146259666879737, Train Accuracy: 0.990360696517413\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.058021545410156, Validation Accuracy: 0.71875\n",
      "Validation Batch #: 101, Validation Loss: 8.067385503561189, Validation Accuracy: 0.7073019801980198\n",
      "Validation Batch #: 201, Validation Loss: 8.061345010254513, Validation Accuracy: 0.7143967661691543\n",
      "Validation Batch #: 301, Validation Loss: 8.059617446506538, Validation Accuracy: 0.7166735880398671\n",
      "Validation Batch #: 401, Validation Loss: 8.05712203313585, Validation Accuracy: 0.7196851620947631\n",
      "Epoch: 146/10\n",
      "Batch #: [001/298], Train Loss: 0.00023469662119168788, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0004523264277695894, Train Accuracy: 0.9913366336633663\n",
      "Batch #: [201/298], Train Loss: 0.0006075903238895388, Train Accuracy: 0.9911380597014925\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.109275817871094, Validation Accuracy: 0.65625\n",
      "Validation Batch #: 101, Validation Loss: 8.052361053995567, Validation Accuracy: 0.724319306930693\n",
      "Validation Batch #: 201, Validation Loss: 8.051798801517013, Validation Accuracy: 0.7249689054726368\n",
      "Validation Batch #: 301, Validation Loss: 8.059253992036332, Validation Accuracy: 0.7163621262458472\n",
      "Validation Batch #: 401, Validation Loss: 8.055307278906616, Validation Accuracy: 0.7211658354114713\n",
      "Epoch: 147/10\n",
      "Batch #: [001/298], Train Loss: 0.0006665957625955343, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0005686252892344486, Train Accuracy: 0.9910272277227723\n",
      "Batch #: [201/298], Train Loss: 0.0005037004701756615, Train Accuracy: 0.992226368159204\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.13542652130127, Validation Accuracy: 0.625\n",
      "Validation Batch #: 101, Validation Loss: 8.059935631138263, Validation Accuracy: 0.7150371287128713\n",
      "Validation Batch #: 201, Validation Loss: 8.061652845411158, Validation Accuracy: 0.712997512437811\n",
      "Validation Batch #: 301, Validation Loss: 8.057854964487577, Validation Accuracy: 0.717296511627907\n",
      "Validation Batch #: 401, Validation Loss: 8.056050722735778, Validation Accuracy: 0.7198410224438903\n",
      "Epoch: 148/10\n",
      "Batch #: [001/298], Train Loss: 0.0003366385353729129, Train Accuracy: 0.96875\n",
      "Batch #: [101/298], Train Loss: 0.00044158800824024776, Train Accuracy: 0.9931930693069307\n",
      "Batch #: [201/298], Train Loss: 0.0008239225649774721, Train Accuracy: 0.992226368159204\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 7.986764430999756, Validation Accuracy: 0.8125\n",
      "Validation Batch #: 101, Validation Loss: 8.067370952946124, Validation Accuracy: 0.7069925742574258\n",
      "Validation Batch #: 201, Validation Loss: 8.059656378048569, Validation Accuracy: 0.7162624378109452\n",
      "Validation Batch #: 301, Validation Loss: 8.057266522087527, Validation Accuracy: 0.71906146179402\n",
      "Validation Batch #: 401, Validation Loss: 8.057066599924369, Validation Accuracy: 0.7192955112219451\n",
      "Epoch: 149/10\n",
      "Batch #: [001/298], Train Loss: 8.311222336487845e-05, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0007344451368246407, Train Accuracy: 0.9919554455445545\n",
      "Batch #: [201/298], Train Loss: 0.0006544089190321532, Train Accuracy: 0.9917599502487562\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.045672416687012, Validation Accuracy: 0.71875\n",
      "Validation Batch #: 101, Validation Loss: 8.064643529382083, Validation Accuracy: 0.7097772277227723\n",
      "Validation Batch #: 201, Validation Loss: 8.057917234316394, Validation Accuracy: 0.7179726368159204\n",
      "Validation Batch #: 301, Validation Loss: 8.057191167558942, Validation Accuracy: 0.7185423588039868\n",
      "Validation Batch #: 401, Validation Loss: 8.056199304480803, Validation Accuracy: 0.7197630922693267\n",
      "Epoch: 150/10\n",
      "Batch #: [001/298], Train Loss: 1.1288277164567262e-05, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0008202096140337289, Train Accuracy: 0.9904084158415841\n",
      "Batch #: [201/298], Train Loss: 0.0006829098784438079, Train Accuracy: 0.9906716417910447\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.034287452697754, Validation Accuracy: 0.75\n",
      "Validation Batch #: 101, Validation Loss: 8.053056542236027, Validation Accuracy: 0.724319306930693\n",
      "Validation Batch #: 201, Validation Loss: 8.052737432925856, Validation Accuracy: 0.724502487562189\n",
      "Validation Batch #: 301, Validation Loss: 8.056450142020799, Validation Accuracy: 0.719892026578073\n",
      "Validation Batch #: 401, Validation Loss: 8.056557650577993, Validation Accuracy: 0.7194513715710723\n",
      "Epoch: 151/10\n",
      "Batch #: [001/298], Train Loss: 8.76860212883912e-05, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0008638872475132183, Train Accuracy: 0.9882425742574258\n",
      "Batch #: [201/298], Train Loss: 0.000784478244338954, Train Accuracy: 0.9902052238805971\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.079830169677734, Validation Accuracy: 0.6875\n",
      "Validation Batch #: 101, Validation Loss: 8.050590944762277, Validation Accuracy: 0.7274133663366337\n",
      "Validation Batch #: 201, Validation Loss: 8.058029656386495, Validation Accuracy: 0.7176616915422885\n",
      "Validation Batch #: 301, Validation Loss: 8.057661785239793, Validation Accuracy: 0.7185423588039868\n",
      "Validation Batch #: 401, Validation Loss: 8.055605824154213, Validation Accuracy: 0.7208541147132169\n",
      "Epoch: 152/10\n",
      "Batch #: [001/298], Train Loss: 0.000269959942670539, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0003478485841618173, Train Accuracy: 0.9907178217821783\n",
      "Batch #: [201/298], Train Loss: 0.0003338055106038399, Train Accuracy: 0.992070895522388\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 7.9211649894714355, Validation Accuracy: 0.875\n",
      "Validation Batch #: 101, Validation Loss: 8.058321093568708, Validation Accuracy: 0.7172029702970297\n",
      "Validation Batch #: 201, Validation Loss: 8.055597435775681, Validation Accuracy: 0.7204601990049752\n",
      "Validation Batch #: 301, Validation Loss: 8.052817853186218, Validation Accuracy: 0.7238372093023255\n",
      "Validation Batch #: 401, Validation Loss: 8.05592369854896, Validation Accuracy: 0.7202306733167082\n",
      "Epoch: 153/10\n",
      "Batch #: [001/298], Train Loss: 1.4331634702102747e-05, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0005621295237518205, Train Accuracy: 0.9910272277227723\n",
      "Batch #: [201/298], Train Loss: 0.001499625186910967, Train Accuracy: 0.9911380597014925\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.009163856506348, Validation Accuracy: 0.78125\n",
      "Validation Batch #: 101, Validation Loss: 8.064447568194701, Validation Accuracy: 0.7097772277227723\n",
      "Validation Batch #: 201, Validation Loss: 8.062561540461298, Validation Accuracy: 0.7122201492537313\n",
      "Validation Batch #: 301, Validation Loss: 8.055397868552477, Validation Accuracy: 0.720514950166113\n",
      "Validation Batch #: 401, Validation Loss: 8.05648623083595, Validation Accuracy: 0.7190617206982544\n",
      "Epoch: 154/10\n",
      "Batch #: [001/298], Train Loss: 7.374437245744048e-06, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0014531898854594565, Train Accuracy: 0.9928836633663366\n",
      "Batch #: [201/298], Train Loss: 0.0009393378308778152, Train Accuracy: 0.992070895522388\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.086418151855469, Validation Accuracy: 0.6875\n",
      "Validation Batch #: 101, Validation Loss: 8.06280293795142, Validation Accuracy: 0.7110148514851485\n",
      "Validation Batch #: 201, Validation Loss: 8.060260174879387, Validation Accuracy: 0.7140858208955224\n",
      "Validation Batch #: 301, Validation Loss: 8.055340600568195, Validation Accuracy: 0.7200996677740864\n",
      "Validation Batch #: 401, Validation Loss: 8.056600491007664, Validation Accuracy: 0.7188279301745636\n",
      "Epoch: 155/10\n",
      "Batch #: [001/298], Train Loss: 0.0006982939084991813, Train Accuracy: 0.96875\n",
      "Batch #: [101/298], Train Loss: 0.0007453442459744128, Train Accuracy: 0.9900990099009901\n",
      "Batch #: [201/298], Train Loss: 0.0006739576341659014, Train Accuracy: 0.990360696517413\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.08731746673584, Validation Accuracy: 0.6875\n",
      "Validation Batch #: 101, Validation Loss: 8.05643903146876, Validation Accuracy: 0.719059405940594\n",
      "Validation Batch #: 201, Validation Loss: 8.05597055254884, Validation Accuracy: 0.7196828358208955\n",
      "Validation Batch #: 301, Validation Loss: 8.056557633156, Validation Accuracy: 0.71906146179402\n",
      "Validation Batch #: 401, Validation Loss: 8.056644288679013, Validation Accuracy: 0.719139650872818\n",
      "Epoch: 156/10\n",
      "Batch #: [001/298], Train Loss: 1.4224352526071016e-05, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0005461594591619729, Train Accuracy: 0.9897896039603961\n",
      "Batch #: [201/298], Train Loss: 0.0005638969385611732, Train Accuracy: 0.9909825870646766\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.083131790161133, Validation Accuracy: 0.6875\n",
      "Validation Batch #: 101, Validation Loss: 8.045322101895172, Validation Accuracy: 0.7326732673267327\n",
      "Validation Batch #: 201, Validation Loss: 8.051024444067655, Validation Accuracy: 0.7254353233830846\n",
      "Validation Batch #: 301, Validation Loss: 8.054536101826006, Validation Accuracy: 0.7211378737541528\n",
      "Validation Batch #: 401, Validation Loss: 8.055592126679837, Validation Accuracy: 0.720074812967581\n",
      "Epoch: 157/10\n",
      "Batch #: [001/298], Train Loss: 1.3808926269121002e-06, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.000486066486643051, Train Accuracy: 0.9941212871287128\n",
      "Batch #: [201/298], Train Loss: 0.000538057853623682, Train Accuracy: 0.9930037313432836\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.215645790100098, Validation Accuracy: 0.53125\n",
      "Validation Batch #: 101, Validation Loss: 8.056475474102662, Validation Accuracy: 0.7196782178217822\n",
      "Validation Batch #: 201, Validation Loss: 8.049494743347168, Validation Accuracy: 0.7276119402985075\n",
      "Validation Batch #: 301, Validation Loss: 8.051687177233521, Validation Accuracy: 0.7250830564784053\n",
      "Validation Batch #: 401, Validation Loss: 8.05492441077482, Validation Accuracy: 0.7211658354114713\n",
      "Epoch: 158/10\n",
      "Batch #: [001/298], Train Loss: 5.2152528951410204e-05, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.002702522945455847, Train Accuracy: 0.9916460396039604\n",
      "Batch #: [201/298], Train Loss: 0.0016967483090079962, Train Accuracy: 0.9912935323383084\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.057475090026855, Validation Accuracy: 0.71875\n",
      "Validation Batch #: 101, Validation Loss: 8.051899263174226, Validation Accuracy: 0.7252475247524752\n",
      "Validation Batch #: 201, Validation Loss: 8.052344357789453, Validation Accuracy: 0.7243470149253731\n",
      "Validation Batch #: 301, Validation Loss: 8.057545668262977, Validation Accuracy: 0.7183347176079734\n",
      "Validation Batch #: 401, Validation Loss: 8.05650744830581, Validation Accuracy: 0.7193734413965087\n",
      "Epoch: 159/10\n",
      "Batch #: [001/298], Train Loss: 7.122484021238051e-06, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.00031149480435595987, Train Accuracy: 0.9941212871287128\n",
      "Batch #: [201/298], Train Loss: 0.0005823100773352451, Train Accuracy: 0.9925373134328358\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.13328742980957, Validation Accuracy: 0.625\n",
      "Validation Batch #: 101, Validation Loss: 8.064809336520657, Validation Accuracy: 0.7097772277227723\n",
      "Validation Batch #: 201, Validation Loss: 8.059889086443393, Validation Accuracy: 0.7153296019900498\n",
      "Validation Batch #: 301, Validation Loss: 8.054106563428707, Validation Accuracy: 0.7220722591362126\n",
      "Validation Batch #: 401, Validation Loss: 8.056145653760344, Validation Accuracy: 0.7196072319201995\n",
      "Epoch: 160/10\n",
      "Batch #: [001/298], Train Loss: 0.0001293193781748414, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0004670451228490168, Train Accuracy: 0.9959777227722773\n",
      "Batch #: [201/298], Train Loss: 0.0003663235984022457, Train Accuracy: 0.9947139303482587\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.111958503723145, Validation Accuracy: 0.65625\n",
      "Validation Batch #: 101, Validation Loss: 8.069901683542987, Validation Accuracy: 0.7035891089108911\n",
      "Validation Batch #: 201, Validation Loss: 8.059685972792591, Validation Accuracy: 0.7157960199004975\n",
      "Validation Batch #: 301, Validation Loss: 8.056821987874484, Validation Accuracy: 0.7188538205980066\n",
      "Validation Batch #: 401, Validation Loss: 8.05532643800959, Validation Accuracy: 0.7205423940149626\n",
      "Epoch: 161/10\n",
      "Batch #: [001/298], Train Loss: 6.759406824130565e-05, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0003462152799897922, Train Accuracy: 0.994740099009901\n",
      "Batch #: [201/298], Train Loss: 0.00036936352401582226, Train Accuracy: 0.9936256218905473\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.114426612854004, Validation Accuracy: 0.65625\n",
      "Validation Batch #: 101, Validation Loss: 8.062813579446019, Validation Accuracy: 0.7122524752475248\n",
      "Validation Batch #: 201, Validation Loss: 8.05958254894807, Validation Accuracy: 0.7154850746268657\n",
      "Validation Batch #: 301, Validation Loss: 8.057236549466156, Validation Accuracy: 0.7181270764119602\n",
      "Validation Batch #: 401, Validation Loss: 8.056943485564425, Validation Accuracy: 0.7185162094763092\n",
      "Epoch: 162/10\n",
      "Batch #: [001/298], Train Loss: 0.00010966556146740913, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0009278829446406807, Train Accuracy: 0.9913366336633663\n",
      "Batch #: [201/298], Train Loss: 0.001117935870935943, Train Accuracy: 0.9916044776119403\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 7.954265117645264, Validation Accuracy: 0.84375\n",
      "Validation Batch #: 101, Validation Loss: 8.048581774872128, Validation Accuracy: 0.7295792079207921\n",
      "Validation Batch #: 201, Validation Loss: 8.054483003284208, Validation Accuracy: 0.7223258706467661\n",
      "Validation Batch #: 301, Validation Loss: 8.05692530945686, Validation Accuracy: 0.7192691029900332\n",
      "Validation Batch #: 401, Validation Loss: 8.056527280450759, Validation Accuracy: 0.7197630922693267\n",
      "Epoch: 163/10\n",
      "Batch #: [001/298], Train Loss: 9.118120942730457e-05, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.00038435759034601317, Train Accuracy: 0.9928836633663366\n",
      "Batch #: [201/298], Train Loss: 0.00044429983365188065, Train Accuracy: 0.9931592039800995\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.03303050994873, Validation Accuracy: 0.75\n",
      "Validation Batch #: 101, Validation Loss: 8.064034074839979, Validation Accuracy: 0.7103960396039604\n",
      "Validation Batch #: 201, Validation Loss: 8.06315107725153, Validation Accuracy: 0.7112873134328358\n",
      "Validation Batch #: 301, Validation Loss: 8.059119845545569, Validation Accuracy: 0.715843023255814\n",
      "Validation Batch #: 401, Validation Loss: 8.055607997865748, Validation Accuracy: 0.7199968827930174\n",
      "Epoch: 164/10\n",
      "Batch #: [001/298], Train Loss: 0.011322529055178165, Train Accuracy: 0.9375\n",
      "Batch #: [101/298], Train Loss: 0.0005717351423232451, Train Accuracy: 0.9919554455445545\n",
      "Batch #: [201/298], Train Loss: 0.00094749057020679, Train Accuracy: 0.9909825870646766\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.110981941223145, Validation Accuracy: 0.65625\n",
      "Validation Batch #: 101, Validation Loss: 8.057558446827501, Validation Accuracy: 0.718440594059406\n",
      "Validation Batch #: 201, Validation Loss: 8.059557385705597, Validation Accuracy: 0.7164179104477612\n",
      "Validation Batch #: 301, Validation Loss: 8.05771437990309, Validation Accuracy: 0.7188538205980066\n",
      "Validation Batch #: 401, Validation Loss: 8.057094450306119, Validation Accuracy: 0.7195293017456359\n",
      "Epoch: 165/10\n",
      "Batch #: [001/298], Train Loss: 2.6343568606534973e-05, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0002870994865792463, Train Accuracy: 0.994740099009901\n",
      "Batch #: [201/298], Train Loss: 0.0008597540731426054, Train Accuracy: 0.9923818407960199\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.084385871887207, Validation Accuracy: 0.6875\n",
      "Validation Batch #: 101, Validation Loss: 8.052319063998684, Validation Accuracy: 0.7246287128712872\n",
      "Validation Batch #: 201, Validation Loss: 8.059599425662217, Validation Accuracy: 0.7153296019900498\n",
      "Validation Batch #: 301, Validation Loss: 8.056782049198087, Validation Accuracy: 0.7188538205980066\n",
      "Validation Batch #: 401, Validation Loss: 8.056877204010314, Validation Accuracy: 0.7188279301745636\n",
      "Epoch: 166/10\n",
      "Batch #: [001/298], Train Loss: 0.0011899061501026154, Train Accuracy: 0.9375\n",
      "Batch #: [101/298], Train Loss: 0.0010016286587207141, Train Accuracy: 0.9888613861386139\n",
      "Batch #: [201/298], Train Loss: 0.0007432086363673445, Train Accuracy: 0.9923818407960199\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.079559326171875, Validation Accuracy: 0.6875\n",
      "Validation Batch #: 101, Validation Loss: 8.059247767571176, Validation Accuracy: 0.7162747524752475\n",
      "Validation Batch #: 201, Validation Loss: 8.060709782500766, Validation Accuracy: 0.7139303482587065\n",
      "Validation Batch #: 301, Validation Loss: 8.05795156757697, Validation Accuracy: 0.7171926910299004\n",
      "Validation Batch #: 401, Validation Loss: 8.056310179227605, Validation Accuracy: 0.7190617206982544\n",
      "Epoch: 167/10\n",
      "Batch #: [001/298], Train Loss: 0.00011473464837763458, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0007914815306971022, Train Accuracy: 0.9922648514851485\n",
      "Batch #: [201/298], Train Loss: 0.000641536661479998, Train Accuracy: 0.9914490049751243\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.084896087646484, Validation Accuracy: 0.6875\n",
      "Validation Batch #: 101, Validation Loss: 8.05198600976774, Validation Accuracy: 0.7249381188118812\n",
      "Validation Batch #: 201, Validation Loss: 8.057781340470955, Validation Accuracy: 0.7176616915422885\n",
      "Validation Batch #: 301, Validation Loss: 8.059494780543634, Validation Accuracy: 0.7156353820598007\n",
      "Validation Batch #: 401, Validation Loss: 8.056667092435081, Validation Accuracy: 0.7192175810473815\n",
      "Epoch: 168/10\n",
      "Batch #: [001/298], Train Loss: 4.8638659791322425e-05, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0006031359278085352, Train Accuracy: 0.9900990099009901\n",
      "Batch #: [201/298], Train Loss: 0.0011202695859800934, Train Accuracy: 0.9909825870646766\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.161352157592773, Validation Accuracy: 0.59375\n",
      "Validation Batch #: 101, Validation Loss: 8.061993320389549, Validation Accuracy: 0.713490099009901\n",
      "Validation Batch #: 201, Validation Loss: 8.057043469367336, Validation Accuracy: 0.7189054726368159\n",
      "Validation Batch #: 301, Validation Loss: 8.055321672826114, Validation Accuracy: 0.7208264119601329\n",
      "Validation Batch #: 401, Validation Loss: 8.056214417008093, Validation Accuracy: 0.7199189526184538\n",
      "Epoch: 169/10\n",
      "Batch #: [001/298], Train Loss: 1.647123099246528e-05, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0003733293870038666, Train Accuracy: 0.9925742574257426\n",
      "Batch #: [201/298], Train Loss: 0.0007807951730323545, Train Accuracy: 0.992070895522388\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.106913566589355, Validation Accuracy: 0.65625\n",
      "Validation Batch #: 101, Validation Loss: 8.065646856138022, Validation Accuracy: 0.7073019801980198\n",
      "Validation Batch #: 201, Validation Loss: 8.057093421025062, Validation Accuracy: 0.7181281094527363\n",
      "Validation Batch #: 301, Validation Loss: 8.056894020384728, Validation Accuracy: 0.7182308970099668\n",
      "Validation Batch #: 401, Validation Loss: 8.05598059913464, Validation Accuracy: 0.7195293017456359\n",
      "Epoch: 170/10\n",
      "Batch #: [001/298], Train Loss: 1.0440186997584533e-05, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0008923404399116173, Train Accuracy: 0.9922648514851485\n",
      "Batch #: [201/298], Train Loss: 0.001042374088959306, Train Accuracy: 0.9906716417910447\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.135080337524414, Validation Accuracy: 0.625\n",
      "Validation Batch #: 101, Validation Loss: 8.06070103031574, Validation Accuracy: 0.7153465346534653\n",
      "Validation Batch #: 201, Validation Loss: 8.054863296337981, Validation Accuracy: 0.7221703980099502\n",
      "Validation Batch #: 301, Validation Loss: 8.058417052525618, Validation Accuracy: 0.7179194352159468\n",
      "Validation Batch #: 401, Validation Loss: 8.057085216788579, Validation Accuracy: 0.7193734413965087\n",
      "Epoch: 171/10\n",
      "Batch #: [001/298], Train Loss: 1.0164344530494418e-05, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0009277789827393971, Train Accuracy: 0.9928836633663366\n",
      "Batch #: [201/298], Train Loss: 0.000673928815836465, Train Accuracy: 0.9931592039800995\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.007083892822266, Validation Accuracy: 0.78125\n",
      "Validation Batch #: 101, Validation Loss: 8.0527026629684, Validation Accuracy: 0.723700495049505\n",
      "Validation Batch #: 201, Validation Loss: 8.051409453301881, Validation Accuracy: 0.7255907960199005\n",
      "Validation Batch #: 301, Validation Loss: 8.057076591985963, Validation Accuracy: 0.71906146179402\n",
      "Validation Batch #: 401, Validation Loss: 8.056266288804888, Validation Accuracy: 0.7203086034912718\n",
      "Epoch: 172/10\n",
      "Batch #: [001/298], Train Loss: 1.1600495781749487e-05, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0012853449543990566, Train Accuracy: 0.9885519801980198\n",
      "Batch #: [201/298], Train Loss: 0.0009205729746626257, Train Accuracy: 0.9905161691542289\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 7.998929977416992, Validation Accuracy: 0.78125\n",
      "Validation Batch #: 101, Validation Loss: 8.050682218948213, Validation Accuracy: 0.7274133663366337\n",
      "Validation Batch #: 201, Validation Loss: 8.058792600584267, Validation Accuracy: 0.7171952736318408\n",
      "Validation Batch #: 301, Validation Loss: 8.057842010675474, Validation Accuracy: 0.7179194352159468\n",
      "Validation Batch #: 401, Validation Loss: 8.057520341992081, Validation Accuracy: 0.7185162094763092\n",
      "Epoch: 173/10\n",
      "Batch #: [001/298], Train Loss: 0.00022357240959536284, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0003640645528476945, Train Accuracy: 0.9925742574257426\n",
      "Batch #: [201/298], Train Loss: 0.00034659381540218725, Train Accuracy: 0.9933146766169154\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.208780288696289, Validation Accuracy: 0.53125\n",
      "Validation Batch #: 101, Validation Loss: 8.053834863228372, Validation Accuracy: 0.7221534653465347\n",
      "Validation Batch #: 201, Validation Loss: 8.054796921080024, Validation Accuracy: 0.7212375621890548\n",
      "Validation Batch #: 301, Validation Loss: 8.056523077511708, Validation Accuracy: 0.71906146179402\n",
      "Validation Batch #: 401, Validation Loss: 8.055103983367768, Validation Accuracy: 0.7206203241895262\n",
      "Epoch: 174/10\n",
      "Batch #: [001/298], Train Loss: 6.7403962020762265e-06, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0004903003236668245, Train Accuracy: 0.9904084158415841\n",
      "Batch #: [201/298], Train Loss: 0.0009948824823269077, Train Accuracy: 0.9912935323383084\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.00805950164795, Validation Accuracy: 0.78125\n",
      "Validation Batch #: 101, Validation Loss: 8.055858262694708, Validation Accuracy: 0.7209158415841584\n",
      "Validation Batch #: 201, Validation Loss: 8.054941718258075, Validation Accuracy: 0.7220149253731343\n",
      "Validation Batch #: 301, Validation Loss: 8.05568318667998, Validation Accuracy: 0.7209302325581395\n",
      "Validation Batch #: 401, Validation Loss: 8.056168882032285, Validation Accuracy: 0.7203865336658354\n",
      "Epoch: 175/10\n",
      "Batch #: [001/298], Train Loss: 9.619896445656195e-06, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0005852045016349666, Train Accuracy: 0.9935024752475248\n",
      "Batch #: [201/298], Train Loss: 0.0008895379578879005, Train Accuracy: 0.9923818407960199\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 7.971076011657715, Validation Accuracy: 0.8125\n",
      "Validation Batch #: 101, Validation Loss: 8.052658680642006, Validation Accuracy: 0.723700495049505\n",
      "Validation Batch #: 201, Validation Loss: 8.053288946104287, Validation Accuracy: 0.722636815920398\n",
      "Validation Batch #: 301, Validation Loss: 8.052674003613747, Validation Accuracy: 0.7233181063122923\n",
      "Validation Batch #: 401, Validation Loss: 8.055145424203088, Validation Accuracy: 0.7205423940149626\n",
      "Epoch: 176/10\n",
      "Batch #: [001/298], Train Loss: 5.489521299750777e-06, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0005108715758320604, Train Accuracy: 0.9935024752475248\n",
      "Batch #: [201/298], Train Loss: 0.0005120046959355271, Train Accuracy: 0.9930037313432836\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 7.971389293670654, Validation Accuracy: 0.8125\n",
      "Validation Batch #: 101, Validation Loss: 8.057512467450435, Validation Accuracy: 0.7168935643564357\n",
      "Validation Batch #: 201, Validation Loss: 8.0552082299, Validation Accuracy: 0.7201492537313433\n",
      "Validation Batch #: 301, Validation Loss: 8.05318115082294, Validation Accuracy: 0.7230066445182725\n",
      "Validation Batch #: 401, Validation Loss: 8.056706835206905, Validation Accuracy: 0.7188279301745636\n",
      "Epoch: 177/10\n",
      "Batch #: [001/298], Train Loss: 1.8393591744825244e-05, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0009308769762418422, Train Accuracy: 0.9910272277227723\n",
      "Batch #: [201/298], Train Loss: 0.0006983248286131817, Train Accuracy: 0.9911380597014925\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.086474418640137, Validation Accuracy: 0.6875\n",
      "Validation Batch #: 101, Validation Loss: 8.062479448790597, Validation Accuracy: 0.7128712871287128\n",
      "Validation Batch #: 201, Validation Loss: 8.061591931243441, Validation Accuracy: 0.714863184079602\n",
      "Validation Batch #: 301, Validation Loss: 8.055709260642727, Validation Accuracy: 0.721968438538206\n",
      "Validation Batch #: 401, Validation Loss: 8.057649466164985, Validation Accuracy: 0.7194513715710723\n",
      "Epoch: 178/10\n",
      "Batch #: [001/298], Train Loss: 1.868700678642199e-06, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0006228012482743357, Train Accuracy: 0.9913366336633663\n",
      "Batch #: [201/298], Train Loss: 0.0004931844499705294, Train Accuracy: 0.992226368159204\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.192888259887695, Validation Accuracy: 0.5625\n",
      "Validation Batch #: 101, Validation Loss: 8.072369910702847, Validation Accuracy: 0.7020420792079208\n",
      "Validation Batch #: 201, Validation Loss: 8.05997053070448, Validation Accuracy: 0.7164179104477612\n",
      "Validation Batch #: 301, Validation Loss: 8.057988040074953, Validation Accuracy: 0.7189576411960132\n",
      "Validation Batch #: 401, Validation Loss: 8.056784470479684, Validation Accuracy: 0.7199968827930174\n",
      "Epoch: 179/10\n",
      "Batch #: [001/298], Train Loss: 1.1103621545771603e-05, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0006225898409525706, Train Accuracy: 0.9919554455445545\n",
      "Batch #: [201/298], Train Loss: 0.0005508063074316919, Train Accuracy: 0.9916044776119403\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.08355712890625, Validation Accuracy: 0.6875\n",
      "Validation Batch #: 101, Validation Loss: 8.058498731934199, Validation Accuracy: 0.7178217821782178\n",
      "Validation Batch #: 201, Validation Loss: 8.058221705517365, Validation Accuracy: 0.7173507462686567\n",
      "Validation Batch #: 301, Validation Loss: 8.058142812545118, Validation Accuracy: 0.717296511627907\n",
      "Validation Batch #: 401, Validation Loss: 8.056236445457857, Validation Accuracy: 0.7196851620947631\n",
      "Epoch: 180/10\n",
      "Batch #: [001/298], Train Loss: 3.6111676308792084e-05, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0007309729954570657, Train Accuracy: 0.9910272277227723\n",
      "Batch #: [201/298], Train Loss: 0.0005042891631286912, Train Accuracy: 0.9933146766169154\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.00503921508789, Validation Accuracy: 0.78125\n",
      "Validation Batch #: 101, Validation Loss: 8.055181437199659, Validation Accuracy: 0.7199876237623762\n",
      "Validation Batch #: 201, Validation Loss: 8.055100815806222, Validation Accuracy: 0.7204601990049752\n",
      "Validation Batch #: 301, Validation Loss: 8.05774664958054, Validation Accuracy: 0.7177117940199336\n",
      "Validation Batch #: 401, Validation Loss: 8.056484123715142, Validation Accuracy: 0.7192955112219451\n",
      "Epoch: 181/10\n",
      "Batch #: [001/298], Train Loss: 1.839231458689028e-06, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.00028301416174732403, Train Accuracy: 0.9913366336633663\n",
      "Batch #: [201/298], Train Loss: 0.000548102431781587, Train Accuracy: 0.9906716417910447\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.138215065002441, Validation Accuracy: 0.625\n",
      "Validation Batch #: 101, Validation Loss: 8.053477853831678, Validation Accuracy: 0.7261757425742574\n",
      "Validation Batch #: 201, Validation Loss: 8.05376985654309, Validation Accuracy: 0.7252798507462687\n",
      "Validation Batch #: 301, Validation Loss: 8.058510653600344, Validation Accuracy: 0.7196843853820598\n",
      "Validation Batch #: 401, Validation Loss: 8.058779245600142, Validation Accuracy: 0.7192955112219451\n",
      "Epoch: 182/10\n",
      "Batch #: [001/298], Train Loss: 0.00024196671438403428, Train Accuracy: 0.96875\n",
      "Batch #: [101/298], Train Loss: 0.0004667738710406753, Train Accuracy: 0.9935024752475248\n",
      "Batch #: [201/298], Train Loss: 0.0004239893137731368, Train Accuracy: 0.994092039800995\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.08123779296875, Validation Accuracy: 0.6875\n",
      "Validation Batch #: 101, Validation Loss: 8.058618045089268, Validation Accuracy: 0.7172029702970297\n",
      "Validation Batch #: 201, Validation Loss: 8.056165540989358, Validation Accuracy: 0.7198383084577115\n",
      "Validation Batch #: 301, Validation Loss: 8.055823107494469, Validation Accuracy: 0.7200996677740864\n",
      "Validation Batch #: 401, Validation Loss: 8.056054336471748, Validation Accuracy: 0.7199968827930174\n",
      "Epoch: 183/10\n",
      "Batch #: [001/298], Train Loss: 0.0004173863853793591, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0006086819771770244, Train Accuracy: 0.9916460396039604\n",
      "Batch #: [201/298], Train Loss: 0.0005684212962964196, Train Accuracy: 0.9919154228855721\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.061637878417969, Validation Accuracy: 0.71875\n",
      "Validation Batch #: 101, Validation Loss: 8.062953000021453, Validation Accuracy: 0.7116336633663366\n",
      "Validation Batch #: 201, Validation Loss: 8.060675779978434, Validation Accuracy: 0.7142412935323383\n",
      "Validation Batch #: 301, Validation Loss: 8.05845271867771, Validation Accuracy: 0.716985049833887\n",
      "Validation Batch #: 401, Validation Loss: 8.057348155024046, Validation Accuracy: 0.7182824189526185\n",
      "Epoch: 184/10\n",
      "Batch #: [001/298], Train Loss: 4.8949614210869186e-06, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0005565832006454056, Train Accuracy: 0.9900990099009901\n",
      "Batch #: [201/298], Train Loss: 0.0005471602509433057, Train Accuracy: 0.9916044776119403\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 7.982143402099609, Validation Accuracy: 0.8125\n",
      "Validation Batch #: 101, Validation Loss: 8.047480399065678, Validation Accuracy: 0.7301980198019802\n",
      "Validation Batch #: 201, Validation Loss: 8.055695891973391, Validation Accuracy: 0.7204601990049752\n",
      "Validation Batch #: 301, Validation Loss: 8.055121192108357, Validation Accuracy: 0.7209302325581395\n",
      "Validation Batch #: 401, Validation Loss: 8.054494841140405, Validation Accuracy: 0.7215554862842892\n",
      "Epoch: 185/10\n",
      "Batch #: [001/298], Train Loss: 0.0010278758127242327, Train Accuracy: 0.9375\n",
      "Batch #: [101/298], Train Loss: 0.0009437049944835962, Train Accuracy: 0.9897896039603961\n",
      "Batch #: [201/298], Train Loss: 0.0006033836745629416, Train Accuracy: 0.9923818407960199\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 7.974465847015381, Validation Accuracy: 0.8125\n",
      "Validation Batch #: 101, Validation Loss: 8.063389490146449, Validation Accuracy: 0.7113242574257426\n",
      "Validation Batch #: 201, Validation Loss: 8.059569218858558, Validation Accuracy: 0.7156405472636815\n",
      "Validation Batch #: 301, Validation Loss: 8.058064606498641, Validation Accuracy: 0.7174003322259136\n",
      "Validation Batch #: 401, Validation Loss: 8.055742637177655, Validation Accuracy: 0.7203865336658354\n",
      "Epoch: 186/10\n",
      "Batch #: [001/298], Train Loss: 3.599235787987709e-05, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0006197211075585632, Train Accuracy: 0.9907178217821783\n",
      "Batch #: [201/298], Train Loss: 0.0007084992208482571, Train Accuracy: 0.9914490049751243\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.113462448120117, Validation Accuracy: 0.65625\n",
      "Validation Batch #: 101, Validation Loss: 8.063698074605206, Validation Accuracy: 0.7103960396039604\n",
      "Validation Batch #: 201, Validation Loss: 8.058246861642866, Validation Accuracy: 0.7170398009950248\n",
      "Validation Batch #: 301, Validation Loss: 8.058556049765146, Validation Accuracy: 0.7168812292358804\n",
      "Validation Batch #: 401, Validation Loss: 8.055857175603471, Validation Accuracy: 0.720074812967581\n",
      "Epoch: 187/10\n",
      "Batch #: [001/298], Train Loss: 0.0007999902591109276, Train Accuracy: 0.96875\n",
      "Batch #: [101/298], Train Loss: 0.0005450849798211097, Train Accuracy: 0.9916460396039604\n",
      "Batch #: [201/298], Train Loss: 0.0009510628586080636, Train Accuracy: 0.9923818407960199\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.000658988952637, Validation Accuracy: 0.78125\n",
      "Validation Batch #: 101, Validation Loss: 8.060810023015089, Validation Accuracy: 0.713180693069307\n",
      "Validation Batch #: 201, Validation Loss: 8.054426309481189, Validation Accuracy: 0.7210820895522388\n",
      "Validation Batch #: 301, Validation Loss: 8.053013779396235, Validation Accuracy: 0.7230066445182725\n",
      "Validation Batch #: 401, Validation Loss: 8.05511200041545, Validation Accuracy: 0.7206982543640897\n",
      "Epoch: 188/10\n",
      "Batch #: [001/298], Train Loss: 0.0010023772483691573, Train Accuracy: 0.96875\n",
      "Batch #: [101/298], Train Loss: 0.0007356623512807778, Train Accuracy: 0.9900990099009901\n",
      "Batch #: [201/298], Train Loss: 0.0006188241477478705, Train Accuracy: 0.9916044776119403\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.083503723144531, Validation Accuracy: 0.6875\n",
      "Validation Batch #: 101, Validation Loss: 8.064210141059196, Validation Accuracy: 0.7097772277227723\n",
      "Validation Batch #: 201, Validation Loss: 8.057818635779233, Validation Accuracy: 0.7171952736318408\n",
      "Validation Batch #: 301, Validation Loss: 8.057557806224127, Validation Accuracy: 0.7174003322259136\n",
      "Validation Batch #: 401, Validation Loss: 8.055335084101802, Validation Accuracy: 0.7201527431421446\n",
      "Epoch: 189/10\n",
      "Batch #: [001/298], Train Loss: 0.00021293126337695867, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0007190557172446749, Train Accuracy: 0.9925742574257426\n",
      "Batch #: [201/298], Train Loss: 0.0005879048667250771, Train Accuracy: 0.9925373134328358\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.005473136901855, Validation Accuracy: 0.78125\n",
      "Validation Batch #: 101, Validation Loss: 8.064199013285117, Validation Accuracy: 0.7107054455445545\n",
      "Validation Batch #: 201, Validation Loss: 8.05389307031584, Validation Accuracy: 0.7231032338308457\n",
      "Validation Batch #: 301, Validation Loss: 8.0532555184095, Validation Accuracy: 0.723421926910299\n",
      "Validation Batch #: 401, Validation Loss: 8.055817915614407, Validation Accuracy: 0.7203865336658354\n",
      "Epoch: 190/10\n",
      "Batch #: [001/298], Train Loss: 0.0017632764065638185, Train Accuracy: 0.96875\n",
      "Batch #: [101/298], Train Loss: 0.001101893926891035, Train Accuracy: 0.9904084158415841\n",
      "Batch #: [201/298], Train Loss: 0.0007080418268650312, Train Accuracy: 0.9923818407960199\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.002603530883789, Validation Accuracy: 0.78125\n",
      "Validation Batch #: 101, Validation Loss: 8.04714834572065, Validation Accuracy: 0.7308168316831684\n",
      "Validation Batch #: 201, Validation Loss: 8.052949174719663, Validation Accuracy: 0.7234141791044776\n",
      "Validation Batch #: 301, Validation Loss: 8.054298529197212, Validation Accuracy: 0.7217607973421927\n",
      "Validation Batch #: 401, Validation Loss: 8.056252663866838, Validation Accuracy: 0.7192175810473815\n",
      "Epoch: 191/10\n",
      "Batch #: [001/298], Train Loss: 0.0005236437427811325, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.00048439463510606916, Train Accuracy: 0.9913366336633663\n",
      "Batch #: [201/298], Train Loss: 0.0005049808880513216, Train Accuracy: 0.9930037313432836\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.110949516296387, Validation Accuracy: 0.65625\n",
      "Validation Batch #: 101, Validation Loss: 8.056224648315128, Validation Accuracy: 0.7206064356435643\n",
      "Validation Batch #: 201, Validation Loss: 8.055184532753863, Validation Accuracy: 0.7217039800995025\n",
      "Validation Batch #: 301, Validation Loss: 8.058704800780033, Validation Accuracy: 0.7171926910299004\n",
      "Validation Batch #: 401, Validation Loss: 8.057322094268038, Validation Accuracy: 0.7190617206982544\n",
      "Epoch: 192/10\n",
      "Batch #: [001/298], Train Loss: 5.600799704552628e-05, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0007804003299438051, Train Accuracy: 0.9922648514851485\n",
      "Batch #: [201/298], Train Loss: 0.0006261543904616843, Train Accuracy: 0.9926927860696517\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.031022071838379, Validation Accuracy: 0.75\n",
      "Validation Batch #: 101, Validation Loss: 8.058823401385014, Validation Accuracy: 0.7168935643564357\n",
      "Validation Batch #: 201, Validation Loss: 8.05661109430873, Validation Accuracy: 0.7189054726368159\n",
      "Validation Batch #: 301, Validation Loss: 8.055658001440309, Validation Accuracy: 0.720203488372093\n",
      "Validation Batch #: 401, Validation Loss: 8.055834657236227, Validation Accuracy: 0.7201527431421446\n",
      "Epoch: 193/10\n",
      "Batch #: [001/298], Train Loss: 9.744110684550833e-06, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.00038799124846330995, Train Accuracy: 0.994430693069307\n",
      "Batch #: [201/298], Train Loss: 0.00044679399165432866, Train Accuracy: 0.9933146766169154\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.161041259765625, Validation Accuracy: 0.59375\n",
      "Validation Batch #: 101, Validation Loss: 8.057288656140319, Validation Accuracy: 0.7181311881188119\n",
      "Validation Batch #: 201, Validation Loss: 8.052905255882301, Validation Accuracy: 0.7231032338308457\n",
      "Validation Batch #: 301, Validation Loss: 8.055290583360234, Validation Accuracy: 0.7203073089700996\n",
      "Validation Batch #: 401, Validation Loss: 8.055362367273268, Validation Accuracy: 0.7203865336658354\n",
      "Epoch: 194/10\n",
      "Batch #: [001/298], Train Loss: 1.1994217857136391e-05, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.00023660988799263416, Train Accuracy: 0.9959777227722773\n",
      "Batch #: [201/298], Train Loss: 0.0003131608714880799, Train Accuracy: 0.994092039800995\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.056577682495117, Validation Accuracy: 0.71875\n",
      "Validation Batch #: 101, Validation Loss: 8.063661849144662, Validation Accuracy: 0.7110148514851485\n",
      "Validation Batch #: 201, Validation Loss: 8.05891703847629, Validation Accuracy: 0.7171952736318408\n",
      "Validation Batch #: 301, Validation Loss: 8.056802966665984, Validation Accuracy: 0.7197882059800664\n",
      "Validation Batch #: 401, Validation Loss: 8.056340645673567, Validation Accuracy: 0.7202306733167082\n",
      "Epoch: 195/10\n",
      "Batch #: [001/298], Train Loss: 0.0006187911494635046, Train Accuracy: 0.96875\n",
      "Batch #: [101/298], Train Loss: 0.0004209413208586018, Train Accuracy: 0.9910272277227723\n",
      "Batch #: [201/298], Train Loss: 0.0006289447733151623, Train Accuracy: 0.9925373134328358\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.08688735961914, Validation Accuracy: 0.6875\n",
      "Validation Batch #: 101, Validation Loss: 8.059189702024554, Validation Accuracy: 0.7165841584158416\n",
      "Validation Batch #: 201, Validation Loss: 8.053104217965805, Validation Accuracy: 0.7241915422885572\n",
      "Validation Batch #: 301, Validation Loss: 8.05361014267931, Validation Accuracy: 0.7235257475083057\n",
      "Validation Batch #: 401, Validation Loss: 8.056278520094189, Validation Accuracy: 0.7203086034912718\n",
      "Epoch: 196/10\n",
      "Batch #: [001/298], Train Loss: 0.0004498485941439867, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0009135426919891699, Train Accuracy: 0.9910272277227723\n",
      "Batch #: [201/298], Train Loss: 0.0007671700539647326, Train Accuracy: 0.992226368159204\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.219243049621582, Validation Accuracy: 0.53125\n",
      "Validation Batch #: 101, Validation Loss: 8.06519118866118, Validation Accuracy: 0.7091584158415841\n",
      "Validation Batch #: 201, Validation Loss: 8.062957668778909, Validation Accuracy: 0.7122201492537313\n",
      "Validation Batch #: 301, Validation Loss: 8.054727555905465, Validation Accuracy: 0.7218646179401993\n",
      "Validation Batch #: 401, Validation Loss: 8.055956814354495, Validation Accuracy: 0.7203865336658354\n",
      "Epoch: 197/10\n",
      "Batch #: [001/298], Train Loss: 0.00016865543148014694, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0005321084072859479, Train Accuracy: 0.9910272277227723\n",
      "Batch #: [201/298], Train Loss: 0.00048828068673092685, Train Accuracy: 0.9925373134328358\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 7.979874610900879, Validation Accuracy: 0.8125\n",
      "Validation Batch #: 101, Validation Loss: 8.058081985700248, Validation Accuracy: 0.718440594059406\n",
      "Validation Batch #: 201, Validation Loss: 8.054634556841494, Validation Accuracy: 0.7227922885572139\n",
      "Validation Batch #: 301, Validation Loss: 8.056368747026818, Validation Accuracy: 0.7207225913621262\n",
      "Validation Batch #: 401, Validation Loss: 8.05677455321809, Validation Accuracy: 0.7197630922693267\n",
      "Epoch: 198/10\n",
      "Batch #: [001/298], Train Loss: 2.260175097035244e-05, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.0003917340265947006, Train Accuracy: 0.9935024752475248\n",
      "Batch #: [201/298], Train Loss: 0.0003779410167490581, Train Accuracy: 0.9930037313432836\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.052606582641602, Validation Accuracy: 0.71875\n",
      "Validation Batch #: 101, Validation Loss: 8.04849619440513, Validation Accuracy: 0.7289603960396039\n",
      "Validation Batch #: 201, Validation Loss: 8.053463430547003, Validation Accuracy: 0.7227922885572139\n",
      "Validation Batch #: 301, Validation Loss: 8.055558294948945, Validation Accuracy: 0.720514950166113\n",
      "Validation Batch #: 401, Validation Loss: 8.055941428329582, Validation Accuracy: 0.720074812967581\n",
      "Epoch: 199/10\n",
      "Batch #: [001/298], Train Loss: 1.6298125046887435e-05, Train Accuracy: 1.0\n",
      "Batch #: [101/298], Train Loss: 0.00044005824071516623, Train Accuracy: 0.994740099009901\n",
      "Batch #: [201/298], Train Loss: 0.0006114523394852206, Train Accuracy: 0.9936256218905473\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 7.99828577041626, Validation Accuracy: 0.78125\n",
      "Validation Batch #: 101, Validation Loss: 8.056773081864462, Validation Accuracy: 0.71875\n",
      "Validation Batch #: 201, Validation Loss: 8.058390237798738, Validation Accuracy: 0.7165733830845771\n",
      "Validation Batch #: 301, Validation Loss: 8.057066326521559, Validation Accuracy: 0.7180232558139535\n",
      "Validation Batch #: 401, Validation Loss: 8.055277949259466, Validation Accuracy: 0.7203086034912718\n",
      "Epoch: 200/10\n",
      "Batch #: [001/298], Train Loss: 0.001928661367855966, Train Accuracy: 0.96875\n",
      "Batch #: [101/298], Train Loss: 0.0008676528620097511, Train Accuracy: 0.989480198019802\n",
      "Batch #: [201/298], Train Loss: 0.0009484565006622783, Train Accuracy: 0.9897388059701493\n",
      "Run Validation:\n",
      "Validation Batch #: 001, Validation Loss: 8.162898063659668, Validation Accuracy: 0.59375\n",
      "Validation Batch #: 101, Validation Loss: 8.051950756866153, Validation Accuracy: 0.7249381188118812\n",
      "Validation Batch #: 201, Validation Loss: 8.05287549744791, Validation Accuracy: 0.7238805970149254\n",
      "Validation Batch #: 301, Validation Loss: 8.053949112115903, Validation Accuracy: 0.7226951827242525\n",
      "Validation Batch #: 401, Validation Loss: 8.057376710554013, Validation Accuracy: 0.7185941396508728\n"
     ]
    }
   ],
   "source": [
    "# Train Model with Provided ArcFace \n",
    "start = time.time()\n",
    "history = []\n",
    "best_acc = 0.0\n",
    "\n",
    "\n",
    "for epoch in range(200):\n",
    "    epoch_start = time.time()\n",
    "    print(\"Epoch: {}/{}\".format(epoch + 1, 10))\n",
    "\n",
    "    # Set model to train mode\n",
    "    models.train()\n",
    "\n",
    "  #  Step through scheduler\n",
    "    scheduler.step()\n",
    "\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0 \n",
    "\n",
    "    valid_loss = 0.0\n",
    "    valid_acc = 0.0\n",
    "\n",
    "\n",
    "    for i, (images, labels) in enumerate(data_loader_train):\n",
    "        # Put tensors into device to run CUDA\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # Run Resnet50 on images to compute the embedding of size 512\n",
    "        embeddings = models(images)\n",
    "\n",
    "        # Push this embedding to our Arcface fc output layer\n",
    "        output = metric_fc(embeddings, labels)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = Loss(output, labels)\n",
    "\n",
    "        # Clean existing gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Backprop the gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Update Parameters after backprop\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "        # Accumulate loss\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # Accuracy prediction\n",
    "        ret, predictions = torch.max(output.data, 1)\n",
    "        correct_counts = predictions.eq(labels.data.view_as(predictions))\n",
    "\n",
    "        # Conver correct_counts to float then compute the mean\n",
    "        acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
    "  \n",
    "        # Compute the total accuracy in the whole batch and add to train_acc\n",
    "        train_acc += acc.item()\n",
    "        if (i % 100 == 0):\n",
    "          #print('Predictions: {}, Truth: {}'.format(output, labels))\n",
    "          #print(correct_counts)\n",
    "          print('Batch #: [{:03d}/{}], Train Loss: {}, Train Accuracy: {}'\n",
    "                  .format(i+1, len(data_loader_train), train_loss / (i+1), train_acc / (i + 1)))\n",
    "      \n",
    "\n",
    "    \n",
    "    # Run Validation \n",
    "    with torch.no_grad():\n",
    "        print(\"Run Validation:\")\n",
    "        # Set to evaluation mode\n",
    "        models.eval()\n",
    "\n",
    "        valid_loss = 0.0\n",
    "        valid_acc = 0.0\n",
    "\n",
    "        for j, (images, labels) in enumerate(data_loader_valid):\n",
    "            # Put tensors into device to run CUDA\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Run Resnet50 on images to compute the output feature\n",
    "            embeddings = models(images)\n",
    "\n",
    "            # Push this embedding to our Arcface fc output layer\n",
    "            output = metric_fc(embeddings)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = Loss(output, labels)\n",
    "\n",
    "            # Calculate the total loss for the batch and add it to valid_loss\n",
    "            valid_loss += loss.item()\n",
    "\n",
    "            # Accuracy prediction\n",
    "            ret, predictions = torch.max(output.data, 1)\n",
    "            correct_counts = predictions.eq(labels.data.view_as(predictions))\n",
    "\n",
    "            # Convert correct_counts to float then compute the mean\n",
    "            acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
    "\n",
    "            # Compute the total accuracy in the whole batch and add to train_acc\n",
    "            valid_acc += acc.item()\n",
    "            if (j % 100 == 0):\n",
    "              print('Validation Batch #: {:03d}, Validation Loss: {}, Validation Accuracy: {}'\n",
    "              .format(j+1, valid_loss / (j + 1), valid_acc / (j + 1)))\n",
    "    history.append({'loss': train_loss / len(data_loader_train), 'acc': train_acc / len(data_loader_train), 'val_loss': valid_loss / len(data_loader_valid), 'val_acc': valid_acc / len(data_loader_valid)})\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9714e406",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-02T06:21:01.966343Z",
     "iopub.status.busy": "2023-04-02T06:21:01.965538Z",
     "iopub.status.idle": "2023-04-02T06:21:02.296336Z",
     "shell.execute_reply": "2023-04-02T06:21:02.295107Z"
    },
    "papermill": {
     "duration": 0.431249,
     "end_time": "2023-04-02T06:21:02.298752",
     "exception": false,
     "start_time": "2023-04-02T06:21:01.867503",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights\n"
     ]
    }
   ],
   "source": [
    "# Save Weights from metric_fc and resnet50\n",
    "torch.save(models.state_dict(), '/kaggle/working/resnet50_weights2.pth')\n",
    "torch.save(metric_fc.state_dict(), '/kaggle/working/arcface_weights2.pth')\n",
    "print(\"Weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "467deaed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-02T06:21:02.502929Z",
     "iopub.status.busy": "2023-04-02T06:21:02.502585Z",
     "iopub.status.idle": "2023-04-02T06:21:02.897325Z",
     "shell.execute_reply": "2023-04-02T06:21:02.896303Z"
    },
    "papermill": {
     "duration": 0.494497,
     "end_time": "2023-04-02T06:21:02.899769",
     "exception": false,
     "start_time": "2023-04-02T06:21:02.405272",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the training and validation results\n",
    "accuracy = [res['acc'] for res in history]\n",
    "losses = [res['loss'] for res in history]\n",
    "val_accuracy = [res['val_acc'] for res in history]\n",
    "val_losses = [res['val_loss'] for res in history]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (10, 5))\n",
    "ax1.plot(losses, '-o', label = 'Loss')\n",
    "ax1.plot(val_losses, '-o', label = 'Validation Loss')\n",
    "ax1.set_xlabel(\"Number of Epochs\")\n",
    "ax1.set_ylabel(\"Loss\")\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(100 * np.array(accuracy), '-o', label = 'Accuracy')\n",
    "ax2.plot(100 * np.array(val_accuracy), '-o', label = 'Validation Accuracy')\n",
    "ax2.set_xlabel(\"Number of Epochs\")\n",
    "ax2.set_ylabel(\"Accuracy\")\n",
    "ax2.legend();\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e28c7a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-02T06:21:03.097299Z",
     "iopub.status.busy": "2023-04-02T06:21:03.096949Z",
     "iopub.status.idle": "2023-04-02T06:21:03.101916Z",
     "shell.execute_reply": "2023-04-02T06:21:03.100844Z"
    },
    "papermill": {
     "duration": 0.105721,
     "end_time": "2023-04-02T06:21:03.104185",
     "exception": false,
     "start_time": "2023-04-02T06:21:02.998464",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Inference Testing\n",
    "# embeddings = [models(img) for img, label in data_loader_train]\n",
    "# with torch.no_grad():\n",
    "#     print(\"Perform Inference Test\")\n",
    "#     models.eval()\n",
    "    \n",
    "#     correct_count = 0.0\n",
    "#     # Find the max value of the label tensor to find the number of classes of people\n",
    "    \n",
    "#     for i, (img, label) in enumerate(data_loader_test):\n",
    "#         img, label = img.to(device), label.to(device)\n",
    "        \n",
    "#         feat = models(img)\n",
    "#         for count, embed in enumerate(embeddings):\n",
    "#             pred = torch.where(F.cosine_similarity(feat, embed) > 0.7, count)\n",
    "        \n",
    "#         print(pred)\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93db2047",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-02T06:21:03.300606Z",
     "iopub.status.busy": "2023-04-02T06:21:03.300301Z",
     "iopub.status.idle": "2023-04-02T06:21:18.356191Z",
     "shell.execute_reply": "2023-04-02T06:21:18.354200Z"
    },
    "papermill": {
     "duration": 15.156617,
     "end_time": "2023-04-02T06:21:18.358698",
     "exception": false,
     "start_time": "2023-04-02T06:21:03.202081",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run Testing Set:\n",
      "Validation Batch #: 001, Train Loss: 8.659337997436523, Accuracy: 0.0\n",
      "Validation Batch #: 006, Train Loss: 8.658408164978027, Accuracy: 0.0\n",
      "Validation Batch #: 011, Train Loss: 8.658976381475275, Accuracy: 0.0\n",
      "Validation Batch #: 016, Train Loss: 8.658588349819183, Accuracy: 0.0\n",
      "Validation Batch #: 021, Train Loss: 8.658482687813896, Accuracy: 0.0\n",
      "Validation Batch #: 026, Train Loss: 8.658613278315617, Accuracy: 0.0\n",
      "Validation Batch #: 031, Train Loss: 8.65826819019933, Accuracy: 0.0\n",
      "Validation Batch #: 036, Train Loss: 8.658629655838013, Accuracy: 0.0\n",
      "Validation Batch #: 041, Train Loss: 8.658553751503549, Accuracy: 0.0\n",
      "Validation Batch #: 046, Train Loss: 8.658324241638184, Accuracy: 0.0\n",
      "Validation Batch #: 051, Train Loss: 8.658408912957883, Accuracy: 0.0\n",
      "Validation Batch #: 056, Train Loss: 8.658388546534947, Accuracy: 0.0\n",
      "Validation Batch #: 061, Train Loss: 8.658413527441807, Accuracy: 0.0\n",
      "Validation Batch #: 066, Train Loss: 8.6583145459493, Accuracy: 0.0\n",
      "Validation Batch #: 071, Train Loss: 8.65829812976676, Accuracy: 0.0\n",
      "Validation Batch #: 076, Train Loss: 8.658208520788895, Accuracy: 0.0\n",
      "Validation Batch #: 081, Train Loss: 8.658224871129166, Accuracy: 0.0\n",
      "Validation Batch #: 086, Train Loss: 8.658186979072038, Accuracy: 0.0\n",
      "Validation Batch #: 091, Train Loss: 8.658093745891865, Accuracy: 0.0\n",
      "Validation Batch #: 096, Train Loss: 8.658110817273458, Accuracy: 0.0\n",
      "Validation Batch #: 101, Train Loss: 8.658029745120814, Accuracy: 0.0\n",
      "Validation Batch #: 106, Train Loss: 8.657972299827719, Accuracy: 0.0\n",
      "Validation Batch #: 111, Train Loss: 8.65793022808728, Accuracy: 0.0\n",
      "Validation Batch #: 116, Train Loss: 8.657891043301287, Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Inference Testing\n",
    "with torch.no_grad():\n",
    "        print(\"Run Testing Set:\")\n",
    "        # Set to evaluation mode\n",
    "        models.eval()\n",
    "\n",
    "        test_loss = 0.0\n",
    "        test_acc = 0.0\n",
    "\n",
    "        for j, (images, labels) in enumerate(data_loader_test):\n",
    "            # Put tensors into device to run CUDA\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Run Resnet50 on images to compute the output feature\n",
    "            embeddings = models(images)\n",
    "\n",
    "            # Push this embedding to our Arcface fc output layer\n",
    "            output = metric_fc(embeddings)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = Loss(output, labels)\n",
    "\n",
    "            # Calculate the total loss for the batch and add it to valid_loss\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            # Accuracy prediction\n",
    "            ret, predictions = torch.max(output.data, 1)\n",
    "            correct_counts = predictions.eq(labels.data.view_as(predictions))\n",
    "\n",
    "            # Convert correct_counts to float then compute the mean\n",
    "            acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
    "\n",
    "            # Compute the total accuracy in the whole batch and add to train_acc\n",
    "            test_acc += acc.item()\n",
    "            if (j % 5 == 0):\n",
    "              print('Validation Batch #: {:03d}, Train Loss: {}, Accuracy: {}'\n",
    "              .format(j+1, test_loss / (j + 1), test_acc / (j + 1)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 27689.77444,
   "end_time": "2023-04-02T06:21:22.306554",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-04-01T22:39:52.532114",
   "version": "2.4.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "02325278f4524aa48091528508077912": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "03214400181e4735b5c8799b9679d42b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "09ddf1c7b05d4bdba652d0035a486945": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_19eecd3e72f34ff98eade769b42440d9",
        "IPY_MODEL_e3dc1d87df2a4456bc2df0807baf15ce",
        "IPY_MODEL_671f0a0b49814698a7c93a8618bf1446"
       ],
       "layout": "IPY_MODEL_a784e0d2f1af4afdbd8ae0ddab8139db"
      }
     },
     "0ecf7d6b26b3425d88f13417b80ee2c4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0f9c4f7394084b7cb54cb3ef22583b7a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e74a62add1604536b631dfab4b4e5c7b",
       "max": 66403.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_db755ed99e8d49a09bb74b00d6bd5608",
       "value": 66403.0
      }
     },
     "143697efbdf24e8a984e59c0e6595ce0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2f78f4cffafa4a17bad2609c2080ec2b",
       "placeholder": "​",
       "style": "IPY_MODEL_a2bc46e434fa4032b7d33b9b5dfd350c",
       "value": " 94727/94727 [00:00&lt;00:00, 1000803.12it/s]"
      }
     },
     "19eecd3e72f34ff98eade769b42440d9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4c8ecf7eea994d31b7b18bc45a80b6d1",
       "placeholder": "​",
       "style": "IPY_MODEL_b40c97266b9843c78c8b9b45185ab3e1",
       "value": "100%"
      }
     },
     "2035a8f8de314b39a9fc6629c295231e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_03214400181e4735b5c8799b9679d42b",
       "placeholder": "​",
       "style": "IPY_MODEL_78f2de5504384fb58c17f75bad535329",
       "value": "100%"
      }
     },
     "215ed6e6635b4103a68221bc5b624253": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "2d67ac4be9454a18a346dd4ab0fff983": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_c94bff29679541a4acd05208a003752c",
        "IPY_MODEL_b440117b9149491aa4a0e778322b0324",
        "IPY_MODEL_95c695b5aa0f4f0894575a41ed994f52"
       ],
       "layout": "IPY_MODEL_3c13fcecd6b64f31bf29bedc7d9dfad1"
      }
     },
     "2f78f4cffafa4a17bad2609c2080ec2b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "33a9a3175c094a14ab9b4de74a4661a6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "35bdbab0473447f28472857e8ec9441e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3c13fcecd6b64f31bf29bedc7d9dfad1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3e95e8c119a645a8aa3be95085845de5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "4c8ecf7eea994d31b7b18bc45a80b6d1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4df42f7ca14347539cfca41257416cdb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_35bdbab0473447f28472857e8ec9441e",
       "max": 94770.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_98072f48a3ad4a61baf069fcbbb63d6d",
       "value": 94770.0
      }
     },
     "55d1a840a0e346cc998a13884109d757": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5f457d1ca89a4c5090ebe82555d55330": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f0fea8800f82470aaa28ffa4b539f419",
       "placeholder": "​",
       "style": "IPY_MODEL_da9578c6bd41493da436ec354d209702",
       "value": "100%"
      }
     },
     "6278319381714ddea029bd6dad4a0aef": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_5f457d1ca89a4c5090ebe82555d55330",
        "IPY_MODEL_0f9c4f7394084b7cb54cb3ef22583b7a",
        "IPY_MODEL_a0a0916491fb4acd8cdad4338426b6e5"
       ],
       "layout": "IPY_MODEL_55d1a840a0e346cc998a13884109d757"
      }
     },
     "637e39a2236347948faeb0d2ccbef53d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "65571fb87f1e409ea4ddfa9401e63614": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "65f15db7935b42a1b593803df93a5161": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "671f0a0b49814698a7c93a8618bf1446": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c2b066f6de6c465d9cb513e0b7568bb4",
       "placeholder": "​",
       "style": "IPY_MODEL_33a9a3175c094a14ab9b4de74a4661a6",
       "value": " 243346528/243346528 [00:04&lt;00:00, 58022549.03it/s]"
      }
     },
     "673cf7ccb8f748b29c7fc9cce50b50de": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_2035a8f8de314b39a9fc6629c295231e",
        "IPY_MODEL_4df42f7ca14347539cfca41257416cdb",
        "IPY_MODEL_dc829650c0d24f50956b96ac616b7154"
       ],
       "layout": "IPY_MODEL_bde7939110964875922004df78156faf"
      }
     },
     "72e5ed27ba624cd6b73c2aba3b613a12": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0ecf7d6b26b3425d88f13417b80ee2c4",
       "placeholder": "​",
       "style": "IPY_MODEL_65571fb87f1e409ea4ddfa9401e63614",
       "value": "100%"
      }
     },
     "730dbf58f4384a3195a1f15b523230eb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7690a1568e2b466786fc17547d04c0dc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "78f2de5504384fb58c17f75bad535329": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "92d1c4b82d3e475f9cc3e4d9a8196534": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "938a38dbb3b34e03b13d2bcd9acfe594": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "95c695b5aa0f4f0894575a41ed994f52": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7690a1568e2b466786fc17547d04c0dc",
       "placeholder": "​",
       "style": "IPY_MODEL_e4a0bbc72c644bdfbba3cb3a9ca223d8",
       "value": " 28334/28334 [00:00&lt;00:00, 577028.90it/s]"
      }
     },
     "98072f48a3ad4a61baf069fcbbb63d6d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "a0a0916491fb4acd8cdad4338426b6e5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c4ab3ed824c24a339a132728d22bee5b",
       "placeholder": "​",
       "style": "IPY_MODEL_65f15db7935b42a1b593803df93a5161",
       "value": " 66403/66403 [00:00&lt;00:00, 707981.78it/s]"
      }
     },
     "a2193c33dc8e410ca8c37388c81839b2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "a2bc46e434fa4032b7d33b9b5dfd350c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "a784e0d2f1af4afdbd8ae0ddab8139db": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a966cf8805d7433f90479a13564fd835": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "ab55889cd8594e038ed62c14e45907aa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "b40c97266b9843c78c8b9b45185ab3e1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "b440117b9149491aa4a0e778322b0324": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_938a38dbb3b34e03b13d2bcd9acfe594",
       "max": 28334.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_ab55889cd8594e038ed62c14e45907aa",
       "value": 28334.0
      }
     },
     "b62ecfeca156452f9fbbe39404d7b2fd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bde7939110964875922004df78156faf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c2b066f6de6c465d9cb513e0b7568bb4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c4ab3ed824c24a339a132728d22bee5b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c94bff29679541a4acd05208a003752c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b62ecfeca156452f9fbbe39404d7b2fd",
       "placeholder": "​",
       "style": "IPY_MODEL_a2193c33dc8e410ca8c37388c81839b2",
       "value": "100%"
      }
     },
     "d0738b28abe54945bff17b662e46e118": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_730dbf58f4384a3195a1f15b523230eb",
       "max": 94727.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_a966cf8805d7433f90479a13564fd835",
       "value": 94727.0
      }
     },
     "d1c42f9a3e3547cc8d061be0dea2ccf9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_72e5ed27ba624cd6b73c2aba3b613a12",
        "IPY_MODEL_d0738b28abe54945bff17b662e46e118",
        "IPY_MODEL_143697efbdf24e8a984e59c0e6595ce0"
       ],
       "layout": "IPY_MODEL_02325278f4524aa48091528508077912"
      }
     },
     "da9578c6bd41493da436ec354d209702": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "db755ed99e8d49a09bb74b00d6bd5608": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "dc829650c0d24f50956b96ac616b7154": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_637e39a2236347948faeb0d2ccbef53d",
       "placeholder": "​",
       "style": "IPY_MODEL_215ed6e6635b4103a68221bc5b624253",
       "value": " 94770/94770 [00:00&lt;00:00, 952682.03it/s]"
      }
     },
     "e3dc1d87df2a4456bc2df0807baf15ce": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_92d1c4b82d3e475f9cc3e4d9a8196534",
       "max": 243346528.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_3e95e8c119a645a8aa3be95085845de5",
       "value": 243346528.0
      }
     },
     "e4a0bbc72c644bdfbba3cb3a9ca223d8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "e74a62add1604536b631dfab4b4e5c7b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f0fea8800f82470aaa28ffa4b539f419": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
